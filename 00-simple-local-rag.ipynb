{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# 從頭開始認識RAG流程\n",
    "\n",
    "**專案目標**: 在本地GPU實作RAG(Retrieval Augmented Generation)一系列pipeline，下query詢問LLM關於文件的內容，由LLM生成回答。\n",
    "\n",
    "**相關框架**: [LlamaIndex](https://www.llamaindex.ai/) and [LangChain](https://www.langchain.com/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 甚麼是RAG?\n",
    "\n",
    "論文: [*Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks*](https://arxiv.org/abs/2005.11401).  \n",
    "[GitHub](https://github.com/mrdbourke/simple-local-rag/?tab=readme-ov-file#setup\n",
    "\n",
    "RAG流程:\n",
    "\n",
    "* **Retrieval** - 從給定的文件中提取Query的答案。  \n",
    "`載入文件 -> chunking -> embedding -> 查詢 -> embed查詢 -> 比較查詢embeddings和chunks的embeddings`\n",
    "\n",
    "* **Augmented** - 利用檢索到的資訊作為LLM的輸入。\n",
    "* **Generation** - 從前面的Imput影響、優化LLM的輸出。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 為什麼要RAG?\n",
    "\n",
    "兩個主要改善：\n",
    "\n",
    "<font color=#faf>**防止幻覺**</font> - LLM容易出現幻覺(hallucinations)，生成出看起來正確但奇是是錯的內容。RAG可以幫助提供LLM帶有事實依據的參考。  \n",
    "<font color=#faf>**自定義數據**</font> - LLM在語言方面能力強大，但往往缺乏**具體的知識**。RAG可以提供特定領域的數據，快速制定出<font color=#ffa>**特殊領域**</font>的知識庫，提供更多<font color=#ffa>可解釋性</font>。\n",
    "\n",
    "RAG也可以是一種比在<font color=#ffa>**特定數據**</font>上微調LLM更快的解決方案。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 為什麼Local? --> 隱私（自己的硬體）、成本、趨勢、（效率？）  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 關鍵名詞\n",
    "\n",
    "- **Token**  \n",
    "- **Embedding** \n",
    "- **Embedding model**: 接收A個tokens的文本，轉成一個大小B的向量。 *嵌入模型可以與大型語言模型不同。*  \n",
    "- **Similarity search/vector search(相似性檢索/向量檢索)**: 使用餘閒相似度(Cosine similarity)。相似文本相似度應該越高;不同文本應該相似度越低。  \n",
    "- **LLM** \n",
    "- **Prompt**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 建構項目\n",
    "\n",
    "建構一個RAG的pipline，它可以和PDF進行對話，具體來說是一本開源的XX知識庫。\n",
    "\n",
    "* 打開 PDF。\n",
    "* 格式化PDF文本，為嵌入模型做好準備（過程稱為text splitting/chunking）。\n",
    "* 將pdf的所有chunks嵌入並轉化為數字表示，稍後可以儲存這些數字。\n",
    "* 建立一個使用向量搜索來根據查詢找到相關chunks的檢索系統。\n",
    "* 創建一個包含檢索到的文本片段的prompt。\n",
    "* 根據pdf的段落生成對查詢的回答。\n",
    "\n",
    "步驟可以分為兩大部分：\n",
    "\n",
    ">文檔預處理/嵌入創建（步驟 1-3）。  \n",
    "搜索與回答（步驟 4-6）。\n",
    "\n",
    "<img src=\"https://github.com/mrdbourke/simple-local-rag/blob/main/images/simple-local-rag-workflow-flowchart.png?raw=true\" alt=\"flowchart of a local RAG workflow\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 建立文件的embedding\n",
    "\n",
    "所需物件\n",
    "* PDF文件\n",
    "* Embedding model\n",
    "\n",
    "步驟:\n",
    "1. 載入文件\n",
    "2. text splitting/chunking\n",
    "3. 嵌入embedding model.\n",
    "4. 保存嵌入，日後使用"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 載入pdf檔  \n",
    "<font color=#ffa>PyMuPDF</font> (`import fitz`): 用python打開pdf檔的庫\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "\n",
    "pdf_path = \"RAG.pdf\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "用fitz套件閱讀文件檔，定義`open_and_read_pdf`函式來存放資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e54daa3cefbc4ccb8e3121296f4a0daa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'page_number': 0,\n",
       "  'page_char_count': 2975,\n",
       "  'page_word_count': 410,\n",
       "  'page_sentence_count_raw': 14,\n",
       "  'page_token_count': 743.75,\n",
       "  'text': 'Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks Patrick Lewis†‡, Ethan Perez?, Aleksandra Piktus†, Fabio Petroni†, Vladimir Karpukhin†, Naman Goyal†, Heinrich Küttler†, Mike Lewis†, Wen-tau Yih†, Tim Rocktäschel†‡, Sebastian Riedel†‡, Douwe Kiela† †Facebook AI Research; ‡University College London; ?New York University; plewis@fb.com Abstract Large pre-trained language models have been shown to store factual knowledge in their parameters, and achieve state-of-the-art results when ﬁne-tuned on down- stream NLP tasks. However, their ability to access and precisely manipulate knowledge is still limited, and hence on knowledge-intensive tasks, their perfor- mance lags behind task-speciﬁc architectures. Additionally, providing provenance for their decisions and updating their world knowledge remain open research prob- lems. Pre-trained models with a differentiable access mechanism to explicit non- parametric memory can overcome this issue, but have so far been only investigated for extractive downstream tasks. We explore a general-purpose ﬁne-tuning recipe for retrieval-augmented generation (RAG) — models which combine pre-trained parametric and non-parametric memory for language generation. We introduce RAG models where the parametric memory is a pre-trained seq2seq model and the non-parametric memory is a dense vector index of Wikipedia, accessed with a pre-trained neural retriever. We compare two RAG formulations, one which conditions on the same retrieved passages across the whole generated sequence, and another which can use different passages per token. We ﬁne-tune and evaluate our models on a wide range of knowledge-intensive NLP tasks and set the state of the art on three open domain QA tasks, outperforming parametric seq2seq models and task-speciﬁc retrieve-and-extract architectures. For language generation tasks, we ﬁnd that RAG models generate more speciﬁc, diverse and factual language than a state-of-the-art parametric-only seq2seq baseline. 1 Introduction Pre-trained neural language models have been shown to learn a substantial amount of in-depth knowl- edge from data [47]. They can do so without any access to an external memory, as a parameterized implicit knowledge base [51, 52]. While this development is exciting, such models do have down- sides: They cannot easily expand or revise their memory, can’t straightforwardly provide insight into their predictions, and may produce “hallucinations” [38]. Hybrid models that combine parametric memory with non-parametric (i.e., retrieval-based) memories [20, 26, 48] can address some of these issues because knowledge can be directly revised and expanded, and accessed knowledge can be inspected and interpreted. REALM [20] and ORQA [31], two recently introduced models that combine masked language models [8] with a differentiable retriever, have shown promising results, 34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada.'},\n",
       " {'page_number': 1,\n",
       "  'page_char_count': 4554,\n",
       "  'page_word_count': 623,\n",
       "  'page_sentence_count_raw': 26,\n",
       "  'page_token_count': 1138.5,\n",
       "  'text': 'The\\x03DiYine Comed\\\\\\x03(x) T QXeU\\\\ EQcRdeU T([) MIPS pθ GeneUaWoU¬Sѡ (PaUaPeWULc) MaUgin- ali]e ThiV\\x0314Wh\\x03cenWXU\\\\\\x03ZoUk iV\\x03diYided\\x03inWo\\x033 VecWionV:\\x03\"InfeUno\", \"PXUgaWoUio\"\\x03& \"PaUadiVo\"\\x03\\x03\\x03\\x03\\x03\\x03\\x03\\x03\\x03(y) End-to-End Backprop through T and¬pθ BaUack\\x03Obama\\x03ZaV boUn\\x03in\\x03HaZaii.(x) FacW VeUiÀcaWiRQ: FacW QXeU\\\\ VXppoUWV\\x03(y) QXeVWiRQ GeQeUaWiRQ FacW VeUiÀcaWiRQ: LabeO GeQeUaWiRQ DRcXmeQW IQde[ Define\\x03\"middle\\x03eaU\"(x) QXeVWiRQ AQVZeUiQg: QXeVWiRQ QXeU\\\\ The\\x03middle\\x03eaU\\x03inclXdeV Whe\\x03W\\\\mpanic\\x03caYiW\\\\\\x03and Whe\\x03WhUee\\x03oVVicleV.\\x03\\x03(y) QXeVWiRQ AQVZeUiQg: AQVZeU GeQeUaWiRQ ReWUieYeU Sη (NRQ-PaUaPeWULc) z4 z3 z2 z1 d(]) JeRSaUd\\\\ QXeVWiRQ GeQeUaWiRQ: AQVZeU QXeU\\\\ Figure 1: Overview of our approach. We combine a pre-trained retriever (Query Encoder + Document Index) with a pre-trained seq2seq model (Generator) and ﬁne-tune end-to-end. For query x, we use Maximum Inner Product Search (MIPS) to ﬁnd the top-K documents zi. For ﬁnal prediction y, we treat z as a latent variable and marginalize over seq2seq predictions given different documents. but have only explored open-domain extractive question answering. Here, we bring hybrid parametric and non-parametric memory to the “workhorse of NLP,” i.e. sequence-to-sequence (seq2seq) models. We endow pre-trained, parametric-memory generation models with a non-parametric memory through a general-purpose ﬁne-tuning approach which we refer to as retrieval-augmented generation (RAG). We build RAG models where the parametric memory is a pre-trained seq2seq transformer, and the non-parametric memory is a dense vector index of Wikipedia, accessed with a pre-trained neural retriever. We combine these components in a probabilistic model trained end-to-end (Fig. 1). The retriever (Dense Passage Retriever [26], henceforth DPR) provides latent documents conditioned on the input, and the seq2seq model (BART [32]) then conditions on these latent documents together with the input to generate the output. We marginalize the latent documents with a top-K approximation, either on a per-output basis (assuming the same document is responsible for all tokens) or a per-token basis (where different documents are responsible for different tokens). Like T5 [51] or BART, RAG can be ﬁne-tuned on any seq2seq task, whereby both the generator and retriever are jointly learned. There has been extensive previous work proposing architectures to enrich systems with non-parametric memory which are trained from scratch for speciﬁc tasks, e.g. memory networks [64, 55], stack- augmented networks [25] and memory layers [30]. In contrast, we explore a setting where both parametric and non-parametric memory components are pre-trained and pre-loaded with extensive knowledge. Crucially, by using pre-trained access mechanisms, the ability to access knowledge is present without additional training. Our results highlight the beneﬁts of combining parametric and non-parametric memory with genera- tion for knowledge-intensive tasks—tasks that humans could not reasonably be expected to perform without access to an external knowledge source. Our RAG models achieve state-of-the-art results on open Natural Questions [29], WebQuestions [3] and CuratedTrec [2] and strongly outperform recent approaches that use specialised pre-training objectives on TriviaQA [24]. Despite these being extractive tasks, we ﬁnd that unconstrained generation outperforms previous extractive approaches. For knowledge-intensive generation, we experiment with MS-MARCO [1] and Jeopardy question generation, and we ﬁnd that our models generate responses that are more factual, speciﬁc, and diverse than a BART baseline. For FEVER [56] fact veriﬁcation, we achieve results within 4.3% of state-of-the-art pipeline models which use strong retrieval supervision. Finally, we demonstrate that the non-parametric memory can be replaced to update the models’ knowledge as the world changes.1 2 Methods We explore RAG models, which use the input sequence x to retrieve text documents z and use them as additional context when generating the target sequence y. As shown in Figure 1, our models leverage two components: (i) a retriever p⌘(z|x) with parameters ⌘ that returns (top-K truncated) distributions over text passages given a query x and (ii) a generator p✓(yi|x, z, y1:i−1) parametrized 1Code to run experiments with RAG has been open-sourced as part of the HuggingFace Transform- ers Library [66] and can be found at https://github.com/huggingface/transformers/blob/master/ examples/rag/. An interactive demo of RAG models can be found at https://huggingface.co/rag/ 2'}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Requires !pip install PyMuPDF, see: https://github.com/pymupdf/pymupdf\n",
    "import fitz\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "def text_formatter(text: str) -> str:\n",
    "    \"\"\"Performs minor formatting on text.\"\"\"\n",
    "    cleaned_text = text.replace(\"\\n\", \" \").strip()\n",
    "    return cleaned_text\n",
    "\n",
    "# 只讀取文字，沒有讀取圖片\n",
    "def open_and_read_pdf(pdf_path):\n",
    "    doc = fitz.open(pdf_path)  # open a document\n",
    "    pages_and_texts = []    #\n",
    "    for page_number, page in tqdm(enumerate(doc)):  # iterate the document pages\n",
    "        text = page.get_text()  # get plain text encoded as UTF-8\n",
    "        text = text_formatter(text)\n",
    "        pages_and_texts.append({\"page_number\": page_number-0,  # adjust page numbers since our PDF starts on page 42\n",
    "                                \"page_char_count\": len(text),\n",
    "                                \"page_word_count\": len(text.split(\" \")),\n",
    "                                \"page_sentence_count_raw\": len(text.split(\". \")),\n",
    "                                \"page_token_count\": len(text) / 4,  # 1 token = ~4 chars, see: https://help.openai.com/en/articles/4936856-what-are-tokens-and-how-to-count-them\n",
    "                                \"text\": text})\n",
    "    return pages_and_texts\n",
    "\n",
    "pages_and_texts = open_and_read_pdf(pdf_path=pdf_path)\n",
    "pages_and_texts[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "隨機測試不同頁碼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'page_number': 2,\n",
       "  'page_char_count': 3678,\n",
       "  'page_word_count': 570,\n",
       "  'page_sentence_count_raw': 25,\n",
       "  'page_token_count': 919.5,\n",
       "  'text': 'by ✓ that generates a current token based on a context of the previous i − 1 tokens y1:i−1, the original input x and a retrieved passage z. To train the retriever and generator end-to-end, we treat the retrieved document as a latent variable. We propose two models that marginalize over the latent documents in different ways to produce a distribution over generated text. In one approach, RAG-Sequence, the model uses the same document to predict each target token. The second approach, RAG-Token, can predict each target token based on a different document. In the following, we formally introduce both models and then describe the p⌘ and p✓ components, as well as the training and decoding procedure. 2.1 Models RAG-Sequence Model The RAG-Sequence model uses the same retrieved document to generate the complete sequence. Technically, it treats the retrieved document as a single latent variable that is marginalized to get the seq2seq probability p(y|x) via a top-K approximation. Concretely, the top K documents are retrieved using the retriever, and the generator produces the output sequence probability for each document, which are then marginalized, pRAG-Sequence(y|x) ⇡ X z2top-k(p(·|x)) p⌘(z|x)p✓(y|x, z) = X z2top-k(p(·|x)) p⌘(z|x) N Y i p✓(yi|x, z, y1:i−1) RAG-Token Model In the RAG-Token model we can draw a different latent document for each target token and marginalize accordingly. This allows the generator to choose content from several documents when producing an answer. Concretely, the top K documents are retrieved using the retriever, and then the generator produces a distribution for the next output token for each document, before marginalizing, and repeating the process with the following output token, Formally, we deﬁne: pRAG-Token(y|x) ⇡ N Y i X z2top-k(p(·|x)) p⌘(z|x)p✓(yi|x, zi, y1:i−1) Finally, we note that RAG can be used for sequence classiﬁcation tasks by considering the target class as a target sequence of length one, in which case RAG-Sequence and RAG-Token are equivalent. 2.2 Retriever: DPR The retrieval component p⌘(z|x) is based on DPR [26]. DPR follows a bi-encoder architecture: p⌘(z|x) / exp # d(z)>q(x) $ d(z) = BERTd(z), q(x) = BERTq(x) where d(z) is a dense representation of a document produced by a BERTBASE document encoder [8], and q(x) a query representation produced by a query encoder, also based on BERTBASE. Calculating top-k(p⌘(·|x)), the list of k documents z with highest prior probability p⌘(z|x), is a Maximum Inner Product Search (MIPS) problem, which can be approximately solved in sub-linear time [23]. We use a pre-trained bi-encoder from DPR to initialize our retriever and to build the document index. This retriever was trained to retrieve documents which contain answers to TriviaQA [24] questions and Natural Questions [29]. We refer to the document index as the non-parametric memory. 2.3 Generator: BART The generator component p✓(yi|x, z, y1:i−1) could be modelled using any encoder-decoder. We use BART-large [32], a pre-trained seq2seq transformer [58] with 400M parameters. To combine the input x with the retrieved content z when generating from BART, we simply concatenate them. BART was pre-trained using a denoising objective and a variety of different noising functions. It has obtained state-of-the-art results on a diverse set of generation tasks and outperforms comparably-sized T5 models [32]. We refer to the BART generator parameters ✓ as the parametric memory henceforth. 2.4 Training We jointly train the retriever and generator components without any direct supervision on what document should be retrieved. Given a ﬁne-tuning training corpus of input/output pairs (xj, yj), we 3'},\n",
       " {'page_number': 12,\n",
       "  'page_char_count': 3852,\n",
       "  'page_word_count': 453,\n",
       "  'page_sentence_count_raw': 65,\n",
       "  'page_token_count': 963.0,\n",
       "  'text': '[31] Kenton Lee, Ming-Wei Chang, and Kristina Toutanova. Latent retrieval for weakly supervised open domain question answering. In Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pages 6086–6096, Florence, Italy, July 2019. Association for Computational Linguistics. doi: 10.18653/v1/P19-1612. URL https://www.aclweb.org/ anthology/P19-1612. [32] Mike Lewis, Yinhan Liu, Naman Goyal, Marjan Ghazvininejad, Abdelrahman Mohamed, Omer Levy, Veselin Stoyanov, and Luke Zettlemoyer. BART: Denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension. arXiv preprint arXiv:1910.13461, 2019. URL https://arxiv.org/abs/1910.13461. [33] Jiwei Li, Michel Galley, Chris Brockett, Jianfeng Gao, and Bill Dolan. A diversity-promoting objective function for neural conversation models. In Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 110–119, San Diego, California, June 2016. Association for Computational Linguistics. doi: 10.18653/v1/N16-1014. URL https://www.aclweb.org/anthology/ N16-1014. [34] Margaret Li, Jason Weston, and Stephen Roller. Acute-eval: Improved dialogue evaluation with optimized questions and multi-turn comparisons. ArXiv, abs/1909.03087, 2019. URL https://arxiv.org/abs/1909.03087. [35] Hairong Liu, Mingbo Ma, Liang Huang, Hao Xiong, and Zhongjun He. Robust neural machine translation with joint textual and phonetic embedding. In Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pages 3044–3049, Florence, Italy, July 2019. Association for Computational Linguistics. doi: 10.18653/v1/P19-1291. URL https://www.aclweb.org/anthology/P19-1291. [36] Peter J. Liu*, Mohammad Saleh*, Etienne Pot, Ben Goodrich, Ryan Sepassi, Lukasz Kaiser, and Noam Shazeer. Generating wikipedia by summarizing long sequences. In International Conference on Learning Representations, 2018. URL https://openreview.net/forum? id=Hyg0vbWC-. [37] Yury A. Malkov and D. A. Yashunin. Efﬁcient and robust approximate nearest neighbor search using hierarchical navigable small world graphs. IEEE Transactions on Pattern Analysis and Machine Intelligence, 42:824–836, 2016. URL https://arxiv.org/abs/1603.09320. [38] Gary Marcus. The next decade in ai: four steps towards robust artiﬁcial intelligence. arXiv preprint arXiv:2002.06177, 2020. URL https://arxiv.org/abs/2002.06177. [39] Luca Massarelli, Fabio Petroni, Aleksandra Piktus, Myle Ott, Tim Rocktäschel, Vassilis Plachouras, Fabrizio Silvestri, and Sebastian Riedel. How decoding strategies affect the veriﬁability of generated text. arXiv preprint arXiv:1911.03587, 2019. URL https: //arxiv.org/abs/1911.03587. [40] Paulius Micikevicius, Sharan Narang, Jonah Alben, Gregory Diamos, Erich Elsen, David Garcia, Boris Ginsburg, Michael Houston, Oleksii Kuchaiev, Ganesh Venkatesh, and Hao Wu. Mixed precision training. In ICLR, 2018. URL https://openreview.net/forum?id=r1gs9JgRZ. [41] Nikita Moghe, Siddhartha Arora, Suman Banerjee, and Mitesh M. Khapra. Towards exploit- ing background knowledge for building conversation systems. In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 2322–2332, Brus- sels, Belgium, October-November 2018. Association for Computational Linguistics. doi: 10.18653/v1/D18-1255. URL https://www.aclweb.org/anthology/D18-1255. [42] Preksha Nema and Mitesh M. Khapra. Towards a better metric for evaluating question generation systems. In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 3950–3959, Brussels, Belgium, October-November 2018. Association for Computational Linguistics. doi: 10.18653/v1/D18-1429. URL https://www.aclweb.org/ anthology/D18-1429. 13'},\n",
       " {'page_number': 5,\n",
       "  'page_char_count': 4115,\n",
       "  'page_word_count': 653,\n",
       "  'page_sentence_count_raw': 36,\n",
       "  'page_token_count': 1028.75,\n",
       "  'text': 'Table 1: Open-Domain QA Test Scores. For TQA, left column uses the standard test set for Open- Domain QA, right column uses the TQA-Wiki test set. See Appendix D for further details. Model NQ TQA WQ CT Closed Book T5-11B [52] 34.5 - /50.1 37.4 - T5-11B+SSM[52] 36.6 - /60.5 44.7 - Open Book REALM [20] 40.4 - / - 40.7 46.8 DPR [26] 41.5 57.9/ - 41.1 50.6 RAG-Token 44.1 55.2/66.1 45.5 50.0 RAG-Seq. 44.5 56.8/68.0 45.2 52.2 Table 2: Generation and classiﬁcation Test Scores. MS-MARCO SotA is [4], FEVER-3 is [68] and FEVER-2 is [57] *Uses gold context/evidence. Best model without gold access underlined. Model Jeopardy MSMARCO FVR3 FVR2 B-1 QB-1 R-L B-1 Label Acc. SotA - - 49.8* 49.9* 76.8 92.2* BART 15.1 19.7 38.2 41.6 64.0 81.1 RAG-Tok. 17.3 22.2 40.1 41.5 72.5 89.5 RAG-Seq. 14.7 21.4 40.8 44.2 to more effective marginalization over documents. Furthermore, RAG can generate correct answers even when the correct answer is not in any retrieved document, achieving 11.8% accuracy in such cases for NQ, where an extractive model would score 0%. 4.2 Abstractive Question Answering As shown in Table 2, RAG-Sequence outperforms BART on Open MS-MARCO NLG by 2.6 Bleu points and 2.6 Rouge-L points. RAG approaches state-of-the-art model performance, which is impressive given that (i) those models access gold passages with speciﬁc information required to generate the reference answer, (ii) many questions are unanswerable without the gold passages, and (iii) not all questions are answerable from Wikipedia alone. Table 3 shows some generated answers from our models. Qualitatively, we ﬁnd that RAG models hallucinate less and generate factually correct text more often than BART. Later, we also show that RAG generations are more diverse than BART generations (see §4.5). 4.3 Jeopardy Question Generation Table 2 shows that RAG-Token performs better than RAG-Sequence on Jeopardy question generation, with both models outperforming BART on Q-BLEU-1. Table 4 shows human evaluation results, over 452 pairs of generations from BART and RAG-Token. Evaluators indicated that BART was more factual than RAG in only 7.1% of cases, while RAG was more factual in 42.7% of cases, and both RAG and BART were factual in a further 17% of cases, clearly demonstrating the effectiveness of RAG on the task over a state-of-the-art generation model. Evaluators also ﬁnd RAG generations to be more speciﬁc by a large margin. Table 3 shows typical generations from each model. Jeopardy questions often contain two separate pieces of information, and RAG-Token may perform best because it can generate responses that combine content from several documents. Figure 2 shows an example. When generating “Sun”, the posterior is high for document 2 which mentions “The Sun Also Rises”. Similarly, document 1 dominates the posterior when “A Farewell to Arms” is generated. Intriguingly, after the ﬁrst token of each book is generated, the document posterior ﬂattens. This observation suggests that the generator can complete the titles without depending on speciﬁc documents. In other words, the model’s parametric knowledge is sufﬁcient to complete the titles. We ﬁnd evidence for this hypothesis by feeding the BART-only baseline with the partial decoding \"The Sun. BART completes the generation \"The Sun Also Rises\" is a novel by this author of \"The Sun Also Rises\" indicating the title \"The Sun Also Rises\" is stored in BART’s parameters. Similarly, BART will complete the partial decoding \"The Sun Also Rises\" is a novel by this author of \"A with \"The Sun Also Rises\" is a novel by this author of \"A Farewell to Arms\". This example shows how parametric and non-parametric memories work together—the non-parametric component helps to guide the generation, drawing out speciﬁc knowledge stored in the parametric memory. 4.4 Fact Veriﬁcation Table 2 shows our results on FEVER. For 3-way classiﬁcation, RAG scores are within 4.3% of state-of-the-art models, which are complex pipeline systems with domain-speciﬁc architectures and substantial engineering, trained using intermediate retrieval supervision, which RAG does not require. 6'}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "random.sample(pages_and_texts, k=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 獲取文本統計資料\n",
    "\n",
    "探索性數據分析（EDA），了解正在處理的文本的大小（字符數、單詞數等）。  \n",
    "從字典列表轉換成 DataFrame 查看"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_number</th>\n",
       "      <th>page_char_count</th>\n",
       "      <th>page_word_count</th>\n",
       "      <th>page_sentence_count_raw</th>\n",
       "      <th>page_token_count</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2975</td>\n",
       "      <td>410</td>\n",
       "      <td>14</td>\n",
       "      <td>743.75</td>\n",
       "      <td>Retrieval-Augmented Generation for Knowledge-I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>4554</td>\n",
       "      <td>623</td>\n",
       "      <td>26</td>\n",
       "      <td>1138.50</td>\n",
       "      <td>The\u0003DiYine Comed\\\u0003(x) T QXeU\\ EQcRdeU T([) MIP...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3678</td>\n",
       "      <td>570</td>\n",
       "      <td>25</td>\n",
       "      <td>919.50</td>\n",
       "      <td>by ✓ that generates a current token based on a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4227</td>\n",
       "      <td>681</td>\n",
       "      <td>35</td>\n",
       "      <td>1056.75</td>\n",
       "      <td>minimize the negative marginal log-likelihood ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4551</td>\n",
       "      <td>693</td>\n",
       "      <td>35</td>\n",
       "      <td>1137.75</td>\n",
       "      <td>MSMARCO as an open-domain abstractive QA task....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>4115</td>\n",
       "      <td>653</td>\n",
       "      <td>36</td>\n",
       "      <td>1028.75</td>\n",
       "      <td>Table 1: Open-Domain QA Test Scores. For TQA, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>4437</td>\n",
       "      <td>725</td>\n",
       "      <td>40</td>\n",
       "      <td>1109.25</td>\n",
       "      <td>Document 1: his works are considered classics ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>3060</td>\n",
       "      <td>499</td>\n",
       "      <td>20</td>\n",
       "      <td>765.00</td>\n",
       "      <td>Table 4: Human assessments for the Jeopardy Qu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>3976</td>\n",
       "      <td>600</td>\n",
       "      <td>23</td>\n",
       "      <td>994.00</td>\n",
       "      <td>General-Purpose Architectures for NLP Prior wo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>3574</td>\n",
       "      <td>505</td>\n",
       "      <td>39</td>\n",
       "      <td>893.50</td>\n",
       "      <td>Broader Impact This work offers several positi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>3749</td>\n",
       "      <td>452</td>\n",
       "      <td>64</td>\n",
       "      <td>937.25</td>\n",
       "      <td>55th Annual Meeting of the Association for Com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>4066</td>\n",
       "      <td>474</td>\n",
       "      <td>73</td>\n",
       "      <td>1016.50</td>\n",
       "      <td>[19] Kelvin Guu, Tatsunori B. Hashimoto, Yonat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>3852</td>\n",
       "      <td>453</td>\n",
       "      <td>65</td>\n",
       "      <td>963.00</td>\n",
       "      <td>[31] Kenton Lee, Ming-Wei Chang, and Kristina ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>3977</td>\n",
       "      <td>479</td>\n",
       "      <td>59</td>\n",
       "      <td>994.25</td>\n",
       "      <td>[43] Tri Nguyen, Mir Rosenberg, Xia Song, Jian...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>4132</td>\n",
       "      <td>522</td>\n",
       "      <td>78</td>\n",
       "      <td>1033.00</td>\n",
       "      <td>[55] Sainbayar Sukhbaatar, Arthur Szlam, Jason...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>1361</td>\n",
       "      <td>167</td>\n",
       "      <td>19</td>\n",
       "      <td>340.25</td>\n",
       "      <td>International Workshop on Search-Oriented Conv...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    page_number  page_char_count  page_word_count  page_sentence_count_raw  \\\n",
       "0             0             2975              410                       14   \n",
       "1             1             4554              623                       26   \n",
       "2             2             3678              570                       25   \n",
       "3             3             4227              681                       35   \n",
       "4             4             4551              693                       35   \n",
       "5             5             4115              653                       36   \n",
       "6             6             4437              725                       40   \n",
       "7             7             3060              499                       20   \n",
       "8             8             3976              600                       23   \n",
       "9             9             3574              505                       39   \n",
       "10           10             3749              452                       64   \n",
       "11           11             4066              474                       73   \n",
       "12           12             3852              453                       65   \n",
       "13           13             3977              479                       59   \n",
       "14           14             4132              522                       78   \n",
       "15           15             1361              167                       19   \n",
       "\n",
       "    page_token_count                                               text  \n",
       "0             743.75  Retrieval-Augmented Generation for Knowledge-I...  \n",
       "1            1138.50  The\u0003DiYine Comed\\\u0003(x) T QXeU\\ EQcRdeU T([) MIP...  \n",
       "2             919.50  by ✓ that generates a current token based on a...  \n",
       "3            1056.75  minimize the negative marginal log-likelihood ...  \n",
       "4            1137.75  MSMARCO as an open-domain abstractive QA task....  \n",
       "5            1028.75  Table 1: Open-Domain QA Test Scores. For TQA, ...  \n",
       "6            1109.25  Document 1: his works are considered classics ...  \n",
       "7             765.00  Table 4: Human assessments for the Jeopardy Qu...  \n",
       "8             994.00  General-Purpose Architectures for NLP Prior wo...  \n",
       "9             893.50  Broader Impact This work offers several positi...  \n",
       "10            937.25  55th Annual Meeting of the Association for Com...  \n",
       "11           1016.50  [19] Kelvin Guu, Tatsunori B. Hashimoto, Yonat...  \n",
       "12            963.00  [31] Kenton Lee, Ming-Wei Chang, and Kristina ...  \n",
       "13            994.25  [43] Tri Nguyen, Mir Rosenberg, Xia Song, Jian...  \n",
       "14           1033.00  [55] Sainbayar Sukhbaatar, Arthur Szlam, Jason...  \n",
       "15            340.25  International Workshop on Search-Oriented Conv...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(pages_and_texts)\n",
    "df.head(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_number</th>\n",
       "      <th>page_char_count</th>\n",
       "      <th>page_word_count</th>\n",
       "      <th>page_sentence_count_raw</th>\n",
       "      <th>page_token_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>16.00</td>\n",
       "      <td>16.00</td>\n",
       "      <td>16.00</td>\n",
       "      <td>16.00</td>\n",
       "      <td>16.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>7.50</td>\n",
       "      <td>3767.75</td>\n",
       "      <td>531.62</td>\n",
       "      <td>40.69</td>\n",
       "      <td>941.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.76</td>\n",
       "      <td>787.18</td>\n",
       "      <td>137.40</td>\n",
       "      <td>20.63</td>\n",
       "      <td>196.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.00</td>\n",
       "      <td>1361.00</td>\n",
       "      <td>167.00</td>\n",
       "      <td>14.00</td>\n",
       "      <td>340.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.75</td>\n",
       "      <td>3652.00</td>\n",
       "      <td>468.75</td>\n",
       "      <td>24.50</td>\n",
       "      <td>913.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7.50</td>\n",
       "      <td>3976.50</td>\n",
       "      <td>513.50</td>\n",
       "      <td>35.50</td>\n",
       "      <td>994.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>11.25</td>\n",
       "      <td>4155.75</td>\n",
       "      <td>630.50</td>\n",
       "      <td>60.25</td>\n",
       "      <td>1038.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>15.00</td>\n",
       "      <td>4554.00</td>\n",
       "      <td>725.00</td>\n",
       "      <td>78.00</td>\n",
       "      <td>1138.50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       page_number  page_char_count  page_word_count  page_sentence_count_raw  \\\n",
       "count        16.00            16.00            16.00                    16.00   \n",
       "mean          7.50          3767.75           531.62                    40.69   \n",
       "std           4.76           787.18           137.40                    20.63   \n",
       "min           0.00          1361.00           167.00                    14.00   \n",
       "25%           3.75          3652.00           468.75                    24.50   \n",
       "50%           7.50          3976.50           513.50                    35.50   \n",
       "75%          11.25          4155.75           630.50                    60.25   \n",
       "max          15.00          4554.00           725.00                    78.00   \n",
       "\n",
       "       page_token_count  \n",
       "count             16.00  \n",
       "mean             941.94  \n",
       "std              196.79  \n",
       "min              340.25  \n",
       "25%              913.00  \n",
       "50%              994.12  \n",
       "75%             1038.94  \n",
       "max             1138.50  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 所有統計數據\n",
    "df.describe().round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 把頁面分割成句子\n",
    "\n",
    "(可調整) 把滅分割成N組句子\n",
    "\n",
    "流程:\n",
    "\n",
    "`get文本 -> chunking -> 嵌入chunks -> embedding`\n",
    "\n",
    "分割文本成句子的2個方法：\n",
    "\n",
    "1. text.split(\". \") 在 \". \"處分割。\n",
    "2. 引用 spaCy 或 nltk 來分割句子\n",
    "\n",
    "分割成句子可以找出哪組句子在RAG中有幫助。\n",
    "\n",
    "使用 spaCy 將文本分割成句子，因為它比只使用 text.split(\". \") 更穩健。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[This is a sentence., This another sentence.]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from spacy.lang.en import English\n",
    "\n",
    "nlp = English()\n",
    "\n",
    "# 加入sentencizer\n",
    "nlp.add_pipe(\"sentencizer\")\n",
    "\n",
    "# Create a document instance as an example\n",
    "doc = nlp(\"This is a sentence. This another sentence.\")\n",
    "assert len(list(doc.sents)) == 2\n",
    "\n",
    "# 成功斷句\n",
    "list(doc.sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2ec07e6e20a41e1b27a7f29eca95e2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for item in tqdm(pages_and_texts):\n",
    "    item[\"sentences\"] = list(nlp(item[\"text\"]).sents)\n",
    "    \n",
    "    # Make sure all sentences are strings\n",
    "    item[\"sentences\"] = [str(sentence) for sentence in item[\"sentences\"]]\n",
    "    \n",
    "    # Count the sentences \n",
    "    item[\"page_sentence_count_spacy\"] = len(item[\"sentences\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'page_number': 5,\n",
       "  'page_char_count': 4115,\n",
       "  'page_word_count': 653,\n",
       "  'page_sentence_count_raw': 36,\n",
       "  'page_token_count': 1028.75,\n",
       "  'text': 'Table 1: Open-Domain QA Test Scores. For TQA, left column uses the standard test set for Open- Domain QA, right column uses the TQA-Wiki test set. See Appendix D for further details. Model NQ TQA WQ CT Closed Book T5-11B [52] 34.5 - /50.1 37.4 - T5-11B+SSM[52] 36.6 - /60.5 44.7 - Open Book REALM [20] 40.4 - / - 40.7 46.8 DPR [26] 41.5 57.9/ - 41.1 50.6 RAG-Token 44.1 55.2/66.1 45.5 50.0 RAG-Seq. 44.5 56.8/68.0 45.2 52.2 Table 2: Generation and classiﬁcation Test Scores. MS-MARCO SotA is [4], FEVER-3 is [68] and FEVER-2 is [57] *Uses gold context/evidence. Best model without gold access underlined. Model Jeopardy MSMARCO FVR3 FVR2 B-1 QB-1 R-L B-1 Label Acc. SotA - - 49.8* 49.9* 76.8 92.2* BART 15.1 19.7 38.2 41.6 64.0 81.1 RAG-Tok. 17.3 22.2 40.1 41.5 72.5 89.5 RAG-Seq. 14.7 21.4 40.8 44.2 to more effective marginalization over documents. Furthermore, RAG can generate correct answers even when the correct answer is not in any retrieved document, achieving 11.8% accuracy in such cases for NQ, where an extractive model would score 0%. 4.2 Abstractive Question Answering As shown in Table 2, RAG-Sequence outperforms BART on Open MS-MARCO NLG by 2.6 Bleu points and 2.6 Rouge-L points. RAG approaches state-of-the-art model performance, which is impressive given that (i) those models access gold passages with speciﬁc information required to generate the reference answer, (ii) many questions are unanswerable without the gold passages, and (iii) not all questions are answerable from Wikipedia alone. Table 3 shows some generated answers from our models. Qualitatively, we ﬁnd that RAG models hallucinate less and generate factually correct text more often than BART. Later, we also show that RAG generations are more diverse than BART generations (see §4.5). 4.3 Jeopardy Question Generation Table 2 shows that RAG-Token performs better than RAG-Sequence on Jeopardy question generation, with both models outperforming BART on Q-BLEU-1. Table 4 shows human evaluation results, over 452 pairs of generations from BART and RAG-Token. Evaluators indicated that BART was more factual than RAG in only 7.1% of cases, while RAG was more factual in 42.7% of cases, and both RAG and BART were factual in a further 17% of cases, clearly demonstrating the effectiveness of RAG on the task over a state-of-the-art generation model. Evaluators also ﬁnd RAG generations to be more speciﬁc by a large margin. Table 3 shows typical generations from each model. Jeopardy questions often contain two separate pieces of information, and RAG-Token may perform best because it can generate responses that combine content from several documents. Figure 2 shows an example. When generating “Sun”, the posterior is high for document 2 which mentions “The Sun Also Rises”. Similarly, document 1 dominates the posterior when “A Farewell to Arms” is generated. Intriguingly, after the ﬁrst token of each book is generated, the document posterior ﬂattens. This observation suggests that the generator can complete the titles without depending on speciﬁc documents. In other words, the model’s parametric knowledge is sufﬁcient to complete the titles. We ﬁnd evidence for this hypothesis by feeding the BART-only baseline with the partial decoding \"The Sun. BART completes the generation \"The Sun Also Rises\" is a novel by this author of \"The Sun Also Rises\" indicating the title \"The Sun Also Rises\" is stored in BART’s parameters. Similarly, BART will complete the partial decoding \"The Sun Also Rises\" is a novel by this author of \"A with \"The Sun Also Rises\" is a novel by this author of \"A Farewell to Arms\". This example shows how parametric and non-parametric memories work together—the non-parametric component helps to guide the generation, drawing out speciﬁc knowledge stored in the parametric memory. 4.4 Fact Veriﬁcation Table 2 shows our results on FEVER. For 3-way classiﬁcation, RAG scores are within 4.3% of state-of-the-art models, which are complex pipeline systems with domain-speciﬁc architectures and substantial engineering, trained using intermediate retrieval supervision, which RAG does not require. 6',\n",
       "  'sentences': ['Table 1: Open-Domain QA Test Scores.',\n",
       "   'For TQA, left column uses the standard test set for Open- Domain QA, right column uses the TQA-Wiki test set.',\n",
       "   'See Appendix D for further details.',\n",
       "   'Model NQ TQA WQ CT Closed Book T5-11B [52] 34.5 - /50.1 37.4 - T5-11B+SSM[52] 36.6 - /60.5 44.7 - Open Book REALM [20] 40.4 - / - 40.7 46.8 DPR [26] 41.5 57.9/ - 41.1 50.6 RAG-Token 44.1 55.2/66.1 45.5 50.0 RAG-Seq.',\n",
       "   '44.5 56.8/68.0 45.2 52.2 Table 2: Generation and classiﬁcation Test Scores.',\n",
       "   'MS-MARCO SotA is [4], FEVER-3 is [68] and FEVER-2 is [57] *Uses gold context/evidence.',\n",
       "   'Best model without gold access underlined.',\n",
       "   'Model Jeopardy MSMARCO FVR3 FVR2 B-1 QB-1 R-L B-1 Label Acc.',\n",
       "   'SotA - - 49.8* 49.9* 76.8 92.2* BART 15.1 19.7 38.2 41.6 64.0 81.1 RAG-Tok.',\n",
       "   '17.3 22.2 40.1 41.5 72.5 89.5 RAG-Seq.',\n",
       "   '14.7 21.4 40.8 44.2 to more effective marginalization over documents.',\n",
       "   'Furthermore, RAG can generate correct answers even when the correct answer is not in any retrieved document, achieving 11.8% accuracy in such cases for NQ, where an extractive model would score 0%.',\n",
       "   '4.2 Abstractive Question Answering As shown in Table 2, RAG-Sequence outperforms BART on Open MS-MARCO NLG by 2.6 Bleu points and 2.6 Rouge-L points.',\n",
       "   'RAG approaches state-of-the-art model performance, which is impressive given that (i) those models access gold passages with speciﬁc information required to generate the reference answer, (ii) many questions are unanswerable without the gold passages, and (iii) not all questions are answerable from Wikipedia alone.',\n",
       "   'Table 3 shows some generated answers from our models.',\n",
       "   'Qualitatively, we ﬁnd that RAG models hallucinate less and generate factually correct text more often than BART.',\n",
       "   'Later, we also show that RAG generations are more diverse than BART generations (see §4.5).',\n",
       "   '4.3 Jeopardy Question Generation Table 2 shows that RAG-Token performs better than RAG-Sequence on Jeopardy question generation, with both models outperforming BART on Q-BLEU-1.',\n",
       "   'Table 4 shows human evaluation results, over 452 pairs of generations from BART and RAG-Token.',\n",
       "   'Evaluators indicated that BART was more factual than RAG in only 7.1% of cases, while RAG was more factual in 42.7% of cases, and both RAG and BART were factual in a further 17% of cases, clearly demonstrating the effectiveness of RAG on the task over a state-of-the-art generation model.',\n",
       "   'Evaluators also ﬁnd RAG generations to be more speciﬁc by a large margin.',\n",
       "   'Table 3 shows typical generations from each model.',\n",
       "   'Jeopardy questions often contain two separate pieces of information, and RAG-Token may perform best because it can generate responses that combine content from several documents.',\n",
       "   'Figure 2 shows an example.',\n",
       "   'When generating “Sun”, the posterior is high for document 2 which mentions “The Sun Also Rises”.',\n",
       "   'Similarly, document 1 dominates the posterior when “A Farewell to Arms” is generated.',\n",
       "   'Intriguingly, after the ﬁrst token of each book is generated, the document posterior ﬂattens.',\n",
       "   'This observation suggests that the generator can complete the titles without depending on speciﬁc documents.',\n",
       "   'In other words, the model’s parametric knowledge is sufﬁcient to complete the titles.',\n",
       "   'We ﬁnd evidence for this hypothesis by feeding the BART-only baseline with the partial decoding \"The Sun.',\n",
       "   'BART completes the generation \"The Sun Also Rises\" is a novel by this author of \"The Sun Also Rises\" indicating the title \"The Sun Also Rises\" is stored in BART’s parameters.',\n",
       "   'Similarly, BART will complete the partial decoding \"The Sun Also Rises\" is a novel by this author of \"A with \"The Sun Also Rises\" is a novel by this author of \"A Farewell to Arms\".',\n",
       "   'This example shows how parametric and non-parametric memories work together—the non-parametric component helps to guide the generation, drawing out speciﬁc knowledge stored in the parametric memory.',\n",
       "   '4.4 Fact Veriﬁcation Table 2 shows our results on FEVER.',\n",
       "   'For 3-way classiﬁcation, RAG scores are within 4.3% of state-of-the-art models, which are complex pipeline systems with domain-speciﬁc architectures and substantial engineering, trained using intermediate retrieval supervision, which RAG does not require.',\n",
       "   '6'],\n",
       "  'page_sentence_count_spacy': 36}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 測試斷句\n",
    "random.sample(pages_and_texts, k=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "轉成DataFrame查看"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_number</th>\n",
       "      <th>page_char_count</th>\n",
       "      <th>page_word_count</th>\n",
       "      <th>page_sentence_count_raw</th>\n",
       "      <th>page_token_count</th>\n",
       "      <th>page_sentence_count_spacy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>16.00</td>\n",
       "      <td>16.00</td>\n",
       "      <td>16.00</td>\n",
       "      <td>16.00</td>\n",
       "      <td>16.00</td>\n",
       "      <td>16.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>7.50</td>\n",
       "      <td>3767.75</td>\n",
       "      <td>531.62</td>\n",
       "      <td>40.69</td>\n",
       "      <td>941.94</td>\n",
       "      <td>37.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.76</td>\n",
       "      <td>787.18</td>\n",
       "      <td>137.40</td>\n",
       "      <td>20.63</td>\n",
       "      <td>196.79</td>\n",
       "      <td>16.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.00</td>\n",
       "      <td>1361.00</td>\n",
       "      <td>167.00</td>\n",
       "      <td>14.00</td>\n",
       "      <td>340.25</td>\n",
       "      <td>16.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.75</td>\n",
       "      <td>3652.00</td>\n",
       "      <td>468.75</td>\n",
       "      <td>24.50</td>\n",
       "      <td>913.00</td>\n",
       "      <td>22.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7.50</td>\n",
       "      <td>3976.50</td>\n",
       "      <td>513.50</td>\n",
       "      <td>35.50</td>\n",
       "      <td>994.12</td>\n",
       "      <td>37.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>11.25</td>\n",
       "      <td>4155.75</td>\n",
       "      <td>630.50</td>\n",
       "      <td>60.25</td>\n",
       "      <td>1038.94</td>\n",
       "      <td>54.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>15.00</td>\n",
       "      <td>4554.00</td>\n",
       "      <td>725.00</td>\n",
       "      <td>78.00</td>\n",
       "      <td>1138.50</td>\n",
       "      <td>62.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       page_number  page_char_count  page_word_count  page_sentence_count_raw  \\\n",
       "count        16.00            16.00            16.00                    16.00   \n",
       "mean          7.50          3767.75           531.62                    40.69   \n",
       "std           4.76           787.18           137.40                    20.63   \n",
       "min           0.00          1361.00           167.00                    14.00   \n",
       "25%           3.75          3652.00           468.75                    24.50   \n",
       "50%           7.50          3976.50           513.50                    35.50   \n",
       "75%          11.25          4155.75           630.50                    60.25   \n",
       "max          15.00          4554.00           725.00                    78.00   \n",
       "\n",
       "       page_token_count  page_sentence_count_spacy  \n",
       "count             16.00                      16.00  \n",
       "mean             941.94                      37.62  \n",
       "std              196.79                      16.44  \n",
       "min              340.25                      16.00  \n",
       "25%              913.00                      22.75  \n",
       "50%              994.12                      37.00  \n",
       "75%             1038.94                      54.75  \n",
       "max             1138.50                      62.00  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(pages_and_texts)\n",
    "df.describe().round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4個句子/chunk -->取10個chunk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 將句子做Chunking\n",
    "\n",
    "embedding_model = `all-mpnet-base-v2` (容量=384Tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9825332d43214e229049d046bac76aaa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define split size to turn groups of sentences into chunks\n",
    "num_sentence_chunk_size = 10\n",
    "\n",
    "# Create a function that recursively splits a list into desired sizes\n",
    "def split_list(input_list: list, \n",
    "               slice_size: int) -> list[list[str]]:\n",
    "    \"\"\"\n",
    "    Splits the input_list into sublists of size slice_size (or as close as possible).\n",
    "\n",
    "    For example, a list of 17 sentences would be split into two lists of [[10], [7]]\n",
    "    \"\"\"\n",
    "    return [input_list[i:i + slice_size] for i in range(0, len(input_list), slice_size)]\n",
    "\n",
    "# Loop through pages and texts and split sentences into chunks\n",
    "for item in tqdm(pages_and_texts):\n",
    "    item[\"sentence_chunks\"] = split_list(input_list=item[\"sentences\"],\n",
    "                                         slice_size=num_sentence_chunk_size)\n",
    "    item[\"num_chunks\"] = len(item[\"sentence_chunks\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 查看chunking後結果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'page_number': 3,\n",
       "  'page_char_count': 4227,\n",
       "  'page_word_count': 681,\n",
       "  'page_sentence_count_raw': 35,\n",
       "  'page_token_count': 1056.75,\n",
       "  'text': 'minimize the negative marginal log-likelihood of each target, P j − log p(yj|xj) using stochastic gradient descent with Adam [28]. Updating the document encoder BERTd during training is costly as it requires the document index to be periodically updated as REALM does during pre-training [20]. We do not ﬁnd this step necessary for strong performance, and keep the document encoder (and index) ﬁxed, only ﬁne-tuning the query encoder BERTq and the BART generator. 2.5 Decoding At test time, RAG-Sequence and RAG-Token require different ways to approximate arg maxy p(y|x). RAG-Token The RAG-Token model can be seen as a standard, autoregressive seq2seq genera- tor with transition probability: p0 ✓(yi|x, y1:i−1) = P z2top-k(p(·|x)) p⌘(zi|x)p✓(yi|x, zi, y1:i−1) To decode, we can plug p0 ✓(yi|x, y1:i−1) into a standard beam decoder. RAG-Sequence For RAG-Sequence, the likelihood p(y|x) does not break into a conventional per- token likelihood, hence we cannot solve it with a single beam search. Instead, we run beam search for each document z, scoring each hypothesis using p✓(yi|x, z, y1:i−1). This yields a set of hypotheses Y , some of which may not have appeared in the beams of all documents. To estimate the probability of an hypothesis y we run an additional forward pass for each document z for which y does not appear in the beam, multiply generator probability with p⌘(z|x) and then sum the probabilities across beams for the marginals. We refer to this decoding procedure as “Thorough Decoding.” For longer output sequences, |Y | can become large, requiring many forward passes. For more efﬁcient decoding, we can make a further approximation that p✓(y|x, zi) ⇡ 0 where y was not generated during beam search from x, zi. This avoids the need to run additional forward passes once the candidate set Y has been generated. We refer to this decoding procedure as “Fast Decoding.” 3 Experiments We experiment with RAG in a wide range of knowledge-intensive tasks. For all experiments, we use a single Wikipedia dump for our non-parametric knowledge source. Following Lee et al. [31] and Karpukhin et al. [26], we use the December 2018 dump. Each Wikipedia article is split into disjoint 100-word chunks, to make a total of 21M documents. We use the document encoder to compute an embedding for each document, and build a single MIPS index using FAISS [23] with a Hierarchical Navigable Small World approximation for fast retrieval [37]. During training, we retrieve the top k documents for each query. We consider k 2 {5, 10} for training and set k for test time using dev data. We now discuss experimental details for each task. 3.1 Open-domain Question Answering Open-domain question answering (QA) is an important real-world application and common testbed for knowledge-intensive tasks [20]. We treat questions and answers as input-output text pairs (x, y) and train RAG by directly minimizing the negative log-likelihood of answers. We compare RAG to the popular extractive QA paradigm [5, 7, 31, 26], where answers are extracted spans from retrieved documents, relying primarily on non-parametric knowledge. We also compare to “Closed-Book QA” approaches [52], which, like RAG, generate answers, but which do not exploit retrieval, instead relying purely on parametric knowledge. We consider four popular open-domain QA datasets: Natural Questions (NQ) [29], TriviaQA (TQA) [24]. WebQuestions (WQ) [3] and CuratedTrec (CT) [2]. As CT and WQ are small, we follow DPR [26] by initializing CT and WQ models with our NQ RAG model. We use the same train/dev/test splits as prior work [31, 26] and report Exact Match (EM) scores. For TQA, to compare with T5 [52], we also evaluate on the TQA Wiki test set. 3.2 Abstractive Question Answering RAG models can go beyond simple extractive QA and answer questions with free-form, abstractive text generation. To test RAG’s natural language generation (NLG) in a knowledge-intensive setting, we use the MSMARCO NLG task v2.1 [43]. The task consists of questions, ten gold passages retrieved from a search engine for each question, and a full sentence answer annotated from the retrieved passages. We do not use the supplied passages, only the questions and answers, to treat 4',\n",
       "  'sentences': ['minimize the negative marginal log-likelihood of each target, P j − log p(yj|xj) using stochastic gradient descent with Adam [28].',\n",
       "   'Updating the document encoder BERTd during training is costly as it requires the document index to be periodically updated as REALM does during pre-training [20].',\n",
       "   'We do not ﬁnd this step necessary for strong performance, and keep the document encoder (and index) ﬁxed, only ﬁne-tuning the query encoder BERTq and the BART generator.',\n",
       "   '2.5 Decoding At test time, RAG-Sequence and RAG-Token require different ways to approximate arg maxy p(y|x).',\n",
       "   'RAG-Token The RAG-Token model can be seen as a standard, autoregressive seq2seq genera- tor with transition probability: p0 ✓(yi|x, y1:i−1) = P z2top-k(p(·|x)) p⌘(zi|x)p✓(yi|x, zi, y1:i−1) To decode, we can plug p0 ✓(yi|x, y1:i−1) into a standard beam decoder.',\n",
       "   'RAG-Sequence For RAG-Sequence, the likelihood p(y|x) does not break into a conventional per- token likelihood, hence we cannot solve it with a single beam search.',\n",
       "   'Instead, we run beam search for each document z, scoring each hypothesis using p✓(yi|x, z, y1:i−1).',\n",
       "   'This yields a set of hypotheses Y , some of which may not have appeared in the beams of all documents.',\n",
       "   'To estimate the probability of an hypothesis y we run an additional forward pass for each document z for which y does not appear in the beam, multiply generator probability with p⌘(z|x) and then sum the probabilities across beams for the marginals.',\n",
       "   'We refer to this decoding procedure as “Thorough Decoding.”',\n",
       "   'For longer output sequences, |Y | can become large, requiring many forward passes.',\n",
       "   'For more efﬁcient decoding, we can make a further approximation that p✓(y|x, zi) ⇡ 0 where y was not generated during beam search from x, zi.',\n",
       "   'This avoids the need to run additional forward passes once the candidate set Y has been generated.',\n",
       "   'We refer to this decoding procedure as “Fast Decoding.”',\n",
       "   '3 Experiments We experiment with RAG in a wide range of knowledge-intensive tasks.',\n",
       "   'For all experiments, we use a single Wikipedia dump for our non-parametric knowledge source.',\n",
       "   'Following Lee et al. [',\n",
       "   '31] and Karpukhin et al. [',\n",
       "   '26], we use the December 2018 dump.',\n",
       "   'Each Wikipedia article is split into disjoint 100-word chunks, to make a total of 21M documents.',\n",
       "   'We use the document encoder to compute an embedding for each document, and build a single MIPS index using FAISS [23] with a Hierarchical Navigable Small World approximation for fast retrieval [37].',\n",
       "   'During training, we retrieve the top k documents for each query.',\n",
       "   'We consider k 2 {5, 10} for training and set k for test time using dev data.',\n",
       "   'We now discuss experimental details for each task.',\n",
       "   '3.1 Open-domain Question Answering Open-domain question answering (QA) is an important real-world application and common testbed for knowledge-intensive tasks [20].',\n",
       "   'We treat questions and answers as input-output text pairs (x, y) and train RAG by directly minimizing the negative log-likelihood of answers.',\n",
       "   'We compare RAG to the popular extractive QA paradigm [5, 7, 31, 26], where answers are extracted spans from retrieved documents, relying primarily on non-parametric knowledge.',\n",
       "   'We also compare to “Closed-Book QA” approaches [52], which, like RAG, generate answers, but which do not exploit retrieval, instead relying purely on parametric knowledge.',\n",
       "   'We consider four popular open-domain QA datasets: Natural Questions (NQ) [29], TriviaQA (TQA) [24].',\n",
       "   'WebQuestions (WQ) [3] and CuratedTrec (CT) [2].',\n",
       "   'As CT and WQ are small, we follow DPR [26] by initializing CT and WQ models with our NQ RAG model.',\n",
       "   'We use the same train/dev/test splits as prior work [31, 26] and report Exact Match (EM) scores.',\n",
       "   'For TQA, to compare with T5 [52], we also evaluate on the TQA Wiki test set.',\n",
       "   '3.2 Abstractive Question Answering RAG models can go beyond simple extractive QA and answer questions with free-form, abstractive text generation.',\n",
       "   'To test RAG’s natural language generation (NLG) in a knowledge-intensive setting, we use the MSMARCO NLG task v2.1 [43].',\n",
       "   'The task consists of questions, ten gold passages retrieved from a search engine for each question, and a full sentence answer annotated from the retrieved passages.',\n",
       "   'We do not use the supplied passages, only the questions and answers, to treat 4'],\n",
       "  'page_sentence_count_spacy': 37,\n",
       "  'sentence_chunks': [['minimize the negative marginal log-likelihood of each target, P j − log p(yj|xj) using stochastic gradient descent with Adam [28].',\n",
       "    'Updating the document encoder BERTd during training is costly as it requires the document index to be periodically updated as REALM does during pre-training [20].',\n",
       "    'We do not ﬁnd this step necessary for strong performance, and keep the document encoder (and index) ﬁxed, only ﬁne-tuning the query encoder BERTq and the BART generator.',\n",
       "    '2.5 Decoding At test time, RAG-Sequence and RAG-Token require different ways to approximate arg maxy p(y|x).',\n",
       "    'RAG-Token The RAG-Token model can be seen as a standard, autoregressive seq2seq genera- tor with transition probability: p0 ✓(yi|x, y1:i−1) = P z2top-k(p(·|x)) p⌘(zi|x)p✓(yi|x, zi, y1:i−1) To decode, we can plug p0 ✓(yi|x, y1:i−1) into a standard beam decoder.',\n",
       "    'RAG-Sequence For RAG-Sequence, the likelihood p(y|x) does not break into a conventional per- token likelihood, hence we cannot solve it with a single beam search.',\n",
       "    'Instead, we run beam search for each document z, scoring each hypothesis using p✓(yi|x, z, y1:i−1).',\n",
       "    'This yields a set of hypotheses Y , some of which may not have appeared in the beams of all documents.',\n",
       "    'To estimate the probability of an hypothesis y we run an additional forward pass for each document z for which y does not appear in the beam, multiply generator probability with p⌘(z|x) and then sum the probabilities across beams for the marginals.',\n",
       "    'We refer to this decoding procedure as “Thorough Decoding.”'],\n",
       "   ['For longer output sequences, |Y | can become large, requiring many forward passes.',\n",
       "    'For more efﬁcient decoding, we can make a further approximation that p✓(y|x, zi) ⇡ 0 where y was not generated during beam search from x, zi.',\n",
       "    'This avoids the need to run additional forward passes once the candidate set Y has been generated.',\n",
       "    'We refer to this decoding procedure as “Fast Decoding.”',\n",
       "    '3 Experiments We experiment with RAG in a wide range of knowledge-intensive tasks.',\n",
       "    'For all experiments, we use a single Wikipedia dump for our non-parametric knowledge source.',\n",
       "    'Following Lee et al. [',\n",
       "    '31] and Karpukhin et al. [',\n",
       "    '26], we use the December 2018 dump.',\n",
       "    'Each Wikipedia article is split into disjoint 100-word chunks, to make a total of 21M documents.'],\n",
       "   ['We use the document encoder to compute an embedding for each document, and build a single MIPS index using FAISS [23] with a Hierarchical Navigable Small World approximation for fast retrieval [37].',\n",
       "    'During training, we retrieve the top k documents for each query.',\n",
       "    'We consider k 2 {5, 10} for training and set k for test time using dev data.',\n",
       "    'We now discuss experimental details for each task.',\n",
       "    '3.1 Open-domain Question Answering Open-domain question answering (QA) is an important real-world application and common testbed for knowledge-intensive tasks [20].',\n",
       "    'We treat questions and answers as input-output text pairs (x, y) and train RAG by directly minimizing the negative log-likelihood of answers.',\n",
       "    'We compare RAG to the popular extractive QA paradigm [5, 7, 31, 26], where answers are extracted spans from retrieved documents, relying primarily on non-parametric knowledge.',\n",
       "    'We also compare to “Closed-Book QA” approaches [52], which, like RAG, generate answers, but which do not exploit retrieval, instead relying purely on parametric knowledge.',\n",
       "    'We consider four popular open-domain QA datasets: Natural Questions (NQ) [29], TriviaQA (TQA) [24].',\n",
       "    'WebQuestions (WQ) [3] and CuratedTrec (CT) [2].'],\n",
       "   ['As CT and WQ are small, we follow DPR [26] by initializing CT and WQ models with our NQ RAG model.',\n",
       "    'We use the same train/dev/test splits as prior work [31, 26] and report Exact Match (EM) scores.',\n",
       "    'For TQA, to compare with T5 [52], we also evaluate on the TQA Wiki test set.',\n",
       "    '3.2 Abstractive Question Answering RAG models can go beyond simple extractive QA and answer questions with free-form, abstractive text generation.',\n",
       "    'To test RAG’s natural language generation (NLG) in a knowledge-intensive setting, we use the MSMARCO NLG task v2.1 [43].',\n",
       "    'The task consists of questions, ten gold passages retrieved from a search engine for each question, and a full sentence answer annotated from the retrieved passages.',\n",
       "    'We do not use the supplied passages, only the questions and answers, to treat 4']],\n",
       "  'num_chunks': 4}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample an example from the group (note: many samples have only 1 chunk as they have <=10 sentences total)\n",
    "random.sample(pages_and_texts, k=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 平均一頁有4.12個chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_number</th>\n",
       "      <th>page_char_count</th>\n",
       "      <th>page_word_count</th>\n",
       "      <th>page_sentence_count_raw</th>\n",
       "      <th>page_token_count</th>\n",
       "      <th>page_sentence_count_spacy</th>\n",
       "      <th>num_chunks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>16.00</td>\n",
       "      <td>16.00</td>\n",
       "      <td>16.00</td>\n",
       "      <td>16.00</td>\n",
       "      <td>16.00</td>\n",
       "      <td>16.00</td>\n",
       "      <td>16.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>7.50</td>\n",
       "      <td>3767.75</td>\n",
       "      <td>531.62</td>\n",
       "      <td>40.69</td>\n",
       "      <td>941.94</td>\n",
       "      <td>37.62</td>\n",
       "      <td>4.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.76</td>\n",
       "      <td>787.18</td>\n",
       "      <td>137.40</td>\n",
       "      <td>20.63</td>\n",
       "      <td>196.79</td>\n",
       "      <td>16.44</td>\n",
       "      <td>1.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.00</td>\n",
       "      <td>1361.00</td>\n",
       "      <td>167.00</td>\n",
       "      <td>14.00</td>\n",
       "      <td>340.25</td>\n",
       "      <td>16.00</td>\n",
       "      <td>2.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.75</td>\n",
       "      <td>3652.00</td>\n",
       "      <td>468.75</td>\n",
       "      <td>24.50</td>\n",
       "      <td>913.00</td>\n",
       "      <td>22.75</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7.50</td>\n",
       "      <td>3976.50</td>\n",
       "      <td>513.50</td>\n",
       "      <td>35.50</td>\n",
       "      <td>994.12</td>\n",
       "      <td>37.00</td>\n",
       "      <td>4.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>11.25</td>\n",
       "      <td>4155.75</td>\n",
       "      <td>630.50</td>\n",
       "      <td>60.25</td>\n",
       "      <td>1038.94</td>\n",
       "      <td>54.75</td>\n",
       "      <td>6.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>15.00</td>\n",
       "      <td>4554.00</td>\n",
       "      <td>725.00</td>\n",
       "      <td>78.00</td>\n",
       "      <td>1138.50</td>\n",
       "      <td>62.00</td>\n",
       "      <td>7.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       page_number  page_char_count  page_word_count  page_sentence_count_raw  \\\n",
       "count        16.00            16.00            16.00                    16.00   \n",
       "mean          7.50          3767.75           531.62                    40.69   \n",
       "std           4.76           787.18           137.40                    20.63   \n",
       "min           0.00          1361.00           167.00                    14.00   \n",
       "25%           3.75          3652.00           468.75                    24.50   \n",
       "50%           7.50          3976.50           513.50                    35.50   \n",
       "75%          11.25          4155.75           630.50                    60.25   \n",
       "max          15.00          4554.00           725.00                    78.00   \n",
       "\n",
       "       page_token_count  page_sentence_count_spacy  num_chunks  \n",
       "count             16.00                      16.00       16.00  \n",
       "mean             941.94                      37.62        4.12  \n",
       "std              196.79                      16.44        1.63  \n",
       "min              340.25                      16.00        2.00  \n",
       "25%              913.00                      22.75        3.00  \n",
       "50%              994.12                      37.00        4.00  \n",
       "75%             1038.94                      54.75        6.00  \n",
       "max             1138.50                      62.00        7.00  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a DataFrame to get stats\n",
    "df = pd.DataFrame(pages_and_texts)\n",
    "df.describe().round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 從 `page_and_text[]` 到 `page_and_chunks[]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8adc79cbe0f44f84a9a5b32ad5bdf4db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "66"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Split each chunk into its own item\n",
    "pages_and_chunks = []\n",
    "for item in tqdm(pages_and_texts):\n",
    "    for sentence_chunk in item[\"sentence_chunks\"]:\n",
    "        chunk_dict = {}\n",
    "        chunk_dict[\"page_number\"] = item[\"page_number\"]\n",
    "        \n",
    "        # Join the sentences together into a paragraph-like structure, aka a chunk (so they are a single string)\n",
    "        joined_sentence_chunk = \"\".join(sentence_chunk).replace(\"  \", \" \").strip()\n",
    "        joined_sentence_chunk = re.sub(r'\\.([A-Z])', r'. \\1', joined_sentence_chunk) # \".A\" -> \". A\" for any full-stop/capital letter combo \n",
    "        chunk_dict[\"sentence_chunk\"] = joined_sentence_chunk\n",
    "\n",
    "        # Get stats about the chunk\n",
    "        chunk_dict[\"chunk_char_count\"] = len(joined_sentence_chunk)\n",
    "        chunk_dict[\"chunk_word_count\"] = len([word for word in joined_sentence_chunk.split(\" \")])\n",
    "        chunk_dict[\"chunk_token_count\"] = len(joined_sentence_chunk) / 4 # 1 token = ~4 characters\n",
    "        \n",
    "        pages_and_chunks.append(chunk_dict)\n",
    "\n",
    "# 有幾個chunks?\n",
    "len(pages_and_chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 隨機查看某頁的某個chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'page_number': 15,\n",
       "  'sentence_chunk': 'Association for Computational Linguistics.doi: 10.18653/v1/D19-1253. URL https://www.aclweb.org/anthology/D19-1253. [68] Wanjun Zhong, Jingjing Xu, Duyu Tang, Zenan Xu, Nan Duan, Ming Zhou, Jiahai Wang, and Jian Yin. Reasoning over semantic-level graph for fact checking. ArXiv, abs/1909.03745, 2019. URL https://arxiv.org/abs/1909.03745.16',\n",
       "  'chunk_char_count': 340,\n",
       "  'chunk_word_count': 37,\n",
       "  'chunk_token_count': 85.0}]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "random.sample(pages_and_chunks, k=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### chunk的Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_number</th>\n",
       "      <th>chunk_char_count</th>\n",
       "      <th>chunk_word_count</th>\n",
       "      <th>chunk_token_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>66.00</td>\n",
       "      <td>66.00</td>\n",
       "      <td>66.00</td>\n",
       "      <td>66.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>8.41</td>\n",
       "      <td>911.61</td>\n",
       "      <td>127.85</td>\n",
       "      <td>227.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.36</td>\n",
       "      <td>447.55</td>\n",
       "      <td>73.90</td>\n",
       "      <td>111.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.00</td>\n",
       "      <td>109.00</td>\n",
       "      <td>14.00</td>\n",
       "      <td>27.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5.00</td>\n",
       "      <td>604.75</td>\n",
       "      <td>73.00</td>\n",
       "      <td>151.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>9.50</td>\n",
       "      <td>769.00</td>\n",
       "      <td>98.00</td>\n",
       "      <td>192.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>12.00</td>\n",
       "      <td>1175.75</td>\n",
       "      <td>180.50</td>\n",
       "      <td>293.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>15.00</td>\n",
       "      <td>2017.00</td>\n",
       "      <td>313.00</td>\n",
       "      <td>504.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       page_number  chunk_char_count  chunk_word_count  chunk_token_count\n",
       "count        66.00             66.00             66.00              66.00\n",
       "mean          8.41            911.61            127.85             227.90\n",
       "std           4.36            447.55             73.90             111.89\n",
       "min           0.00            109.00             14.00              27.25\n",
       "25%           5.00            604.75             73.00             151.19\n",
       "50%           9.50            769.00             98.00             192.25\n",
       "75%          12.00           1175.75            180.50             293.94\n",
       "max          15.00           2017.00            313.00             504.25"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get stats about our chunks\n",
    "df = pd.DataFrame(pages_and_chunks)\n",
    "df.describe().round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 檢查token數<=30的chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk token 內有: 27.25 | Text: 32nd AAAI Conference on Artiﬁcial Intelligence, AAAI 2018 ; Conference date: 02-02-2018 Through 07-02-2018.11\n",
      "Chunk token 內有: 27.25 | Text: 32nd AAAI Conference on Artiﬁcial Intelligence, AAAI 2018 ; Conference date: 02-02-2018 Through 07-02-2018.11\n",
      "Chunk token 內有: 27.25 | Text: 32nd AAAI Conference on Artiﬁcial Intelligence, AAAI 2018 ; Conference date: 02-02-2018 Through 07-02-2018.11\n",
      "Chunk token 內有: 27.25 | Text: 32nd AAAI Conference on Artiﬁcial Intelligence, AAAI 2018 ; Conference date: 02-02-2018 Through 07-02-2018.11\n",
      "Chunk token 內有: 27.25 | Text: 32nd AAAI Conference on Artiﬁcial Intelligence, AAAI 2018 ; Conference date: 02-02-2018 Through 07-02-2018.11\n"
     ]
    }
   ],
   "source": [
    "# Show random chunks with under 30 tokens in length\n",
    "min_token_length = 30\n",
    "for row in df[df[\"chunk_token_count\"] <= min_token_length].sample(5,replace=True).iterrows():\n",
    "    print(f'Chunk token 內有: {row[1][\"chunk_token_count\"]} | Text: {row[1][\"sentence_chunk\"]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通常token數<30的chunks都是header或是footer，把他們過濾掉"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'page_number': 0,\n",
       "  'sentence_chunk': 'Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks Patrick Lewis†‡, Ethan Perez?,Aleksandra Piktus†, Fabio Petroni†, Vladimir Karpukhin†, Naman Goyal†, Heinrich Küttler†, Mike Lewis†, Wen-tau Yih†, Tim Rocktäschel†‡, Sebastian Riedel†‡, Douwe Kiela† †Facebook AI Research; ‡University College London; ?New York University; plewis@fb.com Abstract Large pre-trained language models have been shown to store factual knowledge in their parameters, and achieve state-of-the-art results when ﬁne-tuned on down- stream NLP tasks. However, their ability to access and precisely manipulate knowledge is still limited, and hence on knowledge-intensive tasks, their perfor- mance lags behind task-speciﬁc architectures. Additionally, providing provenance for their decisions and updating their world knowledge remain open research prob- lems. Pre-trained models with a differentiable access mechanism to explicit non- parametric memory can overcome this issue, but have so far been only investigated for extractive downstream tasks. We explore a general-purpose ﬁne-tuning recipe for retrieval-augmented generation (RAG) — models which combine pre-trained parametric and non-parametric memory for language generation. We introduce RAG models where the parametric memory is a pre-trained seq2seq model and the non-parametric memory is a dense vector index of Wikipedia, accessed with a pre-trained neural retriever. We compare two RAG formulations, one which conditions on the same retrieved passages across the whole generated sequence, and another which can use different passages per token. We ﬁne-tune and evaluate our models on a wide range of knowledge-intensive NLP tasks and set the state of the art on three open domain QA tasks, outperforming parametric seq2seq models and task-speciﬁc retrieve-and-extract architectures.',\n",
       "  'chunk_char_count': 1833,\n",
       "  'chunk_word_count': 246,\n",
       "  'chunk_token_count': 458.25},\n",
       " {'page_number': 0,\n",
       "  'sentence_chunk': 'For language generation tasks, we ﬁnd that RAG models generate more speciﬁc, diverse and factual language than a state-of-the-art parametric-only seq2seq baseline.1 Introduction Pre-trained neural language models have been shown to learn a substantial amount of in-depth knowl- edge from data [47]. They can do so without any access to an external memory, as a parameterized implicit knowledge base [51, 52]. While this development is exciting, such models do have down- sides: They cannot easily expand or revise their memory, can’t straightforwardly provide insight into their predictions, and may produce “hallucinations” [38]. Hybrid models that combine parametric memory with non-parametric (i.e., retrieval-based) memories [20, 26, 48] can address some of these issues because knowledge can be directly revised and expanded, and accessed knowledge can be inspected and interpreted. REALM [20] and ORQA [31], two recently introduced models that combine masked language models [8] with a differentiable retriever, have shown promising results, 34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada.',\n",
       "  'chunk_char_count': 1139,\n",
       "  'chunk_word_count': 162,\n",
       "  'chunk_token_count': 284.75}]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pages_and_chunks_over_min_token_len = df[df[\"chunk_token_count\"] > min_token_length].to_dict(orient=\"records\")\n",
    "pages_and_chunks_over_min_token_len[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 實作Chunks的Embedding\n",
    "\n",
    "將我們的每個塊轉換成數字表示（一個嵌入向量，向量是按順序排列的數字序列）。\n",
    "\n",
    "使用 `sentence-transformers` 庫，此庫包含很多embedding_models。\n",
    "\n",
    "使用`all-mpnet-base-v2` 模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ailab\\anaconda3\\envs\\MYRAG\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\ailab\\anaconda3\\envs\\MYRAG\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: The Sentences Transformers library provides an easy and open-source way to create embeddings.\n",
      "Embedding: [-2.07981262e-02  3.03164721e-02 -2.01218110e-02  6.86483458e-02\n",
      " -2.55255401e-02 -8.47689249e-03 -2.07080549e-04 -6.32377267e-02\n",
      "  2.81606130e-02 -3.33353281e-02  3.02635022e-02  5.30720614e-02\n",
      " -5.03526330e-02  2.62288079e-02  3.33313793e-02 -4.51578870e-02\n",
      "  3.63044031e-02 -1.37112231e-03 -1.20171243e-02  1.14946552e-02\n",
      "  5.04510924e-02  4.70856987e-02  2.11912915e-02  5.14607430e-02\n",
      " -2.03746371e-02 -3.58889252e-02 -6.67838030e-04 -2.94393003e-02\n",
      "  4.95858938e-02 -1.05639631e-02 -1.52013665e-02 -1.31754903e-03\n",
      "  4.48197164e-02  1.56023102e-02  8.60379885e-07 -1.21394161e-03\n",
      " -2.37978324e-02 -9.09417809e-04  7.34483683e-03 -2.53928010e-03\n",
      "  5.23370244e-02 -4.68043461e-02  1.66214723e-02  4.71579023e-02\n",
      " -4.15599048e-02  9.01954074e-04  3.60278673e-02  3.42214704e-02\n",
      "  9.68227386e-02  5.94828576e-02 -1.64984502e-02 -3.51249799e-02\n",
      "  5.92516130e-03 -7.07989209e-04 -2.41031107e-02  3.49741019e-02\n",
      " -2.94746514e-02  6.04269095e-03 -9.80646536e-03  2.83217672e-02\n",
      " -1.85376108e-02  3.63213308e-02  1.30292708e-02 -3.71233113e-02\n",
      "  5.27256466e-02 -1.19706672e-02 -7.18082264e-02  1.24431262e-02\n",
      " -6.70566829e-03  7.42154717e-02  1.16357272e-02 -1.74533147e-02\n",
      " -1.82406045e-02 -1.88930258e-02  2.82414593e-02  1.32828830e-02\n",
      " -3.51909883e-02  8.87350005e-04  5.79572245e-02  3.22092883e-02\n",
      " -3.48585518e-03  4.13768403e-02  1.44357746e-02 -3.28044482e-02\n",
      " -9.79082752e-03 -3.16492841e-02  4.23871167e-02 -4.70847338e-02\n",
      " -2.08937302e-02 -1.91249400e-02 -1.22626871e-02  1.01605020e-02\n",
      "  3.91921885e-02 -2.61895619e-02  1.09028388e-02  1.35722766e-02\n",
      " -5.79267107e-02 -3.21499743e-02 -5.75724011e-03 -2.43516099e-02\n",
      "  5.23417369e-02  5.46126580e-03 -2.30996013e-02  2.57172855e-03\n",
      " -6.63345754e-02  3.54126282e-02 -1.03907324e-02  2.25409716e-02\n",
      " -1.84574295e-02 -2.42006071e-02 -4.78364788e-02 -4.79239039e-03\n",
      " -5.34138456e-02  3.01790852e-02 -1.56130511e-02 -5.51476069e-02\n",
      " -3.91874872e-02  5.92152663e-02 -3.47646438e-02  9.68119595e-03\n",
      "  2.13415492e-02  2.30417568e-02  1.91712342e-02  2.77378652e-02\n",
      " -7.73511780e-03  1.04445741e-02 -2.67720018e-02 -2.40199640e-02\n",
      " -1.92289483e-02  3.91500816e-03 -2.54714750e-02  3.61942835e-02\n",
      "  5.12866937e-02 -8.41695815e-03 -3.13829631e-02  1.47484085e-02\n",
      "  2.13939734e-02 -3.84901352e-02  2.01946255e-02  1.20766014e-02\n",
      " -3.12085077e-03  7.84028228e-03  3.30334948e-03 -4.94357347e-02\n",
      "  5.83886355e-02  3.26132006e-03  4.84489463e-03 -4.50681672e-02\n",
      "  2.45682765e-02  3.55427898e-02 -5.32505810e-02  9.21152756e-02\n",
      "  2.04395410e-02 -3.36952060e-02 -6.19804263e-02 -2.11038962e-02\n",
      "  7.82359838e-02  5.11908121e-02  5.93170859e-02 -1.25036444e-04\n",
      "  4.96349148e-02 -1.55722685e-02 -3.35674197e-03  1.82016008e-02\n",
      " -2.73444466e-02 -1.08771883e-02  1.41475871e-02  1.09877130e-02\n",
      "  4.32550628e-03  8.23311731e-02 -9.85416234e-04  7.58791044e-02\n",
      "  9.44998115e-03  2.37688031e-02  1.61929000e-02  6.24994077e-02\n",
      "  4.75921743e-02 -3.92626692e-03  9.07524824e-02  4.49874178e-02\n",
      " -3.47131230e-02  2.14077458e-02 -3.35604437e-02  4.93849814e-02\n",
      "  1.08670453e-02  2.63447464e-02 -3.26089300e-02  8.00303668e-02\n",
      "  9.29764938e-03  7.16571510e-03 -2.79172212e-02 -3.06820776e-02\n",
      "  4.01059166e-03 -4.93906550e-02 -3.13776149e-03  4.00537625e-02\n",
      " -3.97855155e-02  5.48014380e-02  1.36244753e-05 -8.38373825e-02\n",
      " -1.21547459e-02  3.40950340e-02  3.22401244e-03  6.11846559e-02\n",
      "  5.60066663e-02  9.62878391e-03  2.54615992e-02 -4.64168750e-02\n",
      " -3.98899764e-02  7.68132955e-02  2.28408761e-02 -2.26567537e-02\n",
      " -1.91192906e-02 -6.53027892e-02  4.56781089e-02 -4.43655578e-03\n",
      "  1.49632050e-02 -2.15077978e-02  2.74244370e-03  1.90358665e-02\n",
      "  5.91888353e-02 -2.47569308e-02  3.66144851e-02  5.63083775e-02\n",
      " -8.86445306e-03 -1.74324661e-02 -1.03283639e-03  2.47667152e-02\n",
      "  1.30762896e-02  5.04632927e-02 -5.28499065e-03  5.92396632e-02\n",
      "  6.29906580e-02 -4.36783582e-02 -4.97831106e-02  5.56297190e-02\n",
      " -2.44854391e-02 -8.26755315e-02  2.04911176e-02 -1.06446341e-01\n",
      "  6.64840918e-03  2.97303833e-02 -2.36440562e-02 -8.84609297e-03\n",
      "  2.45557376e-03 -3.35234776e-02  7.52212331e-02 -5.89880012e-02\n",
      " -3.67807858e-02  3.41542289e-02  5.41131049e-02 -1.74904671e-02\n",
      "  1.33920247e-02  4.71681990e-02  1.46117127e-02 -2.12310757e-02\n",
      " -6.55338913e-02  1.23857502e-02  2.76074745e-02 -8.02161358e-03\n",
      " -4.59636562e-02 -8.22445657e-03  9.16954130e-03 -1.56398602e-02\n",
      "  7.54616829e-03  1.58315548e-03 -3.03959120e-02 -5.10670878e-02\n",
      "  1.96313486e-02  1.26263155e-02 -1.51738967e-03  2.02890728e-02\n",
      "  1.37817673e-02  1.49110416e-02  2.50766668e-02 -3.62870283e-02\n",
      "  1.08084828e-02  2.74135452e-03  1.81510448e-02  5.39872684e-02\n",
      " -4.74542119e-02 -4.28731553e-02 -2.89914440e-02  2.13234853e-02\n",
      " -3.85161266e-02  6.31922111e-02 -5.77975661e-02  3.77891934e-03\n",
      " -2.54394524e-02 -1.77179027e-04  9.08244494e-03  1.59095135e-02\n",
      "  4.11799178e-02 -3.94369215e-02 -9.64432582e-03  1.30792409e-02\n",
      "  6.87962249e-02  4.32193168e-02  7.54074485e-04  6.77741840e-02\n",
      "  4.93705980e-02 -3.47818807e-03 -1.06054591e-02  6.72492757e-03\n",
      " -1.39062125e-02  4.88276407e-02 -1.05736265e-02  3.50226834e-03\n",
      "  2.90220859e-03  2.40044594e-02  1.20272217e-02 -2.09796708e-02\n",
      " -2.39112489e-02  3.26579474e-02 -1.01324474e-03 -5.92755107e-03\n",
      " -7.40534440e-03  3.63141717e-03 -2.26698723e-02 -2.21242420e-02\n",
      "  3.86995934e-02  1.72322076e-02  3.85921448e-02 -5.04711270e-02\n",
      " -3.42144929e-02 -4.00443003e-02 -3.57910767e-02 -4.62560840e-02\n",
      "  6.70231953e-02 -4.61645704e-03 -3.29679390e-03  2.08444428e-02\n",
      " -5.14255464e-03 -5.00850379e-02  2.22504325e-02  4.66933250e-02\n",
      "  1.36208395e-02  1.77530646e-02  4.28083073e-03 -2.79332399e-02\n",
      " -1.93421282e-02 -3.87860686e-02 -3.09555531e-02 -6.64133802e-02\n",
      " -1.13434019e-02  1.64267216e-02  1.77629609e-02 -2.28226511e-03\n",
      " -3.30088735e-02 -1.36266602e-03 -2.17934307e-02 -2.67508999e-02\n",
      " -1.26375835e-02  1.61864504e-03 -4.95673046e-02  7.85445049e-02\n",
      "  4.10962477e-02  9.65922140e-03 -1.14643276e-02  1.68852753e-03\n",
      "  5.37663475e-02  2.05535418e-03 -4.11201045e-02  1.46330306e-02\n",
      " -3.75564098e-02 -3.35689113e-02  5.19258436e-03 -6.33089095e-02\n",
      "  3.32964137e-02  8.76124762e-03  1.33859098e-03 -3.95751186e-03\n",
      " -1.61678120e-02  8.26747194e-02  4.75944430e-02 -3.43055427e-02\n",
      "  2.50881594e-02 -3.50975767e-02  3.68657447e-02  4.12655994e-03\n",
      "  4.16018143e-02 -1.35181770e-01 -4.76337522e-02 -1.20025445e-02\n",
      " -3.48891728e-02  3.25454548e-02 -2.93573132e-03 -4.85059386e-03\n",
      " -1.04223765e-01  2.78610811e-02  1.41570186e-02  3.94396372e-02\n",
      " -3.88806164e-02 -1.42463427e-02 -5.19984365e-02  8.92738532e-03\n",
      " -1.99771449e-02 -2.51724925e-02 -3.41300443e-02  1.93041395e-02\n",
      " -5.20207584e-02 -6.71999976e-02 -9.46363900e-03 -1.25586509e-03\n",
      " -5.66048399e-02  2.62097940e-02  9.91585664e-03  4.38286811e-02\n",
      "  2.26635276e-03 -3.11896428e-02 -6.25468045e-02 -3.87793072e-02\n",
      " -6.83938861e-02  4.93722670e-02  5.85507825e-02 -4.08730060e-02\n",
      " -1.98638570e-02 -2.12634858e-02  4.98036928e-02 -4.51748110e-02\n",
      " -2.37141512e-02  2.32674833e-02  1.00594774e-01  9.87115223e-03\n",
      " -1.38014741e-02 -5.21041304e-02  9.08212457e-03  1.72427595e-02\n",
      "  5.91432601e-02  2.62337197e-02 -7.04642991e-03 -1.50032174e-02\n",
      " -3.76661844e-03  6.28263643e-03 -5.23982048e-02 -4.96638902e-02\n",
      "  3.06610893e-02 -3.33648990e-03  2.34911293e-02 -8.58829916e-02\n",
      " -4.62449715e-02  5.59701286e-02  3.09092458e-04  2.01729126e-02\n",
      " -2.98067182e-03  1.76645033e-02  1.54669471e-02 -7.41718337e-02\n",
      "  7.34986225e-03 -1.05014611e-02  2.45247371e-02  1.36878574e-02\n",
      " -1.17803570e-02  4.51543927e-02  3.29039358e-02 -3.50393588e-03\n",
      " -2.71315444e-02 -5.27364910e-02 -4.60164584e-02  2.22850237e-02\n",
      "  2.62272414e-02  5.56151196e-03  1.45788398e-02 -2.97145043e-02\n",
      "  3.57042514e-02  2.22534463e-02  3.89618166e-02 -7.92634636e-02\n",
      " -9.01089329e-03  2.19012834e-02 -5.49061503e-03  8.69963132e-03\n",
      "  4.33030799e-02 -2.12631524e-02  1.13292458e-02 -6.33699149e-02\n",
      "  3.63723487e-02  2.67442744e-02 -6.64251745e-02  1.70499869e-02\n",
      " -2.79691759e-02  2.36358750e-03 -1.81953628e-02  1.52955223e-02\n",
      " -8.50431528e-03  1.16648311e-02 -9.75921899e-02 -2.92093530e-02\n",
      " -5.42547107e-02  3.61234695e-02  3.25116329e-02  8.26972537e-03\n",
      " -2.96536396e-04  1.11556128e-02 -3.85188535e-02  2.36161426e-02\n",
      "  9.85921361e-03  5.73998019e-02  4.86060232e-02 -1.37579935e-02\n",
      " -6.19215937e-03  1.11972857e-02 -3.37175131e-02 -1.10515337e-02\n",
      " -7.08333328e-02 -1.01816235e-02 -3.66010517e-02 -1.55561352e-02\n",
      " -2.13110112e-02 -1.02760177e-02 -4.35734205e-02  5.55186532e-02\n",
      " -3.76547836e-02  5.29252104e-02 -3.45224030e-02 -2.43008276e-03\n",
      "  7.25553334e-02  4.45070071e-03  4.71416488e-02 -9.43879504e-03\n",
      " -1.98978167e-02  5.71899451e-02  8.60540196e-02 -5.25058024e-02\n",
      " -1.39550539e-02  1.17373336e-02  1.33974366e-02 -4.73052710e-02\n",
      " -5.41673973e-02  4.62725610e-02 -2.58970819e-02  1.51415607e-02\n",
      "  3.38944830e-02 -3.78252752e-03 -5.76043054e-02 -1.60082374e-02\n",
      "  2.42737886e-02  3.37359868e-02 -1.96820758e-02 -2.53464114e-02\n",
      " -4.75617424e-02 -5.68755679e-02 -2.28193607e-02  3.83186489e-02\n",
      " -1.78330690e-02  1.35963429e-02  7.85977114e-04  9.74011887e-03\n",
      "  3.34298760e-02 -2.60133985e-02 -7.38572562e-03  3.56451012e-02\n",
      " -2.68532522e-02 -7.53624141e-02 -2.66983788e-02 -4.46457714e-33\n",
      " -3.31646055e-02  1.41704194e-02 -3.92909534e-02 -3.46318670e-02\n",
      " -5.88678056e-03 -1.18212393e-02  1.53951468e-02  1.18474020e-02\n",
      "  1.07757859e-02  3.62141021e-02  7.87952915e-03 -2.31844969e-02\n",
      "  1.07623311e-02  1.72346123e-02  9.54192423e-04  2.83640698e-02\n",
      "  2.37420145e-02 -1.48057425e-02  1.24191958e-03  3.52353090e-03\n",
      "  2.33735349e-02  5.58307953e-02  5.38328327e-02 -3.74078378e-02\n",
      " -2.11805124e-02  1.52705179e-04 -7.27785612e-03  5.50559862e-03\n",
      "  3.05824354e-02  4.54633571e-02 -3.35786715e-02  3.16142663e-02\n",
      " -2.56392756e-03  3.96354869e-02 -1.47572970e-02  5.67167178e-02\n",
      " -5.62787689e-02 -5.04601933e-03  3.56154703e-02 -2.76198704e-02\n",
      " -2.32292190e-02 -4.63292897e-02 -3.70919406e-02 -4.23189327e-02\n",
      "  3.70305777e-02  7.88716506e-03  3.85176502e-02  1.74770551e-03\n",
      "  5.62762795e-03  6.18099002e-03 -6.90268949e-02 -9.42972489e-03\n",
      " -7.74678309e-03  1.68349817e-02  1.22767044e-02  2.26406865e-02\n",
      "  1.21009108e-02  1.11743696e-02  1.21538918e-02 -1.16861835e-02\n",
      " -4.41612378e-02  2.30048280e-02  2.20671576e-02 -5.87504767e-02\n",
      " -3.96428443e-02  6.83135241e-02 -3.29947509e-02 -3.66773866e-02\n",
      " -3.53655107e-02  1.76185165e-02  6.95639802e-03  5.92692271e-02\n",
      "  4.12156209e-02  7.98109695e-02 -5.36564505e-03  1.14238169e-02\n",
      " -2.96388790e-02 -1.15411459e-02  2.22812053e-02  7.93187879e-03\n",
      "  2.60356553e-02  1.28211239e-02  1.71346087e-02 -6.90190867e-03\n",
      " -1.07603576e-02  1.35715222e-02 -9.90742934e-04 -6.16075248e-02\n",
      "  4.40513380e-02 -8.26544128e-04 -2.78340895e-02 -1.23619679e-02\n",
      "  1.34629374e-02 -3.85745317e-02  1.08699338e-03  2.18712855e-02\n",
      " -3.32398452e-02  1.84615478e-02 -5.10103023e-03  3.74665149e-02\n",
      " -3.67544033e-03 -2.19246112e-02 -4.96483222e-03 -9.59823374e-03\n",
      "  2.33591106e-02  1.04876505e-02  4.38721851e-02 -1.51424212e-02\n",
      " -6.30309731e-02  8.23257677e-03 -1.09131094e-02 -4.06409539e-02\n",
      " -6.21690638e-02  2.21326109e-02 -2.71434281e-02  4.05539833e-02\n",
      " -8.09454639e-03 -1.76406594e-03  3.01526096e-02 -5.42268204e-03\n",
      " -4.69821505e-02 -1.73767935e-02  4.11631167e-02  3.20635997e-02\n",
      " -2.22943835e-02 -1.58162024e-02 -4.50720936e-02  5.69486842e-02\n",
      "  4.71596196e-02 -5.78058846e-02  1.32474815e-02 -4.71288525e-03\n",
      "  1.66824535e-07  4.81090471e-02  5.03628142e-02  5.45264110e-02\n",
      "  2.07568742e-02 -1.19080972e-02 -6.37493236e-03  5.26369456e-03\n",
      "  7.21948817e-02 -2.21763048e-02  2.20103059e-02 -9.90453991e-04\n",
      " -1.37163354e-02  6.89209811e-03  2.46912278e-02 -1.39462054e-01\n",
      "  2.56981212e-03 -4.64827679e-02 -4.04967405e-02 -6.08555935e-02\n",
      " -1.53212855e-02  1.36129886e-01  9.45034847e-02  4.25741486e-02\n",
      "  4.67131063e-02 -2.30677892e-02 -1.20965848e-02  3.86673249e-02\n",
      "  2.11654534e-03 -2.51473151e-02 -1.15076220e-02 -3.46506536e-02\n",
      " -2.29534023e-02 -6.33849716e-03 -3.05175968e-02 -1.56236393e-02\n",
      "  1.39514022e-02  3.27446032e-04  2.00329977e-03  4.15108446e-03\n",
      " -2.22924910e-02 -3.62589695e-02 -2.36579049e-02 -1.87817588e-02\n",
      " -1.96288805e-02  4.52125780e-02 -8.12569261e-02 -2.14569271e-02\n",
      " -4.41542715e-02 -2.68476214e-02  2.01974213e-02  2.82995263e-03\n",
      " -1.95011478e-02 -3.45331505e-02  2.26913486e-02  3.78325582e-02\n",
      " -1.02544222e-02 -2.19748542e-03 -8.96744430e-02 -4.50030975e-02\n",
      "  8.09704512e-03 -2.05805749e-02 -2.02998333e-02 -2.09922120e-02\n",
      " -1.79405063e-02  5.81897385e-02 -7.63657177e-03  1.50847342e-02\n",
      "  1.78279767e-34  4.86179404e-02  4.22228537e-02  4.71596457e-02\n",
      "  5.89047186e-02  3.99784818e-02 -5.27070947e-02  1.56905726e-02\n",
      " -5.25146665e-04  1.13652116e-02 -6.56410754e-02 -2.20849160e-02]\n",
      "\n",
      "Sentence: Sentences can be embedded one by one or as a list of strings.\n",
      "Embedding: [ 4.31717895e-02 -5.38701080e-02 -3.78044546e-02  4.27235663e-02\n",
      " -2.35409290e-02  3.44861299e-02  2.89587025e-02  1.92818046e-03\n",
      "  2.41732895e-02 -3.17011997e-02  7.32856095e-02  1.25589753e-02\n",
      "  3.64621021e-02 -2.05252022e-02  2.81973723e-02 -6.87329695e-02\n",
      "  4.22230847e-02  9.31720308e-04  3.54035422e-02  1.41787110e-02\n",
      "  7.83993397e-03  2.31179539e-02 -4.84742224e-03  1.07173957e-02\n",
      "  4.39494010e-03  5.47802029e-03 -3.80338654e-02 -3.05488729e-03\n",
      "  5.72235743e-03 -6.78213909e-02 -4.88007888e-02 -1.45032275e-02\n",
      "  6.68005226e-03 -7.17479661e-02  1.64644894e-06  1.07564135e-02\n",
      " -3.60922292e-02 -2.37057284e-02 -5.22791967e-02  3.46110649e-02\n",
      " -5.42175211e-03  1.62611008e-02  1.96564700e-02  2.25395467e-02\n",
      " -2.25997414e-03  4.06342372e-02  8.17157924e-02  2.48179454e-02\n",
      "  5.31884544e-02  7.82715231e-02 -1.91813298e-02 -1.94087271e-02\n",
      " -2.62805503e-02 -2.44083814e-02  5.49405590e-02  1.90319028e-02\n",
      "  1.60810929e-02 -2.68895533e-02 -8.24690703e-03  7.33444020e-02\n",
      "  1.00122988e-02  2.93315779e-02  3.42864054e-03 -2.13270094e-02\n",
      " -1.62445463e-03 -5.56256622e-03 -7.64880106e-02 -5.85450530e-02\n",
      " -2.82272100e-02  7.51855178e-03  7.11225942e-02  1.95452478e-03\n",
      "  5.45927184e-03  3.22314049e-03  5.12799956e-02 -3.54105830e-02\n",
      " -5.03608771e-02  4.70519587e-02  5.15474146e-03  1.52287195e-02\n",
      " -1.06680887e-02  3.16299014e-02 -9.09037422e-03 -4.01326977e-02\n",
      " -4.35235836e-02 -1.94969624e-02  1.65604949e-02 -4.71168458e-02\n",
      " -3.92091647e-02 -3.07756905e-02 -2.94167213e-02 -4.20826413e-02\n",
      "  2.27071485e-03 -2.78329439e-02  1.69421863e-02  7.74500007e-03\n",
      " -5.23741581e-02 -4.50039618e-02  3.83605845e-02 -4.90786806e-02\n",
      "  5.06618619e-02  1.01615032e-02 -1.25022056e-02 -4.64552781e-03\n",
      " -1.54539747e-02  1.58862136e-02  1.18369646e-02 -3.59232873e-02\n",
      " -7.76226074e-02  3.43358815e-02 -2.14709770e-02 -6.86098710e-02\n",
      " -5.46235666e-02  7.83901364e-02 -3.00702974e-02 -3.37549970e-02\n",
      " -4.04999033e-02  4.80515063e-02  9.53902490e-03  2.31399201e-02\n",
      " -8.16115513e-02 -6.51691528e-03  1.54213095e-02  7.04257190e-02\n",
      " -1.25068882e-02 -2.48266459e-02 -1.71329100e-02  6.13108417e-03\n",
      "  5.44412844e-02 -1.40566230e-02 -6.24516234e-03  3.65787670e-02\n",
      "  7.36230314e-02 -6.05683168e-03 -3.61630172e-02 -1.42200012e-03\n",
      "  4.43165563e-02 -3.14518251e-03  3.18767764e-02 -1.30947940e-02\n",
      " -3.69524844e-02 -4.98030521e-03  1.30017078e-03 -2.05213502e-02\n",
      "  2.06277650e-02  5.93870925e-03 -3.07158381e-03 -3.97513025e-02\n",
      "  4.29889709e-02  6.49802014e-02 -6.76022395e-02  5.41655235e-02\n",
      "  1.52564235e-03 -3.72908562e-02 -4.02426831e-02 -2.28771642e-02\n",
      "  1.31769776e-01  4.87874215e-03  1.39470864e-02  4.92436066e-02\n",
      "  2.49219537e-02 -8.76091234e-03 -5.38766198e-03 -2.65595149e-02\n",
      " -1.19766667e-02 -2.32006516e-02 -2.67433934e-02  5.66912163e-03\n",
      "  2.21721604e-02  4.67294380e-02 -5.78486957e-02  8.22120234e-02\n",
      " -3.36837210e-03  8.09646845e-02  1.41423587e-02  1.02393106e-01\n",
      " -5.76838432e-03 -1.15876850e-02  4.90584895e-02  5.87830022e-02\n",
      "  6.50030598e-02  4.74621654e-02 -2.89464016e-02 -1.76579924e-03\n",
      "  3.32561135e-02  2.91198082e-02  6.03811927e-02  3.73513583e-04\n",
      "  1.06575768e-02 -5.96284419e-02 -7.28600919e-02  2.95080245e-02\n",
      "  9.54460539e-03 -2.71541420e-02 -5.63305356e-02  9.66666965e-04\n",
      " -4.77729067e-02  4.67576757e-02  4.87256050e-03 -6.57520071e-02\n",
      " -1.42248413e-02  3.99872921e-02 -1.09798089e-02  7.68942684e-02\n",
      " -4.00003791e-02  2.96826400e-02  2.81303693e-02 -5.55424765e-02\n",
      "  6.31273538e-03  5.00450581e-02  1.89884417e-02  5.38683869e-02\n",
      " -1.95981152e-02  1.08601013e-02  1.64150726e-02  1.44135281e-02\n",
      "  1.71448719e-02  2.17624661e-02 -4.98863570e-02  1.56105934e-02\n",
      "  4.83735930e-03  1.87053606e-02 -3.18550295e-03  2.66863350e-02\n",
      "  5.55552505e-02 -4.88005653e-02 -3.02929152e-02  2.52110381e-02\n",
      "  1.07264752e-02  1.88270379e-02 -1.50688253e-02  3.43831889e-02\n",
      "  4.15124819e-02  1.37788774e-02 -5.54848202e-02  1.43848211e-02\n",
      " -5.88139556e-02 -6.01676367e-02  2.69856174e-02 -5.46130501e-02\n",
      "  8.14632885e-03 -1.17758522e-02  1.57442074e-02  1.43904262e-03\n",
      " -2.64554415e-02 -4.48877215e-02  4.39732820e-02 -1.06171581e-04\n",
      " -2.25905441e-02  3.00296415e-02  1.97440721e-02  7.44072441e-03\n",
      " -1.93790104e-02  8.09794012e-03  4.34860364e-02 -1.08538719e-04\n",
      " -3.77225690e-02  2.67196130e-02 -4.63157706e-02 -1.53400644e-03\n",
      "  8.05306621e-03 -4.30901684e-02 -2.13848744e-02  1.20185344e-02\n",
      "  8.41401611e-03  2.48270598e-03 -3.09566222e-02 -9.05277655e-02\n",
      " -4.76694256e-02  1.22606335e-02 -1.36466846e-02 -2.63654906e-02\n",
      " -7.65548786e-03  8.72375723e-03  2.65724547e-02  8.40094115e-04\n",
      " -5.55932522e-03 -9.29540955e-03  3.19337584e-02  5.94646409e-02\n",
      "  1.83205865e-02 -7.56546855e-02 -5.59389368e-02 -1.20871309e-02\n",
      " -3.16260643e-02  3.62187065e-02  7.53609883e-03 -6.15654178e-02\n",
      " -2.30458919e-02 -3.51675437e-03  1.23331901e-02 -9.67642665e-03\n",
      "  4.96861488e-02 -8.42256844e-02  1.52396038e-02 -1.82445236e-02\n",
      "  7.70462230e-02  9.28718522e-02  4.03725952e-02  1.11732624e-01\n",
      " -1.03270672e-02 -2.54558697e-02  2.13153772e-02 -1.16187357e-03\n",
      "  2.82597076e-03  5.06967157e-02 -3.13697234e-02 -8.14278051e-03\n",
      "  1.38387224e-02  4.66889516e-02  5.09671345e-02  3.77154090e-02\n",
      " -2.94988789e-02  3.60631943e-02 -2.61166180e-03  2.72212870e-04\n",
      " -6.71807304e-02 -6.54026344e-02 -3.43590714e-02  1.91067960e-02\n",
      "  4.13293839e-02 -1.10970698e-02  4.51952368e-02 -5.93564920e-02\n",
      "  1.06963813e-02 -1.82229411e-02 -5.65814190e-02  1.20387180e-02\n",
      "  4.44774777e-02  1.87049527e-02  1.63810086e-02  5.51151186e-02\n",
      " -2.23332271e-02  2.12861691e-02 -1.20339524e-02  3.26752774e-02\n",
      "  1.47003857e-02 -8.16681050e-03  1.12904217e-02 -3.00620571e-02\n",
      " -2.34345272e-02 -2.68646348e-02 -1.28718384e-03 -7.67189935e-02\n",
      "  2.22607842e-03 -5.89482998e-03  2.63103656e-02  2.07129214e-03\n",
      " -6.91152140e-02 -1.43792592e-02  2.68788449e-02 -3.51540111e-02\n",
      " -2.69612093e-02  2.54716724e-03 -6.48881197e-02  3.18728052e-02\n",
      "  1.70126893e-02 -4.54004332e-02 -1.80615876e-02 -1.61116756e-02\n",
      "  5.70773333e-02 -2.78268708e-03 -6.45585954e-02  7.86598325e-02\n",
      "  2.29075905e-02  6.81843469e-03 -9.11737513e-03 -2.27726493e-02\n",
      " -4.76526171e-02  4.88430932e-02 -2.09891330e-02 -2.43694056e-02\n",
      " -5.01210243e-03  6.70254007e-02  6.91369316e-03  2.25843005e-02\n",
      "  2.51125470e-02 -6.92503760e-03  8.59400630e-03  2.38977242e-02\n",
      "  3.29738334e-02 -1.05310582e-01  1.22094452e-02 -1.22263879e-02\n",
      " -5.73768727e-02  1.84311401e-02  2.97157634e-02 -6.09429367e-02\n",
      " -6.55256286e-02  3.55712920e-02  5.64321736e-03  3.34644667e-03\n",
      " -3.59686315e-02 -8.83415993e-03 -6.97894990e-02  6.89779446e-02\n",
      " -4.88216570e-03  2.23995093e-02 -3.16054113e-02 -7.41183385e-03\n",
      "  3.19351405e-02 -5.18788770e-02  2.11601872e-02 -5.03339842e-02\n",
      "  9.10577085e-03  2.13354249e-02  1.66838225e-02  3.49020176e-02\n",
      " -6.38500229e-02 -6.75630337e-03 -1.27405291e-02 -4.63366993e-02\n",
      " -1.14779584e-02  2.08778810e-02  2.44822465e-02  3.66463605e-03\n",
      " -2.86100199e-03  2.29389556e-02  2.13745795e-02 -3.48900743e-02\n",
      " -3.00388075e-02  4.78870273e-02  5.83370365e-02 -9.70498752e-03\n",
      "  1.38233965e-02 -3.27485539e-02 -8.11400882e-04  9.54227429e-03\n",
      "  1.20401718e-02  1.97230522e-02 -4.74874425e-04 -1.39226075e-02\n",
      " -5.21069951e-02 -1.75592359e-02 -5.41699082e-02 -1.17970007e-02\n",
      " -1.71030276e-02 -3.50194871e-02  3.38661410e-02 -6.76587373e-02\n",
      " -2.27606613e-02  1.95606686e-02  5.50249629e-02  1.22029260e-02\n",
      " -1.75167446e-03  7.22444663e-03  1.16349850e-02 -1.61908474e-02\n",
      " -3.37754861e-02  3.22626606e-02 -2.03813948e-02 -2.33859401e-02\n",
      " -1.29992096e-02 -1.66799091e-02  1.03070484e-02 -1.46030160e-02\n",
      " -7.79070109e-02 -8.25812444e-02 -3.38809639e-02  3.81114483e-02\n",
      "  7.86006916e-03  2.41455007e-02 -2.75715105e-02  1.30867576e-02\n",
      " -7.88598042e-03  1.78651493e-02  5.37323095e-02 -3.01823169e-02\n",
      "  1.69455782e-02  1.19571108e-02  3.52598494e-04  4.90208678e-02\n",
      " -8.57212394e-03  1.71267660e-03  4.83876653e-03 -4.10080813e-02\n",
      " -4.68120463e-02 -2.32560793e-03 -5.16776703e-02  3.10030580e-02\n",
      "  1.60961077e-02 -1.00803776e-02 -3.72488564e-03 -3.53388190e-02\n",
      "  2.95961313e-02  2.89097074e-02 -7.59911016e-02 -5.02980500e-02\n",
      " -2.11783368e-02  3.20462734e-02 -3.84537913e-02  2.45102681e-02\n",
      " -2.04188488e-02  6.02114713e-03 -9.81935859e-03  3.74778137e-02\n",
      "  3.40838283e-02  1.28863985e-02  5.67342117e-02 -8.09703469e-02\n",
      " -8.93604849e-03  1.33352783e-02 -2.51565911e-02  2.58413120e-03\n",
      " -6.51803017e-02  1.34400567e-02 -2.04681847e-02  6.53377268e-03\n",
      "  4.56972932e-03  1.99271310e-02 -6.07340075e-02  1.40692210e-02\n",
      " -5.75334020e-02  9.79795866e-03  3.55392620e-02 -2.45283525e-02\n",
      " -4.73311869e-03 -2.77493037e-02  2.34282836e-02 -8.76456979e-05\n",
      "  7.30441744e-03  1.42028891e-02  4.92807142e-02 -3.16540375e-02\n",
      " -1.34902308e-02  3.08487378e-02  2.80402079e-02 -4.33068834e-02\n",
      " -4.42284420e-02  3.80738936e-02  9.47320004e-05 -4.34895866e-02\n",
      "  1.43868085e-02  2.44335667e-03 -4.84073125e-02  1.08955475e-02\n",
      " -9.87492036e-03  4.59295548e-02  3.96379381e-02 -2.60117128e-02\n",
      "  2.48134155e-02 -5.37149124e-02  5.62824570e-02  8.81362241e-03\n",
      "  5.25077060e-02 -1.47370836e-02 -1.74380988e-02  3.45084444e-02\n",
      "  3.75523269e-02 -4.70167026e-02 -1.94911323e-02  3.82631719e-02\n",
      " -5.67595959e-02 -1.78614375e-03  2.33404469e-02 -5.88216492e-33\n",
      " -4.87187691e-02 -2.76265666e-02 -3.38240638e-02  2.66188066e-02\n",
      " -3.39277610e-02 -8.49195290e-03 -1.91250611e-02  3.00252214e-02\n",
      "  3.40781696e-02  5.11157587e-02 -1.92479938e-02  2.85642240e-02\n",
      "  3.66040356e-02  1.68858264e-02  4.77258638e-02  1.23802386e-02\n",
      "  2.14844178e-02  4.93667903e-04  1.21273445e-02 -5.82143813e-02\n",
      "  1.62954368e-02 -7.14258244e-03  4.80092317e-02  2.51190737e-02\n",
      "  4.60097678e-02 -2.29839608e-02 -2.05696579e-02 -3.22232861e-03\n",
      "  4.00092043e-02  3.52309942e-02 -3.43154073e-02  2.75634276e-03\n",
      " -1.25138145e-02  1.97685529e-02  5.53494459e-03  1.03744514e-01\n",
      "  5.77610359e-03 -5.65426387e-02  4.19558696e-02 -3.78830880e-02\n",
      " -3.93443219e-02 -6.24309704e-02 -2.24395865e-03 -5.46548590e-02\n",
      "  4.56134677e-02 -5.69245359e-03  3.38917263e-02 -1.44447973e-02\n",
      "  2.72108917e-03  1.11191189e-02 -5.00661209e-02 -1.61127020e-02\n",
      "  1.72815507e-03  6.88877404e-02  1.16492435e-02  2.83171386e-02\n",
      "  6.97191153e-03  2.68372018e-02 -7.72088254e-03  2.16828696e-02\n",
      "  1.15182698e-02  8.72832984e-02 -6.27271459e-03 -6.44473583e-02\n",
      " -1.58233475e-02  4.03268784e-02 -1.69728659e-02 -1.61188785e-02\n",
      " -3.75576578e-02  7.02938586e-02 -3.30486260e-02  4.66323979e-02\n",
      "  1.18027711e-02  6.51075691e-02 -1.16979741e-02 -8.28347169e-03\n",
      " -5.46905212e-02 -2.00226940e-02  8.42688198e-04 -8.19525123e-03\n",
      "  2.08357200e-02  1.37453983e-02 -1.29923306e-03 -3.94575074e-02\n",
      " -2.00184826e-02 -1.53721645e-02  1.17272036e-02 -4.40110676e-02\n",
      "  5.39267287e-02 -2.33010389e-02 -2.24211663e-02 -3.65215610e-03\n",
      "  2.92212963e-02  7.56442174e-03 -2.90923417e-02  4.01517786e-02\n",
      " -2.00853813e-02 -1.79862964e-03 -1.26235979e-02  2.51076929e-02\n",
      " -4.69285809e-02 -3.08554098e-02 -3.63370578e-04  6.01792103e-03\n",
      "  3.97509076e-02  1.38547504e-02  2.49774270e-02  1.76975615e-02\n",
      " -9.31573361e-02 -9.83687025e-03  8.44927784e-03 -1.95390712e-02\n",
      " -3.26568857e-02  5.13736717e-03  5.80929732e-03  2.08536796e-02\n",
      " -5.97835984e-03  5.86811490e-02 -1.49496561e-02 -5.72965667e-02\n",
      " -5.98235894e-03  1.95203186e-03  2.72976700e-03  6.07001176e-03\n",
      " -2.00525653e-02 -1.31687541e-02 -4.06228639e-02  5.68997338e-02\n",
      "  4.44969237e-02 -1.24308290e-02  1.96967348e-02  3.80979627e-02\n",
      "  2.30237674e-07  1.10575175e-02  4.79512885e-02  6.18299358e-02\n",
      "  4.40278538e-02  6.17667381e-03  2.58289510e-03  3.38913836e-02\n",
      " -5.32937190e-03 -2.59284005e-02 -1.26144364e-02  2.46495549e-02\n",
      " -1.68769609e-03  1.17909163e-03  2.40442958e-02 -9.77309719e-02\n",
      "  1.97368041e-02 -5.52921668e-02 -6.17424920e-02 -4.87151891e-02\n",
      "  1.11079612e-03  1.18732058e-01  8.13258141e-02  3.32448855e-02\n",
      "  4.38326895e-02 -2.49559265e-02 -3.59626375e-02  1.66319255e-02\n",
      "  5.93768712e-03 -1.43971667e-02  4.46712878e-03 -6.01986721e-02\n",
      " -5.65912053e-02 -8.21544975e-03  5.83057385e-03 -1.69482194e-02\n",
      "  9.58630443e-03  1.46733606e-02  5.05845323e-02  3.06891669e-02\n",
      "  6.60468042e-02 -2.56551970e-02 -2.78858226e-02 -3.19173299e-02\n",
      " -3.39237005e-02  1.49903065e-02 -3.03336121e-02 -6.06492860e-03\n",
      " -4.81769023e-03  1.72137208e-02 -8.23371951e-03  1.55548481e-02\n",
      "  2.69106720e-02  5.44309011e-03 -1.06898956e-02 -7.82140810e-03\n",
      " -4.44506630e-02  2.55874302e-02 -5.74760623e-02 -2.05442384e-02\n",
      " -3.07850074e-02 -1.57855265e-02 -7.07541592e-03 -4.21312451e-02\n",
      "  3.79934721e-02  6.27764612e-02 -7.67790480e-03 -3.18352953e-02\n",
      "  1.99277700e-34  1.04834232e-02 -3.39326188e-02  3.93821299e-02\n",
      "  5.53065501e-02  9.42169316e-03  1.09727858e-02 -4.91940081e-02\n",
      "  2.95024086e-02 -8.85375030e-03 -5.96248172e-02 -2.37825438e-02]\n",
      "\n",
      "Sentence: Embeddings are one of the most powerful concepts in machine learning!\n",
      "Embedding: [-2.98611391e-02 -1.37522565e-02 -4.75401841e-02  2.72126682e-02\n",
      "  3.40054706e-02  3.16465981e-02  4.26964052e-02  3.29792127e-03\n",
      "  4.35717627e-02  2.53837314e-02  3.02529093e-02  3.21131088e-02\n",
      " -3.99913043e-02  1.28760953e-02  6.70220107e-02 -7.92899802e-02\n",
      "  4.68771979e-02  2.40266230e-02 -2.07997523e-02 -1.07433265e-02\n",
      " -1.19410390e-02 -5.39290607e-02  4.21055630e-02  2.23588869e-02\n",
      " -2.98949517e-02  8.35980475e-03  1.58384982e-02 -4.80235554e-02\n",
      "  1.88432599e-03 -1.67521443e-02 -2.15629153e-02 -3.88487913e-02\n",
      "  3.06274928e-02  4.20525931e-02  1.69483371e-06 -1.86928697e-02\n",
      " -1.24558797e-02  1.32128866e-02 -4.89040017e-02  1.34746432e-02\n",
      "  2.28873342e-02  8.81776866e-03  8.64929054e-03 -2.00949535e-02\n",
      " -3.15217562e-02 -2.53433380e-02  7.57319257e-02  3.62445749e-02\n",
      "  1.25290016e-02  3.09694670e-02  4.50757844e-03 -3.50041799e-02\n",
      " -4.42548364e-04 -9.76647716e-03  6.04545213e-02  4.03472073e-02\n",
      "  1.10734655e-02  6.56202435e-03 -5.84600074e-03  3.79782543e-03\n",
      " -4.46915068e-02  1.76405162e-02  2.45917086e-02 -3.60037875e-03\n",
      "  1.02473386e-01  3.73759232e-02  6.13311492e-03 -2.24676058e-02\n",
      "  1.46482298e-02  5.00536971e-02 -2.29907483e-02  1.12924911e-02\n",
      " -3.10552623e-02 -1.49509422e-02 -2.53130822e-03  3.20944972e-02\n",
      " -4.67056185e-02 -4.85887080e-02  2.98306067e-02  6.44215867e-02\n",
      " -3.12613435e-02  3.57406996e-02  4.16527055e-02 -5.52517213e-02\n",
      " -8.74629337e-03 -2.18630768e-02 -1.12744616e-02 -2.14436315e-02\n",
      " -1.32824136e-02 -2.04866026e-02 -1.00575741e-02  3.54764052e-02\n",
      " -7.47604761e-03 -3.70188728e-02  5.77893779e-02 -2.18168888e-02\n",
      "  4.36227955e-03  2.04380862e-02  3.36814448e-02 -4.92800549e-02\n",
      "  4.82793860e-02 -1.81000680e-03 -1.05118742e-02  4.13323045e-02\n",
      " -6.79833293e-02  1.75715983e-02 -4.43412922e-02  9.90839861e-03\n",
      " -3.81810181e-02  1.10827321e-02 -5.07279374e-02 -2.17450988e-02\n",
      " -1.03835985e-02  4.60332111e-02  1.55862719e-02 -4.21366692e-02\n",
      " -2.72146463e-02  3.22818309e-02 -4.24739309e-02  2.71207187e-02\n",
      " -7.41061494e-02  4.20107394e-02  2.02437863e-02  7.31810853e-02\n",
      " -8.97694752e-03 -2.31159888e-02 -3.93559411e-02 -1.46008469e-02\n",
      " -3.30910236e-02  1.12240082e-02  2.58562621e-03 -4.36854735e-03\n",
      "  1.85855515e-02  2.69934647e-02 -1.67215001e-02  3.69569845e-02\n",
      "  4.44489159e-02 -2.21723728e-02  6.72969082e-03  1.22935651e-02\n",
      "  1.71758011e-02 -2.36472231e-03  3.72264199e-02 -2.22870875e-02\n",
      "  2.94603854e-02 -2.33691055e-02  5.38468966e-03 -3.06581426e-02\n",
      " -2.38920003e-02 -2.63614655e-02 -2.01789401e-02  1.11245640e-01\n",
      " -1.99836902e-02 -3.54030058e-02  3.84143107e-02  2.53069121e-02\n",
      "  1.99550800e-02  5.53518198e-02 -1.99332610e-02 -2.16719788e-03\n",
      "  4.91092503e-02 -4.03530896e-02 -1.16977058e-02 -5.33113368e-02\n",
      "  8.29585828e-03 -5.08251637e-02 -2.65504215e-02 -1.53242536e-02\n",
      "  5.78812230e-03  2.46576359e-03 -3.44448909e-02 -1.85131794e-03\n",
      " -3.95730175e-02 -2.71690898e-02  4.93568033e-02  8.38369131e-02\n",
      "  5.43491282e-02  8.22260901e-02  1.23894839e-02 -4.79797833e-03\n",
      "  7.77335255e-04  2.98486240e-02 -1.85584854e-02  5.98795302e-02\n",
      " -6.82790624e-03  9.78177530e-04  2.85485964e-02 -7.64616765e-03\n",
      " -1.86620038e-02 -2.69287471e-02 -2.90332939e-02 -1.37871196e-02\n",
      " -2.57600122e-03 -2.20173467e-02 -1.70821808e-02 -3.81843820e-02\n",
      "  2.21505221e-02 -3.59234251e-02 -1.19439391e-02 -3.18307951e-02\n",
      " -4.80801426e-02  9.77633148e-03 -1.04865700e-03  4.15372178e-02\n",
      " -1.10974358e-02 -4.72829565e-02  1.90984551e-02 -5.31177446e-02\n",
      "  2.11326275e-02 -2.53064535e-03  5.61055280e-02 -1.33795468e-02\n",
      " -5.95856924e-03 -1.20307626e-02  4.63929772e-02 -2.81908959e-02\n",
      "  2.25354992e-02 -2.50473851e-03 -3.52453478e-02  2.55494341e-02\n",
      "  9.10396595e-03  3.25210788e-03  2.55967816e-03 -1.25624062e-02\n",
      " -3.51496451e-02 -4.28946242e-02 -2.32331175e-03  2.41021160e-02\n",
      " -5.16839372e-03  1.68739948e-02  5.52645279e-03  2.36792061e-02\n",
      "  5.65164350e-02 -3.47868949e-02 -6.34517744e-02 -7.45624444e-03\n",
      " -1.78447943e-02  5.35898320e-02  2.67291404e-02 -8.74199644e-02\n",
      "  1.04195774e-02 -4.13975766e-04 -3.04448092e-03  9.14249010e-03\n",
      "  2.91529223e-02 -5.81831858e-02  6.83463663e-02 -4.08618078e-02\n",
      " -9.09789559e-03 -3.40769924e-02  3.52410749e-02 -1.02627734e-02\n",
      " -5.72488818e-04 -2.73456913e-03  1.59635693e-02  4.49073687e-03\n",
      " -2.09051501e-02  3.02769579e-02  2.46119797e-02 -1.44067341e-02\n",
      "  1.73268672e-02  1.99034601e-03  4.23051231e-02 -2.39177048e-02\n",
      " -3.25547904e-02 -1.45939644e-02  3.95101085e-02 -6.04650006e-02\n",
      " -3.02065592e-02  1.67189259e-02 -2.26817578e-02 -2.61955298e-02\n",
      " -5.51320277e-02  1.44908410e-02 -1.99246891e-02  3.99752753e-03\n",
      "  3.12609635e-02 -4.90727797e-02 -9.49675799e-04  5.39496839e-02\n",
      " -9.10080038e-03 -2.69486606e-02 -3.63159403e-02 -1.38437087e-02\n",
      " -4.45622057e-02  5.49358837e-02  2.17591319e-03  2.23448314e-03\n",
      " -5.23017067e-03 -1.47894155e-02  3.60592082e-02  1.45263020e-02\n",
      "  8.39191768e-03 -6.10361062e-02 -7.89947342e-03 -2.98298150e-03\n",
      "  3.56563274e-03  8.33992213e-02 -2.61215344e-02  8.06722492e-02\n",
      "  3.63062462e-03  1.69974416e-02  2.58604083e-02  1.09440880e-03\n",
      " -4.57063317e-02  5.55678569e-02  2.00643539e-02  4.76660766e-02\n",
      " -4.91054319e-02 -1.86080877e-02  3.34404595e-02 -2.57310215e-02\n",
      " -3.16371117e-03  7.21444637e-02 -1.61519013e-02 -1.33933919e-02\n",
      " -6.06293790e-02 -2.82187015e-02 -8.91923998e-03 -2.71173357e-03\n",
      "  8.04914813e-03 -4.95209917e-02  7.89434463e-02  2.76427977e-02\n",
      " -5.42579964e-03 -3.06721521e-03 -4.11826558e-02  1.39172450e-02\n",
      "  3.04253101e-02  1.02856327e-02  1.06679080e-02 -5.56554012e-02\n",
      " -1.75082926e-02  2.03868505e-02  8.43309797e-03  3.82471047e-02\n",
      " -3.89099680e-02 -1.61303356e-02  3.18059213e-02 -7.32970089e-02\n",
      " -1.76502261e-02 -4.79874723e-02 -5.55042066e-02 -5.00755198e-03\n",
      "  4.46767313e-04  3.57333124e-02 -8.24693998e-04 -3.34323905e-02\n",
      " -3.32417227e-02 -2.46460438e-02  2.15331968e-02  3.90854804e-03\n",
      "  2.53471229e-02  6.02990016e-03 -7.81611074e-03  1.23765413e-02\n",
      " -1.71039179e-02  2.68103573e-02  2.83678668e-03 -1.27643915e-02\n",
      "  1.00510888e-01  1.03581157e-02 -3.55143100e-02  1.56616643e-02\n",
      " -9.85949934e-02  4.58441526e-02 -3.15230340e-02 -2.35780925e-02\n",
      " -2.78350227e-02 -7.75450171e-05 -2.82362886e-02 -1.92918107e-02\n",
      "  1.87389571e-02  5.71941249e-02  2.56911982e-02 -3.20030265e-02\n",
      "  1.99074615e-02 -3.15819569e-02 -4.02061045e-02  5.77630624e-02\n",
      "  1.72974486e-02 -5.37013486e-02 -1.25325844e-02 -1.45483902e-02\n",
      " -5.76174296e-02  1.09727522e-02 -2.04727743e-02  2.85540987e-02\n",
      " -5.04399948e-02  4.36990969e-02  1.75711140e-02 -1.02343569e-02\n",
      " -9.69771743e-02 -2.99995188e-02 -2.86679249e-02  2.24936809e-02\n",
      " -1.68121178e-02 -1.43674007e-02 -8.79590306e-03 -1.69043839e-02\n",
      "  2.41558105e-02 -6.53192401e-02 -4.10800427e-02 -2.34058257e-02\n",
      " -6.76064938e-02 -1.55690070e-02  3.62357683e-02  7.83159435e-02\n",
      " -4.97516878e-02 -7.08547533e-02 -5.01180142e-02 -8.56431085e-04\n",
      "  5.44899888e-03  4.34705056e-03  9.88052934e-02 -2.16415673e-02\n",
      " -1.87750999e-02  1.15069421e-02  2.63996609e-02  1.65235754e-02\n",
      " -2.24057958e-02 -4.31826673e-02  1.31803900e-01 -2.97034178e-02\n",
      "  2.65934262e-02 -1.38888862e-02 -1.67003796e-02  3.44145298e-02\n",
      " -8.94353259e-03  6.16001710e-02 -3.42303142e-02  2.46425066e-03\n",
      " -8.14093463e-03  5.80325201e-02  5.24208955e-02 -1.53281009e-02\n",
      "  4.01382521e-02  1.51407365e-02 -3.01462505e-03 -4.97020781e-02\n",
      " -4.24301531e-03  5.77289201e-02  3.17874029e-02  4.74008285e-02\n",
      "  2.95218024e-02 -1.50123136e-02 -2.47945357e-02 -7.11501688e-02\n",
      "  2.06848457e-02  3.11488099e-02 -5.86068537e-03  1.62787233e-02\n",
      " -3.93683091e-02  5.46505786e-02  3.26595381e-02 -1.87021624e-02\n",
      " -9.79863107e-02  4.33778716e-03 -5.58156893e-02 -1.34620694e-02\n",
      "  2.88454276e-02  1.58748217e-02 -3.32564265e-02  1.44420180e-03\n",
      " -5.51108047e-02  8.24674889e-02  2.38845963e-02 -2.04838123e-02\n",
      " -4.78585251e-03  3.78722735e-02 -4.87563126e-02  3.44647355e-02\n",
      "  1.10358307e-02  1.12450356e-02  1.33262658e-02 -3.46375406e-02\n",
      " -6.92220852e-02  7.30120158e-03 -6.57012314e-03  1.73203703e-02\n",
      "  5.23052737e-03  4.48132083e-02  3.89852859e-02 -1.99274682e-02\n",
      " -1.80920400e-02  3.25937904e-02 -2.02027354e-02  4.86282603e-04\n",
      " -8.88758153e-03 -1.91348232e-02  2.50686221e-02  4.74019721e-02\n",
      "  2.18652980e-03 -1.69988386e-02  3.62670720e-02  3.46249482e-03\n",
      "  4.21920093e-03  8.04171115e-02  3.10627446e-02 -1.04949879e-03\n",
      " -3.55466567e-02  4.34837006e-02 -3.06218863e-02 -3.03191785e-02\n",
      " -4.13175821e-02 -1.05258338e-02 -2.35242248e-02 -1.86772253e-02\n",
      "  4.42936085e-03  5.45056500e-02 -6.05017543e-02  2.48421840e-02\n",
      " -3.36967371e-02 -4.54169102e-02 -2.63173133e-02  6.98053744e-03\n",
      "  6.92871213e-02 -2.04491708e-02 -1.96812619e-02 -9.72558744e-03\n",
      " -1.21564856e-02  7.89341610e-03  1.84751442e-03 -6.93651214e-02\n",
      "  2.43357234e-02  4.00609747e-02  3.44013311e-02 -2.84281913e-02\n",
      " -1.09431613e-02  1.38743082e-02 -4.40585706e-03  1.19349186e-03\n",
      " -8.81164819e-02  1.15931369e-02 -2.56350636e-02  5.57525270e-02\n",
      "  1.26946226e-01  5.39566018e-02 -1.41436942e-02  1.27196377e-02\n",
      " -1.32236006e-02 -5.94484620e-02  2.86703929e-02  2.57284436e-02\n",
      " -8.33777990e-03  8.17361230e-04  5.93051733e-03  3.29110436e-02\n",
      "  4.12751846e-02 -5.77966357e-03 -1.71124022e-02  1.06227705e-02\n",
      " -2.19601896e-02 -4.97207306e-02  2.53766198e-02 -5.60257542e-33\n",
      " -1.35397241e-02 -3.77958678e-02 -2.67922273e-03 -3.69711517e-04\n",
      " -1.98267531e-02  5.47054689e-03  6.02688501e-03  1.93069391e-02\n",
      "  3.87977972e-03  2.97698714e-02 -1.88228805e-02  2.20034597e-03\n",
      "  8.17021448e-03  1.61964893e-02  3.17529365e-02 -6.83415355e-03\n",
      "  2.19252259e-02  4.37724550e-04  2.96859089e-02 -2.62557101e-02\n",
      "  6.49379287e-03  3.56025323e-02  1.58607052e-03 -4.76584435e-02\n",
      " -5.26238494e-02  3.78274433e-02  3.54341976e-02 -3.10347881e-02\n",
      "  7.96406437e-03  5.48469760e-02 -3.56443822e-02  9.10137873e-03\n",
      " -9.45986155e-03 -4.63287011e-02 -1.63906813e-02  6.32452741e-02\n",
      " -1.38588194e-02 -5.95724471e-02 -1.57990828e-02  2.01886892e-02\n",
      " -1.98292565e-02 -3.49211656e-02  2.27937698e-02 -5.91621809e-02\n",
      "  4.18854952e-02  1.20736647e-03  5.19158989e-02 -1.88435931e-02\n",
      " -3.12102064e-02  2.34933011e-02 -7.41029829e-02 -2.76597944e-04\n",
      " -1.51720056e-02  6.11713454e-02  1.25065118e-01 -1.28458962e-02\n",
      " -1.12670977e-02  1.51753519e-03 -8.09153318e-02  1.12689184e-02\n",
      " -1.97573658e-02  2.74268184e-02  9.40995850e-03 -9.58761945e-03\n",
      "  2.54850071e-02  6.81659132e-02 -1.83453225e-02 -1.00963950e-01\n",
      " -9.45244357e-03 -5.27016539e-03  1.98684558e-02  9.80847552e-02\n",
      "  3.15633193e-02  5.30422516e-02  3.75123285e-02 -6.64208457e-02\n",
      " -5.92879951e-02 -1.57073978e-02  1.76609084e-02 -5.81073277e-02\n",
      "  2.23230775e-02  1.29869403e-02 -3.30261104e-02  9.96858696e-04\n",
      " -9.87092033e-03 -3.12955491e-02  2.28527584e-03 -4.91250455e-02\n",
      "  1.47694107e-02 -1.83367077e-02 -4.16306332e-02  3.76896933e-02\n",
      "  3.35410237e-02 -7.97111839e-02  4.01299335e-02  1.59071982e-02\n",
      "  5.06080920e-03  4.28808294e-02  2.29760204e-02 -4.13351208e-02\n",
      " -3.10503915e-02 -5.26405275e-02 -4.95404750e-02 -2.94256713e-02\n",
      "  5.94924502e-02 -2.59802584e-02  3.02497260e-02  8.80408194e-03\n",
      " -4.84466814e-02 -2.00851876e-02  9.82178189e-03 -7.89194331e-02\n",
      "  4.52874461e-03 -9.34896711e-03  9.23312921e-03 -3.17361429e-02\n",
      "  2.10833084e-02  6.37119263e-03  3.36347595e-02  3.83614078e-02\n",
      " -4.55527417e-02  1.08122244e-03 -9.83323995e-03  7.70195713e-03\n",
      " -2.87617613e-02 -1.74959321e-02 -4.27810661e-03  2.81286892e-02\n",
      "  4.97340076e-02 -7.45570436e-02 -1.07009113e-02 -7.66055146e-03\n",
      "  2.33968805e-07  1.52483415e-02  8.39613453e-02  3.67243104e-02\n",
      " -3.69248949e-02  3.64751779e-02  4.26422283e-02 -4.39828681e-03\n",
      "  1.78134069e-02 -2.67076418e-02 -7.13904761e-03  5.59975356e-02\n",
      "  3.13966908e-02  2.13443721e-03  3.90371270e-02 -8.78527984e-02\n",
      " -2.21659895e-02 -2.47735698e-02 -1.18189454e-02 -7.89708365e-03\n",
      " -2.08857432e-02  4.30556200e-02  1.07643552e-01  4.40618396e-02\n",
      "  1.47962496e-02  2.44862642e-02 -3.86267938e-02  1.80743784e-02\n",
      " -1.47839822e-03  7.74166733e-02 -4.19566222e-02 -3.80529091e-02\n",
      "  3.61257382e-02  1.59033644e-03  1.95323955e-02 -2.00080425e-02\n",
      "  4.22538109e-02  3.06110997e-02 -3.53687257e-03  5.93104400e-03\n",
      " -2.23223679e-02 -2.07131524e-02 -3.62906256e-03  1.74653810e-02\n",
      " -4.08758856e-02  5.91595322e-02 -5.89100495e-02 -3.96753922e-02\n",
      " -3.33529003e-02  1.02161821e-02  6.97295833e-03  7.70389512e-02\n",
      " -1.86911654e-02 -1.82568319e-02 -2.42318995e-02 -3.40697751e-03\n",
      " -3.60555425e-02  4.33389395e-02 -3.48602459e-02  5.27768433e-02\n",
      "  2.89709624e-02 -4.98462506e-02 -1.94749068e-02  1.16397776e-02\n",
      " -3.04614827e-02  8.04637522e-02  6.56247735e-02 -2.84533240e-02\n",
      "  1.81615289e-34 -4.19161702e-03 -2.57882476e-02  5.17320596e-02\n",
      "  4.94420901e-02  1.32476361e-02 -4.21994328e-02 -1.12458598e-02\n",
      " -2.61519682e-02  5.51130362e-02  2.20024735e-02 -2.51170173e-02]\n",
      "\n",
      "Sentence: Learn to use embeddings well and you'll be well on your way to being an AI engineer.\n",
      "Embedding: [-2.20730789e-02  2.08950397e-02 -6.03005365e-02  8.43945052e-03\n",
      "  4.37650867e-02  1.55070126e-02  4.99907658e-02 -3.03232521e-02\n",
      "  4.94784266e-02  2.35512275e-02  3.29350904e-02  1.53877670e-02\n",
      " -6.68355152e-02  1.11002855e-01  6.92677274e-02 -2.31888667e-02\n",
      "  3.79102789e-02 -4.94144764e-03 -1.57800298e-02 -3.45476493e-02\n",
      " -2.65052803e-02 -2.47879438e-02 -1.86141338e-02  3.00361756e-02\n",
      " -2.81186160e-02 -8.75129271e-03 -3.30774416e-03 -2.06115954e-02\n",
      "  1.03315525e-02 -1.51482951e-02 -3.48330885e-02 -2.63248030e-02\n",
      "  2.06907894e-02  3.79108824e-02  1.81912878e-06 -2.44285003e-03\n",
      " -1.80562341e-03  5.61761251e-03 -2.79870220e-02  1.54703036e-02\n",
      "  3.06456294e-02  3.72600630e-02 -1.55611625e-02  2.54414231e-02\n",
      " -6.42072260e-02  3.16353291e-02  6.63442612e-02  3.80969979e-02\n",
      "  5.57844900e-02  5.31659909e-02 -9.69290640e-03 -3.61423902e-02\n",
      "  3.72434817e-02 -4.67827963e-03  5.14574945e-02  1.00057982e-02\n",
      "  4.90289414e-03  1.41562391e-02  4.95099872e-02  3.32949613e-03\n",
      " -3.21100652e-02  4.42388132e-02  3.27416174e-02 -7.90622737e-03\n",
      "  1.07809782e-01  7.32945055e-02  3.36702615e-02 -4.28345799e-02\n",
      "  1.05966376e-02  2.05653962e-02 -2.02670097e-02  1.04964310e-02\n",
      " -1.97615791e-02 -2.89644668e-05 -2.61862557e-02 -1.85173880e-02\n",
      " -3.44269313e-02 -4.08621356e-02  2.32571531e-02  2.14195810e-02\n",
      "  1.31321279e-02 -3.27211060e-02 -1.91425811e-02 -2.86572259e-02\n",
      " -1.16859442e-02  1.21910637e-02  1.05248168e-02 -3.39584872e-02\n",
      "  3.08904005e-03 -4.44888622e-02  2.65104994e-02  1.09536396e-02\n",
      "  2.51450948e-02 -6.48836419e-03  4.54370212e-03 -2.02785172e-02\n",
      " -1.03216497e-02  2.06589792e-02 -1.65314097e-02 -2.45612189e-02\n",
      "  5.47549129e-02  2.68261340e-02  2.95510851e-02  3.86754461e-02\n",
      " -7.76720122e-02  3.80055644e-02 -2.98364684e-02  7.96886012e-02\n",
      " -3.00943553e-02  7.57846469e-03 -6.89826459e-02 -2.92666890e-02\n",
      " -2.35580001e-02  3.48198377e-02  2.52938513e-02 -4.53817248e-02\n",
      " -1.57938916e-02  4.39031161e-02 -4.04335670e-02  8.32526665e-03\n",
      " -2.84665190e-02  4.94934097e-02  2.41276752e-02  3.02191991e-02\n",
      " -4.99590412e-02 -5.94533049e-02 -3.70175764e-02  1.30330725e-02\n",
      " -3.36468741e-02  3.45589444e-02 -1.44523168e-02  2.57640034e-02\n",
      "  4.61184606e-03  2.21551973e-02 -4.93460707e-03  9.66005102e-02\n",
      " -2.72449851e-03  5.65370952e-04 -3.24248001e-02  1.31681794e-02\n",
      "  4.41607498e-02 -7.03051779e-03  6.84261173e-02 -2.28166431e-02\n",
      " -2.81030266e-03 -4.23883200e-02 -1.33631965e-02 -5.96738867e-02\n",
      " -6.96125207e-03 -2.31901240e-02 -3.78851146e-02  9.80186537e-02\n",
      " -2.21728962e-02 -2.30062511e-02  3.22815292e-02  8.21803417e-03\n",
      " -7.04122521e-03  4.84079421e-02  4.23291177e-02 -2.59716483e-03\n",
      "  1.20506687e-04  1.67414155e-02  2.91197933e-02 -1.28740463e-02\n",
      " -2.41077878e-02 -3.29319760e-02 -3.50289349e-03 -3.19322012e-02\n",
      " -2.64171846e-02  2.30404381e-02  1.11637227e-02 -9.96000133e-03\n",
      " -1.75901130e-02 -2.00277357e-03  1.21595031e-02  4.67823334e-02\n",
      "  5.20881899e-02  7.21171871e-02  1.94978453e-02  1.15072737e-02\n",
      "  5.94164338e-03 -1.47833219e-02 -2.87724230e-02  6.72666281e-02\n",
      " -1.68758593e-02  5.25872596e-03 -3.39737386e-02  5.24596050e-02\n",
      " -2.59793252e-02 -4.41379808e-02  1.47452718e-03 -1.06599024e-02\n",
      " -1.51859289e-02 -1.55876018e-03  1.81505363e-02 -4.85411361e-02\n",
      "  3.67910159e-03 -6.59313276e-02 -1.49418563e-02 -3.23529206e-02\n",
      " -2.79949605e-02  1.71856694e-02 -7.87090324e-03  4.65692170e-02\n",
      "  1.47123076e-02 -7.40438849e-02 -6.52104318e-02 -5.22734895e-02\n",
      " -1.82343256e-02  5.20859249e-02  3.06304786e-02 -2.36037150e-02\n",
      "  2.42384840e-02 -1.83939505e-02 -4.83014481e-03 -2.13386528e-02\n",
      "  1.56583544e-02  9.87338927e-03 -4.25561704e-02  6.00461895e-03\n",
      " -3.14500649e-03  4.51512402e-03 -1.52782060e-03  1.13731446e-02\n",
      " -6.96354136e-02 -3.37257385e-02  1.33407013e-02  4.87289671e-03\n",
      " -7.81493541e-03  4.78049628e-02 -1.59711894e-02  3.14606577e-02\n",
      "  5.15920222e-02 -4.05122563e-02 -5.06461114e-02  9.99930594e-03\n",
      " -2.00729296e-02  4.21552882e-02  3.03182453e-02 -1.00431278e-01\n",
      " -4.12019789e-02  3.43990661e-02  3.29209156e-02  1.07410876e-03\n",
      "  3.70961875e-02 -6.94237426e-02  6.52393922e-02  8.31666682e-03\n",
      "  1.68036390e-02 -2.60705780e-02  8.14495329e-03 -1.48009378e-02\n",
      " -2.65671220e-02  3.29321548e-02 -7.37512484e-03  7.23978318e-03\n",
      " -2.69329455e-02  1.71754863e-02 -2.28083190e-02 -4.75338101e-03\n",
      "  2.88569108e-02  1.30790184e-04  5.44128455e-02 -1.43378517e-02\n",
      "  1.89891756e-02 -1.32732317e-02  4.01177332e-02 -7.29275420e-02\n",
      " -2.41211224e-02  3.16216797e-02 -1.68014523e-02  8.47542938e-03\n",
      " -5.23940548e-02 -1.43882651e-02 -1.46156373e-02  6.39907271e-03\n",
      "  2.15113554e-02 -5.18960170e-02 -4.30576280e-02  2.34075822e-02\n",
      "  2.30271020e-03 -2.48434376e-02 -4.38242927e-02 -2.16570720e-02\n",
      " -6.91595450e-02  1.76770203e-02  2.12067850e-02 -2.20293906e-02\n",
      " -1.06773600e-02  9.57429875e-03  2.21988782e-02  5.51470816e-02\n",
      "  1.03682950e-02 -8.14825147e-02 -7.94705190e-03 -1.85866524e-02\n",
      "  1.20494263e-02  7.51403719e-02 -1.41215585e-02  8.83924514e-02\n",
      "  3.12628448e-02  8.12262483e-03 -2.29444839e-02  3.96010280e-02\n",
      " -2.00167950e-02  9.16027725e-02 -2.06839200e-02  5.84990755e-02\n",
      " -4.32368554e-02 -4.74750856e-03 -9.51891486e-03  5.42951003e-03\n",
      "  1.19129749e-04  6.15377054e-02 -1.68787397e-03 -4.66321111e-02\n",
      " -2.01405287e-02  1.32406233e-02  9.70686134e-03  2.73847617e-02\n",
      "  3.06639764e-02  6.71578199e-03  8.71220976e-02 -1.97372143e-03\n",
      "  8.18299316e-03  5.44362795e-03 -5.76205999e-02  1.34821385e-02\n",
      "  5.06280875e-03 -2.10569035e-02  1.25937192e-02 -5.49776480e-03\n",
      " -1.44645171e-02 -2.92567182e-02  5.53299263e-02 -2.60099359e-02\n",
      " -2.82453164e-03 -2.30902452e-02  8.89709219e-03 -2.61565074e-02\n",
      "  9.08614660e-04 -6.16204292e-02 -7.56419227e-02 -1.05932187e-02\n",
      " -1.19563779e-02  6.71458766e-02 -1.96234547e-02 -5.00934310e-02\n",
      " -3.91229093e-02 -3.07008475e-02  7.18906447e-02  9.29243490e-03\n",
      " -6.34387648e-03  7.86949240e-04 -1.36483973e-02  2.87188459e-02\n",
      "  4.01224494e-02  1.28037324e-02  1.77381355e-02 -4.75977641e-03\n",
      "  5.47173470e-02  1.10812136e-03 -2.25790385e-02 -2.80290074e-03\n",
      " -1.13696069e-01  2.55904458e-02  4.00460471e-04 -4.39810492e-02\n",
      "  1.36319110e-02 -1.54137593e-02 -4.99015115e-02 -2.32889559e-02\n",
      " -1.62987527e-03  3.95835266e-02  1.89040191e-02 -3.02703381e-02\n",
      "  2.71438044e-02  1.05684379e-03 -4.21069041e-02  3.71961221e-02\n",
      "  3.54258344e-02 -6.98274374e-02 -2.20937617e-02 -4.01495770e-02\n",
      " -1.90164112e-02 -2.69835591e-02 -1.51212942e-02  3.33365276e-02\n",
      " -9.74889547e-02  1.73102617e-02  6.21014694e-03 -2.59423046e-03\n",
      " -1.10152952e-01 -6.10186458e-02 -1.36549855e-02 -1.35034937e-02\n",
      " -6.72574639e-02 -4.05121408e-03 -6.64983504e-03  3.86569602e-03\n",
      "  9.43470281e-03 -3.86636965e-02 -1.93593334e-02  1.34933582e-02\n",
      " -4.58106995e-02  6.06737360e-02  6.06380180e-02  4.85596322e-02\n",
      " -4.56088707e-02 -5.71936332e-02 -1.55094760e-02  3.40963341e-02\n",
      "  9.48151981e-04 -9.94348433e-03  2.84657516e-02 -3.29024568e-02\n",
      " -2.83211172e-02  3.19907591e-02  2.61299107e-02 -2.74054967e-02\n",
      " -1.36352833e-02  7.47716706e-03  1.19430251e-01 -4.45807278e-02\n",
      "  1.07671991e-02 -8.69424418e-02 -2.19551027e-02  1.83874685e-02\n",
      " -1.06521659e-02 -1.89243108e-02 -3.06514055e-02 -3.04701813e-02\n",
      " -3.22214887e-02  4.12150919e-02  8.95756762e-03 -2.73179822e-02\n",
      "  9.39996075e-03 -9.57184297e-04 -1.94010623e-02 -4.92622592e-02\n",
      " -9.18893423e-03  4.66893911e-02  5.41893505e-02  2.21609399e-02\n",
      " -2.86351908e-02  5.20295613e-02  2.47589722e-02 -7.14267939e-02\n",
      " -1.26206949e-02  7.35524297e-03  2.13785097e-02  2.93514021e-02\n",
      " -2.57651247e-02  5.20562343e-02 -2.74892263e-02 -3.10242232e-02\n",
      " -9.02880505e-02  6.10371493e-02 -5.22610098e-02  2.13111509e-02\n",
      "  4.41735499e-02  3.23370732e-02  1.75648332e-02 -2.39519682e-02\n",
      " -2.69709453e-02  5.11278622e-02  2.69064698e-02 -4.51933071e-02\n",
      "  2.52655242e-03  2.44934186e-02 -2.89541110e-02  2.79992409e-02\n",
      " -1.36022316e-02 -4.32368480e-02  1.85830202e-02  7.63748176e-05\n",
      "  2.43510189e-03 -3.73323075e-03 -1.72280073e-02  1.01293065e-02\n",
      "  1.98437236e-02 -2.60018390e-02 -3.40178865e-03  1.09125469e-02\n",
      " -4.16363478e-02  3.37032042e-02 -2.81635039e-02  1.79126207e-02\n",
      " -4.53095175e-02 -1.09818913e-02 -2.20829877e-03  1.99102331e-02\n",
      "  3.56372222e-02 -3.11798807e-02  3.78752537e-02 -1.41409263e-02\n",
      " -2.16907579e-02  2.73020100e-02  3.69814690e-03  6.35387525e-02\n",
      "  1.22669125e-02 -6.02271780e-03 -7.60754570e-03 -1.86565164e-02\n",
      " -5.64717175e-03 -2.20051268e-03 -1.31825451e-02  1.67724174e-02\n",
      " -3.77264284e-02  2.97895446e-02 -5.01569882e-02  4.89087999e-02\n",
      " -6.07445128e-02 -8.39419216e-02 -5.09001166e-02  1.81767885e-02\n",
      "  6.66732788e-02 -3.30035365e-03 -2.82402523e-03 -5.35406061e-02\n",
      "  3.90340947e-02  2.19852291e-02  3.13555114e-02 -3.36526893e-02\n",
      "  1.96913816e-02  1.67883486e-02  5.04002906e-02  3.08061205e-03\n",
      " -7.24797428e-04  4.42907028e-02 -4.12960164e-03  4.29328829e-02\n",
      " -6.62552416e-02  1.16059324e-03 -2.81716362e-02  1.56885739e-02\n",
      "  9.78133604e-02  5.53594455e-02 -1.39378598e-02  2.12307293e-02\n",
      " -1.30955447e-02 -6.82027638e-02 -8.09096207e-04  4.99291569e-02\n",
      " -2.69265827e-02 -2.97804084e-02  3.84461954e-02  1.97354816e-02\n",
      "  3.37088294e-02  1.65873989e-02  5.77316573e-03 -3.04897837e-02\n",
      " -1.52511979e-02 -3.56159247e-02 -8.69219471e-03 -5.42296833e-33\n",
      "  3.24374926e-03 -3.46329883e-02  3.58932763e-02  1.83770955e-02\n",
      " -2.17505097e-02 -3.26411575e-02  2.88398960e-03  1.50463907e-02\n",
      " -1.75262091e-03 -1.99418776e-02 -6.10355334e-03  2.23847236e-02\n",
      " -8.78943480e-04  2.48684920e-02  3.39736678e-02  2.75593139e-02\n",
      "  3.37792374e-02  3.98564599e-02  2.55545285e-02  1.83042623e-02\n",
      " -2.92878747e-02  5.18081477e-03  8.37746600e-04 -3.66560407e-02\n",
      " -3.46732773e-02  3.82687002e-02  5.50825149e-03 -4.35187444e-02\n",
      "  2.44077761e-02  3.54167186e-02 -2.13442314e-02  2.86623891e-02\n",
      " -2.65391194e-04  3.73409167e-02 -8.68168846e-03  3.04785650e-03\n",
      " -2.71681938e-02 -3.85087989e-02 -6.12388812e-02 -2.00844416e-03\n",
      " -1.22080110e-02 -8.67197961e-02  3.75360483e-03 -1.77707616e-02\n",
      "  8.32476281e-03 -1.69167891e-02  7.02404156e-02  3.32233943e-02\n",
      "  4.34313267e-02  1.47016617e-02 -1.25546873e-01  1.50866760e-02\n",
      " -5.43164425e-02 -1.79149513e-03  4.99600805e-02 -1.53786335e-02\n",
      "  3.32683511e-02 -3.07709016e-02 -1.83896795e-02  9.45797376e-03\n",
      " -4.60291058e-02 -2.03868165e-03  2.62428839e-02 -5.00789285e-02\n",
      "  2.01835781e-02  6.08982965e-02 -2.01180447e-02 -2.60054246e-02\n",
      "  1.05925454e-02 -3.31153944e-02  1.62595529e-02  7.77862146e-02\n",
      " -1.90731068e-03 -5.62889501e-03  1.43715916e-02 -4.06833738e-02\n",
      " -5.14970981e-02  1.66243073e-04 -3.33060254e-03  1.44688869e-02\n",
      "  4.24947153e-04  3.04452907e-02 -1.83636695e-02  1.51185214e-03\n",
      "  2.99861562e-02 -3.68002057e-02  8.35627411e-03 -3.31025422e-02\n",
      "  2.66911779e-02  5.47832344e-03 -1.80524308e-02  2.42577009e-02\n",
      "  5.72711322e-03 -5.93372323e-02  1.04358479e-01 -9.87923145e-03\n",
      " -1.36105698e-02  5.79998717e-02  2.50108521e-02  2.89337356e-02\n",
      " -3.20521332e-02 -3.40233147e-02 -3.41698751e-02 -2.76981238e-02\n",
      "  6.47003204e-02  1.50797814e-02 -1.61925778e-02  3.03266123e-02\n",
      " -2.67187897e-02 -3.67774256e-02 -2.27845535e-02 -5.36434092e-02\n",
      "  1.90499835e-02 -3.42503376e-02  1.32688470e-02 -5.41319558e-03\n",
      "  7.49742100e-03 -7.36990711e-04 -3.08569707e-02  3.82288322e-02\n",
      " -2.08311491e-02 -3.43154930e-02  5.60242543e-03  1.45000229e-02\n",
      " -3.76364440e-02 -5.11782579e-02 -3.51075381e-02  1.71867944e-02\n",
      "  1.50721567e-02 -9.62026045e-02 -1.53545383e-02  1.58376526e-02\n",
      "  2.42940956e-07 -5.88806346e-03  7.68795311e-02  5.86063750e-02\n",
      "  2.21232940e-02 -2.36690864e-02  5.25274277e-02  1.48661518e-02\n",
      "  7.34179281e-03 -4.98919981e-03  4.37413752e-02 -1.28331743e-02\n",
      "  3.37342285e-02 -1.10814795e-02 -1.33938110e-02 -7.80063644e-02\n",
      " -1.36330584e-02  1.94749106e-02  1.91750086e-03 -3.00251599e-02\n",
      "  1.02692866e-04  9.54533294e-02  1.19653940e-01  3.73371765e-02\n",
      "  4.25125472e-03  2.05129702e-02 -3.85414697e-02 -1.90614704e-02\n",
      "  5.88793196e-02  6.81264699e-02 -3.12595665e-02 -6.50441051e-02\n",
      "  2.48044766e-02  3.90078087e-04  7.54762143e-02 -3.46075967e-02\n",
      "  1.32949166e-02  4.14005928e-02  3.07569336e-02  5.50351758e-03\n",
      " -1.53086090e-03  2.75993533e-02  6.46030810e-03  1.05398092e-02\n",
      " -3.09298374e-02  4.60232496e-02 -3.64921205e-02 -1.39540313e-02\n",
      " -3.53720821e-02  7.97827786e-04  1.40632810e-02  1.80258621e-02\n",
      " -1.43368663e-02  2.19213660e-03 -3.96873355e-02 -1.17282076e-02\n",
      " -4.45220396e-02  8.05770792e-03 -4.04861309e-02  3.56149152e-02\n",
      "  5.12852557e-02 -6.64038956e-02 -5.32594919e-02  8.92902631e-03\n",
      "  1.56424362e-02  1.02110937e-01  8.10772087e-03 -4.03857511e-03\n",
      "  2.02352559e-34 -1.38294064e-02 -1.17623424e-02  1.51005890e-02\n",
      "  8.25896561e-02  2.39228681e-02 -1.10378163e-02  3.65649536e-03\n",
      " -7.44782528e-03  2.94555034e-02  3.52996611e-03 -6.10421859e-02]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Requires !pip install sentence-transformers\n",
    "from sentence_transformers import SentenceTransformer\n",
    "embedding_model = SentenceTransformer(model_name_or_path=\"all-mpnet-base-v2\", \n",
    "                                      device=\"cuda\")\n",
    "# Create a list of sentences to turn into numbers\n",
    "sentences = [\n",
    "    \"The Sentences Transformers library provides an easy and open-source way to create embeddings.\",\n",
    "    \"Sentences can be embedded one by one or as a list of strings.\",\n",
    "    \"Embeddings are one of the most powerful concepts in machine learning!\",\n",
    "    \"Learn to use embeddings well and you'll be well on your way to being an AI engineer.\"\n",
    "]\n",
    "\n",
    "# Sentences are encoded/embedded by calling model.encode()\n",
    "embeddings = embedding_model.encode(sentences)\n",
    "embeddings_dict = dict(zip(sentences, embeddings))\n",
    "\n",
    "# See the embeddings\n",
    "for sentence, embedding in embeddings_dict.items():\n",
    "    print(\"Sentence:\", sentence)\n",
    "    print(\"Embedding:\", embedding)\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`all-mpnet-base-v2`模型的窗口大小為384，嵌入向量的形狀為(768,)  \n",
    "文本轉成list，然後做embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4805cda6ffa540cd9a80ebbbbac522d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/65 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 11.6 s\n",
      "Wall time: 1.19 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Send the model to the GPU\n",
    "embedding_model.to(\"cuda\")\n",
    "\n",
    "# Create embeddings one by one on the GPU\n",
    "for item in tqdm(pages_and_chunks_over_min_token_len):\n",
    "    item[\"embedding\"] = embedding_model.encode(item[\"sentence_chunk\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn text chunks into a single list\n",
    "text_chunks = [item[\"sentence_chunk\"] for item in pages_and_chunks_over_min_token_len]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 3.25 s\n",
      "Wall time: 957 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0397,  0.0469, -0.0115,  ...,  0.0245, -0.0699, -0.0454],\n",
       "        [ 0.0150,  0.0806, -0.0144,  ...,  0.0126, -0.0488, -0.0525],\n",
       "        [ 0.0131,  0.0966, -0.0178,  ...,  0.0178, -0.0884, -0.0685],\n",
       "        ...,\n",
       "        [ 0.0296,  0.0491, -0.0122,  ...,  0.0119, -0.0609, -0.0661],\n",
       "        [ 0.0516,  0.0396, -0.0147,  ...,  0.0588, -0.0588, -0.0222],\n",
       "        [ 0.0214,  0.0002,  0.0174,  ...,  0.0413, -0.0303, -0.0084]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "\n",
    "# Embed all texts in batches\n",
    "text_chunk_embeddings = embedding_model.encode(text_chunks,\n",
    "                                               batch_size=32, # you can use different batch sizes here for speed/performance, I found 32 works well for this use case\n",
    "                                               convert_to_tensor=True) # optional to return embeddings as tensor instead of array\n",
    "\n",
    "text_chunk_embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "把`text_chunk_embeddings`存起來"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save embeddings to file\n",
    "\n",
    "把`pages_and_chunks_over_min_token_len` list of dictionaries 轉成 DataFrame 然後存起來."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_chunks_and_embeddings_df = pd.DataFrame(pages_and_chunks_over_min_token_len)\n",
    "embeddings_df_save_path = \"text_chunks_and_embeddings_df.csv\"\n",
    "text_chunks_and_embeddings_df.to_csv(embeddings_df_save_path, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 檢查是否有正確存到指定路徑"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_number</th>\n",
       "      <th>sentence_chunk</th>\n",
       "      <th>chunk_char_count</th>\n",
       "      <th>chunk_word_count</th>\n",
       "      <th>chunk_token_count</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Retrieval-Augmented Generation for Knowledge-I...</td>\n",
       "      <td>1833</td>\n",
       "      <td>246</td>\n",
       "      <td>458.25</td>\n",
       "      <td>[ 3.97273190e-02  4.69269864e-02 -1.15035316e-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>For language generation tasks, we ﬁnd that RAG...</td>\n",
       "      <td>1139</td>\n",
       "      <td>162</td>\n",
       "      <td>284.75</td>\n",
       "      <td>[ 1.50031894e-02  8.06403011e-02 -1.43866343e-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>The\u0003DiYine Comed\\\u0003(x) T QXeU\\ EQcRdeU T([) MIP...</td>\n",
       "      <td>1686</td>\n",
       "      <td>210</td>\n",
       "      <td>421.50</td>\n",
       "      <td>[ 1.30570084e-02  9.66036320e-02 -1.78332869e-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>The retriever (Dense Passage Retriever [26], h...</td>\n",
       "      <td>1915</td>\n",
       "      <td>270</td>\n",
       "      <td>478.75</td>\n",
       "      <td>[ 5.29118367e-02  5.53543158e-02 -1.69958323e-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>For FEVER [56] fact veriﬁcation, we achieve re...</td>\n",
       "      <td>949</td>\n",
       "      <td>141</td>\n",
       "      <td>237.25</td>\n",
       "      <td>[ 4.94104400e-02  1.70666482e-02  3.50169698e-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>14</td>\n",
       "      <td>URL https://www.aclweb.org/ anthology/W18-5446...</td>\n",
       "      <td>1096</td>\n",
       "      <td>143</td>\n",
       "      <td>274.00</td>\n",
       "      <td>[ 4.58982587e-02 -1.25643425e-02 -3.06721888e-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>14</td>\n",
       "      <td>URL https://www.aaai.org/ocs/index.php/AAAI/AA...</td>\n",
       "      <td>601</td>\n",
       "      <td>75</td>\n",
       "      <td>150.25</td>\n",
       "      <td>[-1.98382903e-02 -2.96843238e-03 -1.32312218e-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>14</td>\n",
       "      <td>URL http://arxiv.org/abs/1410.3916. [65] Jason...</td>\n",
       "      <td>218</td>\n",
       "      <td>30</td>\n",
       "      <td>54.50</td>\n",
       "      <td>[ 2.96152793e-02  4.90686484e-02 -1.22116404e-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>15</td>\n",
       "      <td>International Workshop on Search-Oriented Conv...</td>\n",
       "      <td>1017</td>\n",
       "      <td>127</td>\n",
       "      <td>254.25</td>\n",
       "      <td>[ 5.16357645e-02  3.96283381e-02 -1.46658486e-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>15</td>\n",
       "      <td>Association for Computational Linguistics.doi:...</td>\n",
       "      <td>340</td>\n",
       "      <td>37</td>\n",
       "      <td>85.00</td>\n",
       "      <td>[ 2.13812124e-02  2.30780264e-04  1.73772871e-...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>65 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    page_number                                     sentence_chunk  \\\n",
       "0             0  Retrieval-Augmented Generation for Knowledge-I...   \n",
       "1             0  For language generation tasks, we ﬁnd that RAG...   \n",
       "2             1  The\u0003DiYine Comed\\\u0003(x) T QXeU\\ EQcRdeU T([) MIP...   \n",
       "3             1  The retriever (Dense Passage Retriever [26], h...   \n",
       "4             1  For FEVER [56] fact veriﬁcation, we achieve re...   \n",
       "..          ...                                                ...   \n",
       "60           14  URL https://www.aclweb.org/ anthology/W18-5446...   \n",
       "61           14  URL https://www.aaai.org/ocs/index.php/AAAI/AA...   \n",
       "62           14  URL http://arxiv.org/abs/1410.3916. [65] Jason...   \n",
       "63           15  International Workshop on Search-Oriented Conv...   \n",
       "64           15  Association for Computational Linguistics.doi:...   \n",
       "\n",
       "    chunk_char_count  chunk_word_count  chunk_token_count  \\\n",
       "0               1833               246             458.25   \n",
       "1               1139               162             284.75   \n",
       "2               1686               210             421.50   \n",
       "3               1915               270             478.75   \n",
       "4                949               141             237.25   \n",
       "..               ...               ...                ...   \n",
       "60              1096               143             274.00   \n",
       "61               601                75             150.25   \n",
       "62               218                30              54.50   \n",
       "63              1017               127             254.25   \n",
       "64               340                37              85.00   \n",
       "\n",
       "                                            embedding  \n",
       "0   [ 3.97273190e-02  4.69269864e-02 -1.15035316e-...  \n",
       "1   [ 1.50031894e-02  8.06403011e-02 -1.43866343e-...  \n",
       "2   [ 1.30570084e-02  9.66036320e-02 -1.78332869e-...  \n",
       "3   [ 5.29118367e-02  5.53543158e-02 -1.69958323e-...  \n",
       "4   [ 4.94104400e-02  1.70666482e-02  3.50169698e-...  \n",
       "..                                                ...  \n",
       "60  [ 4.58982587e-02 -1.25643425e-02 -3.06721888e-...  \n",
       "61  [-1.98382903e-02 -2.96843238e-03 -1.32312218e-...  \n",
       "62  [ 2.96152793e-02  4.90686484e-02 -1.22116404e-...  \n",
       "63  [ 5.16357645e-02  3.96283381e-02 -1.46658486e-...  \n",
       "64  [ 2.13812124e-02  2.30780264e-04  1.73772871e-...  \n",
       "\n",
       "[65 rows x 6 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_chunks_and_embedding_df_load = pd.read_csv(embeddings_df_save_path)\n",
    "text_chunks_and_embedding_df_load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Chunking 和 問題的embedding\n",
    "\n",
    "***MTEB*** - Hugging Face 的大規模文本嵌入基準排行榜\n",
    "\n",
    "需要考慮的事情：\n",
    "\n",
    "輸入大小 - 如果你需要嵌入更長的序列，選擇一個輸入容量更大的模型。\n",
    "嵌入向量的大小 - 一般來說，更大通常是更好的表示，但需要更多的計算/存儲。\n",
    "模型的大小 - 更大的模型通常會產生更好的嵌入，但需要更多的計算力/時間來運行。\n",
    "開放或封閉 - 開放模型允許你在自己的硬件上運行，而封閉模型設置可能更簡單，但需要API調用來獲取嵌入。\n",
    "\n",
    "我應該將我的嵌入存儲在哪裡？\n",
    "\n",
    "數據集不到 100,000 個，可用np.array 或 torch.tensor 作為數據集。\n",
    "100,000+ 個embeddings-->Vector Database。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 2. RAG - 搜索和回答"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 相似性搜尋(Similarity search)  \n",
    "導入之前創建的embedding並轉成tensor。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([65, 768])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "import torch\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "text_chunks_and_embedding_df = pd.read_csv(\"text_chunks_and_embeddings_df.csv\")\n",
    "\n",
    "# Convert embedding column back to np.array (it got converted to string when it got saved to CSV)\n",
    "text_chunks_and_embedding_df[\"embedding\"] = text_chunks_and_embedding_df[\"embedding\"].apply(lambda x: np.fromstring(x.strip(\"[]\"), sep=\" \"))\n",
    "\n",
    "# Convert texts and embedding df to list of dicts\n",
    "pages_and_chunks = text_chunks_and_embedding_df.to_dict(orient=\"records\")\n",
    "\n",
    "# Convert embeddings to torch tensor and send to device (note: NumPy arrays are float64, torch tensors are float32 by default)\n",
    "embeddings = torch.tensor(np.array(text_chunks_and_embedding_df[\"embedding\"].tolist()), dtype=torch.float32).to(device)\n",
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 準備好embedding的chunks了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_number</th>\n",
       "      <th>sentence_chunk</th>\n",
       "      <th>chunk_char_count</th>\n",
       "      <th>chunk_word_count</th>\n",
       "      <th>chunk_token_count</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Retrieval-Augmented Generation for Knowledge-I...</td>\n",
       "      <td>1833</td>\n",
       "      <td>246</td>\n",
       "      <td>458.25</td>\n",
       "      <td>[0.039727319, 0.0469269864, -0.0115035316, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>For language generation tasks, we ﬁnd that RAG...</td>\n",
       "      <td>1139</td>\n",
       "      <td>162</td>\n",
       "      <td>284.75</td>\n",
       "      <td>[0.0150031894, 0.0806403011, -0.0143866343, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>The\u0003DiYine Comed\\\u0003(x) T QXeU\\ EQcRdeU T([) MIP...</td>\n",
       "      <td>1686</td>\n",
       "      <td>210</td>\n",
       "      <td>421.50</td>\n",
       "      <td>[0.0130570084, 0.096603632, -0.0178332869, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>The retriever (Dense Passage Retriever [26], h...</td>\n",
       "      <td>1915</td>\n",
       "      <td>270</td>\n",
       "      <td>478.75</td>\n",
       "      <td>[0.0529118367, 0.0553543158, -0.0169958323, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>For FEVER [56] fact veriﬁcation, we achieve re...</td>\n",
       "      <td>949</td>\n",
       "      <td>141</td>\n",
       "      <td>237.25</td>\n",
       "      <td>[0.04941044, 0.0170666482, 0.00350169698, 0.01...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>14</td>\n",
       "      <td>URL https://www.aclweb.org/ anthology/W18-5446...</td>\n",
       "      <td>1096</td>\n",
       "      <td>143</td>\n",
       "      <td>274.00</td>\n",
       "      <td>[0.0458982587, -0.0125643425, -0.0306721888, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>14</td>\n",
       "      <td>URL https://www.aaai.org/ocs/index.php/AAAI/AA...</td>\n",
       "      <td>601</td>\n",
       "      <td>75</td>\n",
       "      <td>150.25</td>\n",
       "      <td>[-0.0198382903, -0.00296843238, -0.00132312218...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>14</td>\n",
       "      <td>URL http://arxiv.org/abs/1410.3916. [65] Jason...</td>\n",
       "      <td>218</td>\n",
       "      <td>30</td>\n",
       "      <td>54.50</td>\n",
       "      <td>[0.0296152793, 0.0490686484, -0.0122116404, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>15</td>\n",
       "      <td>International Workshop on Search-Oriented Conv...</td>\n",
       "      <td>1017</td>\n",
       "      <td>127</td>\n",
       "      <td>254.25</td>\n",
       "      <td>[0.0516357645, 0.0396283381, -0.0146658486, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>15</td>\n",
       "      <td>Association for Computational Linguistics.doi:...</td>\n",
       "      <td>340</td>\n",
       "      <td>37</td>\n",
       "      <td>85.00</td>\n",
       "      <td>[0.0213812124, 0.000230780264, 0.0173772871, 0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>65 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    page_number                                     sentence_chunk  \\\n",
       "0             0  Retrieval-Augmented Generation for Knowledge-I...   \n",
       "1             0  For language generation tasks, we ﬁnd that RAG...   \n",
       "2             1  The\u0003DiYine Comed\\\u0003(x) T QXeU\\ EQcRdeU T([) MIP...   \n",
       "3             1  The retriever (Dense Passage Retriever [26], h...   \n",
       "4             1  For FEVER [56] fact veriﬁcation, we achieve re...   \n",
       "..          ...                                                ...   \n",
       "60           14  URL https://www.aclweb.org/ anthology/W18-5446...   \n",
       "61           14  URL https://www.aaai.org/ocs/index.php/AAAI/AA...   \n",
       "62           14  URL http://arxiv.org/abs/1410.3916. [65] Jason...   \n",
       "63           15  International Workshop on Search-Oriented Conv...   \n",
       "64           15  Association for Computational Linguistics.doi:...   \n",
       "\n",
       "    chunk_char_count  chunk_word_count  chunk_token_count  \\\n",
       "0               1833               246             458.25   \n",
       "1               1139               162             284.75   \n",
       "2               1686               210             421.50   \n",
       "3               1915               270             478.75   \n",
       "4                949               141             237.25   \n",
       "..               ...               ...                ...   \n",
       "60              1096               143             274.00   \n",
       "61               601                75             150.25   \n",
       "62               218                30              54.50   \n",
       "63              1017               127             254.25   \n",
       "64               340                37              85.00   \n",
       "\n",
       "                                            embedding  \n",
       "0   [0.039727319, 0.0469269864, -0.0115035316, -0....  \n",
       "1   [0.0150031894, 0.0806403011, -0.0143866343, -0...  \n",
       "2   [0.0130570084, 0.096603632, -0.0178332869, 0.0...  \n",
       "3   [0.0529118367, 0.0553543158, -0.0169958323, 0....  \n",
       "4   [0.04941044, 0.0170666482, 0.00350169698, 0.01...  \n",
       "..                                                ...  \n",
       "60  [0.0458982587, -0.0125643425, -0.0306721888, 0...  \n",
       "61  [-0.0198382903, -0.00296843238, -0.00132312218...  \n",
       "62  [0.0296152793, 0.0490686484, -0.0122116404, 0....  \n",
       "63  [0.0516357645, 0.0396283381, -0.0146658486, 0....  \n",
       "64  [0.0213812124, 0.000230780264, 0.0173772871, 0...  \n",
       "\n",
       "[65 rows x 6 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_chunks_and_embedding_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 3.9727e-02,  4.6927e-02, -1.1504e-02, -1.5628e-03, -2.1121e-02,\n",
       "        -4.9947e-03, -2.7959e-02, -1.0972e-02, -4.3458e-03, -7.7804e-02,\n",
       "        -2.0022e-02, -2.7189e-02, -2.8272e-02,  4.2074e-02,  3.8686e-02,\n",
       "        -3.2529e-02,  3.7117e-02,  2.2119e-03,  1.2676e-02,  9.3350e-03,\n",
       "        -3.8750e-03,  5.3754e-03, -1.8202e-02,  1.9444e-02, -3.9476e-02,\n",
       "         7.7228e-03, -2.5470e-02, -6.4595e-03, -1.1813e-02, -2.3488e-02,\n",
       "         4.6452e-02,  7.3516e-02,  2.1861e-02,  1.5780e-02,  2.3155e-06,\n",
       "        -2.9542e-02, -1.6238e-02, -2.7006e-02, -4.3258e-02,  1.7498e-03,\n",
       "        -1.7556e-02,  2.2487e-02,  1.1062e-02, -1.1125e-02, -4.5319e-02,\n",
       "        -1.3302e-02,  3.0515e-02,  2.7577e-02,  5.7865e-02,  8.7594e-02,\n",
       "         6.5090e-04,  9.0065e-03,  3.5177e-02, -2.6052e-02,  5.7383e-02,\n",
       "        -8.5708e-03,  9.3581e-03, -3.3440e-02, -6.8433e-03,  3.0560e-02,\n",
       "         6.4515e-03,  3.2190e-02,  4.9336e-02, -7.7907e-03,  4.2671e-02,\n",
       "         4.0554e-02, -3.1175e-02, -3.5589e-02, -2.8664e-02,  7.4000e-02,\n",
       "         1.3135e-02, -3.8051e-02,  1.7661e-02,  7.4701e-03, -7.0262e-03,\n",
       "         1.4205e-02, -4.4321e-02,  3.6317e-02,  1.2477e-03, -1.8919e-03,\n",
       "         6.0706e-03,  1.2940e-02,  1.0752e-02,  1.5832e-02, -1.7304e-03,\n",
       "         2.0088e-02,  3.6553e-02, -1.5363e-02,  5.6013e-03,  3.3874e-02,\n",
       "        -3.5482e-02, -4.4654e-02,  1.8325e-02,  5.8389e-02, -2.5437e-02,\n",
       "         4.1331e-02, -4.3122e-02, -4.8141e-02,  2.0022e-02, -2.9093e-02,\n",
       "         3.5835e-02,  4.7633e-02, -6.0379e-03,  1.4211e-02, -6.5736e-02,\n",
       "         3.7141e-02, -1.5632e-02, -1.2006e-02, -1.7909e-02,  2.5192e-02,\n",
       "        -5.0055e-02, -4.7745e-02, -5.5142e-02,  4.8511e-02, -4.3774e-02,\n",
       "         8.9597e-04, -1.5012e-02,  2.9736e-02, -9.9426e-03, -2.1236e-03,\n",
       "         1.8480e-02,  4.7759e-02, -4.6412e-02,  1.8142e-02, -4.6236e-02,\n",
       "        -1.7546e-02, -3.8946e-02,  1.0105e-02,  6.7993e-02, -2.2556e-02,\n",
       "        -2.3467e-02,  1.5901e-04,  2.1246e-02, -3.7425e-02,  1.3139e-02,\n",
       "         2.4198e-02, -2.4988e-02, -1.8601e-02, -6.5358e-02, -8.2639e-02,\n",
       "        -1.9484e-02, -6.6761e-02,  3.4437e-02, -5.4059e-02,  4.8263e-02,\n",
       "         2.4013e-02, -4.7073e-02, -5.6714e-02,  2.0787e-02,  5.1627e-02,\n",
       "        -3.3865e-02,  1.5021e-02,  3.7482e-03,  2.3546e-03,  1.1280e-02,\n",
       "         3.1024e-02,  1.9917e-02,  5.9723e-02,  2.3005e-02,  4.7352e-02,\n",
       "         4.4401e-02,  2.4483e-02, -2.0522e-02, -7.8116e-03,  6.6221e-02,\n",
       "        -4.7173e-03, -1.9860e-02, -2.1511e-03,  3.1608e-03,  1.3103e-02,\n",
       "         3.9163e-02,  4.4033e-02, -4.1150e-02,  1.1921e-02,  4.4954e-02,\n",
       "        -3.7245e-03,  1.8583e-02,  2.3763e-02,  1.0401e-01, -1.2863e-02,\n",
       "         9.6793e-03,  1.4893e-02, -3.8577e-02,  4.0749e-02, -2.5977e-02,\n",
       "         1.9492e-02,  3.4403e-02,  3.5588e-02, -4.2562e-02, -4.3522e-02,\n",
       "         2.3899e-02,  6.9768e-04, -5.0167e-03, -6.7889e-03,  1.7014e-02,\n",
       "         6.6140e-02, -5.6767e-02,  7.8593e-02,  6.6267e-03, -7.8346e-02,\n",
       "         5.1488e-02, -2.3305e-02,  1.9452e-02,  4.6285e-02,  6.4318e-02,\n",
       "        -2.8799e-02, -3.0670e-02,  3.7631e-02, -4.1200e-03,  4.2820e-02,\n",
       "         4.5883e-02, -9.0646e-03, -1.6934e-02, -3.7789e-02, -1.2036e-02,\n",
       "        -5.7573e-02,  2.6686e-02,  2.3364e-02,  7.0833e-02,  3.3073e-02,\n",
       "         6.9795e-02, -2.2049e-02, -4.5289e-02,  1.8961e-02, -7.4939e-02,\n",
       "        -5.1751e-02, -3.6810e-04,  1.4484e-02, -1.4445e-02,  3.0151e-02,\n",
       "        -5.8168e-03,  4.6962e-02,  3.6480e-02, -1.7914e-02, -2.0002e-02,\n",
       "         1.5154e-02, -7.6473e-02, -5.4186e-02,  8.8791e-03,  4.2194e-02,\n",
       "         2.6766e-02,  5.5910e-03,  2.5443e-03, -6.0510e-02,  2.8570e-02,\n",
       "        -2.2348e-02,  6.8166e-02, -6.0472e-02,  1.5785e-02,  6.4230e-02,\n",
       "         6.3684e-03, -1.9288e-02,  8.7833e-02, -6.0723e-04, -1.4068e-03,\n",
       "         3.1692e-02,  3.4883e-02, -1.4601e-02, -2.3615e-02, -1.7186e-02,\n",
       "        -1.1420e-04, -9.7884e-04,  2.5827e-02,  4.8322e-02,  4.7984e-03,\n",
       "        -7.8267e-02, -1.8001e-02, -7.7677e-02,  2.3507e-02, -4.2520e-02,\n",
       "        -1.0894e-02,  3.4355e-02,  1.0739e-02, -9.8284e-04, -2.4110e-03,\n",
       "        -5.4319e-02,  2.7121e-02,  3.3048e-02,  4.1428e-02,  1.1917e-02,\n",
       "         4.7783e-02,  4.7381e-02, -2.3582e-02, -1.1043e-02,  1.1368e-02,\n",
       "         2.9691e-02,  1.1787e-02,  1.8360e-02, -9.1179e-03,  5.6027e-02,\n",
       "        -6.6077e-02,  1.2410e-02,  1.8386e-04, -8.1050e-03,  5.6524e-03,\n",
       "        -2.7893e-02,  8.1513e-02,  8.8954e-03,  1.6548e-02,  2.9866e-02,\n",
       "         1.6396e-02, -4.6440e-02, -4.2960e-02,  4.4051e-02, -5.1201e-02,\n",
       "        -2.6690e-02,  2.9265e-02,  3.1367e-02,  2.2408e-02,  6.9373e-02,\n",
       "        -1.8256e-02, -2.5477e-02, -6.6232e-02,  3.1603e-02, -6.0500e-03,\n",
       "        -4.3427e-02, -2.1130e-02, -1.6626e-02, -6.6381e-03,  3.5281e-02,\n",
       "        -3.7160e-02, -3.6049e-02,  4.8401e-02, -1.5634e-02,  6.3513e-03,\n",
       "        -4.0714e-02,  3.9324e-02, -9.0220e-03,  7.3175e-02,  1.4645e-02,\n",
       "         3.2016e-02, -1.1183e-02,  3.9690e-03, -4.7160e-02,  2.6078e-02,\n",
       "        -1.5009e-02, -4.7279e-02,  1.9503e-02, -4.9404e-02,  1.5822e-02,\n",
       "         3.6623e-03, -4.5001e-02, -7.8850e-02, -2.0070e-02,  4.6823e-02,\n",
       "         1.2306e-02,  8.2244e-03, -1.5519e-02,  1.0966e-02, -1.9557e-02,\n",
       "         4.2557e-02,  4.1685e-02, -2.3158e-02, -1.1972e-02, -2.4429e-02,\n",
       "         4.2042e-02,  7.7818e-02,  1.5087e-02,  1.3480e-02, -2.1557e-02,\n",
       "        -8.3567e-03,  5.2686e-02,  5.5682e-02, -2.8960e-02,  1.6249e-02,\n",
       "         1.3829e-02,  2.4069e-02, -4.7761e-02, -2.9474e-02,  1.9740e-02,\n",
       "         3.1700e-02, -5.9854e-02, -6.6563e-02,  9.4310e-02,  2.7595e-02,\n",
       "        -4.4295e-02,  7.4683e-03,  1.8695e-02,  5.5979e-02, -1.2457e-03,\n",
       "         3.8382e-02, -3.9002e-02,  1.3756e-03, -1.0065e-02,  1.7066e-02,\n",
       "        -2.5613e-02, -5.7194e-02, -4.6042e-02, -1.1216e-01,  1.5312e-02,\n",
       "         1.1132e-02, -1.7248e-02, -1.4108e-02, -6.4487e-03, -2.6400e-02,\n",
       "         3.6525e-02,  1.1127e-02,  5.0908e-02, -1.2013e-02,  3.0963e-02,\n",
       "         1.8547e-02,  2.1406e-02, -4.7592e-02, -7.2796e-03, -1.6582e-02,\n",
       "         1.1368e-02,  1.6277e-02,  1.9731e-02,  1.4185e-02, -7.5880e-03,\n",
       "         4.6288e-03, -4.6282e-02,  1.5623e-02,  3.9094e-04,  3.6444e-02,\n",
       "        -1.7286e-02, -4.9750e-03, -3.3967e-02,  1.9324e-02, -2.8827e-02,\n",
       "        -4.0415e-02, -2.1533e-02,  5.0523e-02, -2.1996e-02, -4.6849e-03,\n",
       "        -1.1672e-02,  1.3911e-03,  3.5800e-02,  7.0193e-02,  2.4272e-02,\n",
       "        -1.8293e-02, -3.0736e-02, -1.4415e-03,  1.7793e-02, -9.4181e-02,\n",
       "        -1.7704e-02, -4.1039e-03,  2.3051e-03,  6.7556e-03, -1.2682e-01,\n",
       "        -5.9649e-02, -5.6221e-03,  7.0049e-02, -1.9865e-03, -1.4574e-02,\n",
       "         1.8605e-02, -4.7791e-02, -8.5436e-02,  1.4805e-02, -2.0487e-02,\n",
       "        -4.3754e-02, -3.1856e-02, -5.8227e-02,  2.4043e-02, -5.5879e-02,\n",
       "        -7.2841e-03,  1.0188e-02, -4.2292e-02, -6.1487e-02,  9.7838e-03,\n",
       "         8.5725e-02,  1.7630e-02,  3.7438e-02, -5.1559e-03, -1.9242e-02,\n",
       "         7.7854e-02,  4.7136e-02, -7.4223e-02,  1.4872e-02, -6.8838e-03,\n",
       "         9.1478e-03, -2.3261e-02,  3.5607e-02, -6.0032e-02, -5.6404e-03,\n",
       "         9.2323e-03,  7.1136e-02,  2.4221e-02, -2.0898e-03,  3.3108e-02,\n",
       "         9.8190e-04,  1.7362e-02, -4.6582e-03,  1.6691e-02, -5.7603e-02,\n",
       "        -1.7663e-02, -3.0738e-02, -1.7071e-02, -3.4459e-02,  1.1151e-02,\n",
       "        -1.4624e-02, -1.0178e-02, -1.9148e-02,  7.1230e-03,  2.1745e-02,\n",
       "         4.6641e-02, -3.7013e-02, -7.8933e-02, -3.1065e-02, -3.0063e-03,\n",
       "         2.6598e-02, -1.0924e-02, -2.8469e-02,  6.9809e-03, -1.8725e-02,\n",
       "         4.8809e-02, -5.5086e-02,  6.1460e-02,  2.0659e-02, -2.0554e-02,\n",
       "         2.3215e-04,  3.3249e-02, -6.1367e-02, -2.9742e-02, -2.0736e-02,\n",
       "        -1.3295e-02,  6.9568e-02, -4.8293e-02,  5.6843e-02, -5.2865e-02,\n",
       "         5.6020e-03, -2.8737e-02,  2.3440e-02,  2.3000e-02, -3.8192e-02,\n",
       "        -7.2701e-03,  1.8379e-02, -2.5367e-02, -2.6161e-03,  6.6678e-02,\n",
       "         1.8423e-02,  5.2445e-02, -8.6059e-03,  2.9860e-03, -3.2968e-02,\n",
       "        -6.6612e-02, -1.9669e-02,  3.1797e-03, -3.2311e-02,  7.5995e-03,\n",
       "        -4.4849e-02, -6.8795e-02,  3.6087e-03, -2.3169e-02, -1.9966e-02,\n",
       "         1.4624e-02,  4.0260e-02,  6.7009e-02, -3.0945e-02, -1.1452e-02,\n",
       "        -5.1368e-02,  5.0406e-02, -5.9942e-02, -9.7991e-03,  1.1888e-02,\n",
       "        -6.8688e-33, -4.2296e-02, -2.1892e-02,  5.4688e-02, -3.2342e-02,\n",
       "        -2.4695e-02,  1.4016e-02, -5.5531e-02, -1.2305e-02,  2.5572e-04,\n",
       "        -1.2886e-02, -2.9825e-02, -2.2797e-02,  1.7420e-04,  3.9221e-02,\n",
       "        -2.1438e-02, -6.7575e-03,  3.7021e-02,  1.0716e-02, -4.4362e-02,\n",
       "         7.8293e-02,  8.8862e-02,  4.5928e-02,  5.1203e-02,  3.8547e-03,\n",
       "         1.3574e-03, -8.9712e-04,  3.4713e-02,  1.7822e-03,  1.6099e-02,\n",
       "         4.9165e-02, -1.8168e-02,  3.9126e-02,  1.8872e-02, -2.4478e-02,\n",
       "        -2.8512e-02, -1.7026e-02, -7.6463e-02, -4.7197e-02, -1.2744e-02,\n",
       "        -8.7027e-03, -5.5845e-02, -2.6137e-02,  3.4686e-02, -2.3527e-02,\n",
       "         5.3414e-03,  3.8053e-02,  1.2559e-03,  1.0339e-02, -8.5051e-03,\n",
       "        -4.3651e-02, -6.9152e-02, -6.9203e-03,  3.7568e-02, -2.6554e-02,\n",
       "        -3.0928e-02,  3.9236e-02,  1.8027e-02, -1.9477e-02, -8.2156e-02,\n",
       "         1.9754e-02, -2.8240e-02,  8.7287e-02,  3.6747e-02,  1.2222e-02,\n",
       "         8.1716e-03,  6.4427e-02, -1.6087e-02,  1.8698e-02, -3.3174e-02,\n",
       "         2.9678e-02,  3.0898e-02,  3.4152e-02, -9.1153e-03,  7.2029e-03,\n",
       "         2.0523e-02, -3.2700e-02, -3.8593e-02,  4.0002e-02,  4.7538e-03,\n",
       "         4.8293e-02,  2.0942e-02, -4.2354e-02,  3.1001e-04, -1.2922e-02,\n",
       "        -4.9595e-02,  1.1908e-02, -1.8765e-02, -2.2111e-02,  5.0923e-02,\n",
       "         6.8679e-02, -2.0447e-02, -1.1848e-02,  1.8056e-02,  8.1999e-03,\n",
       "         2.4197e-02,  4.6691e-02, -4.2902e-02, -2.1074e-02, -3.3885e-02,\n",
       "         2.3938e-02, -5.7601e-02, -4.0404e-02,  3.9929e-02, -1.3867e-02,\n",
       "        -2.6929e-02,  3.0099e-02,  1.1046e-02,  5.0532e-02, -2.8989e-02,\n",
       "         2.8016e-02, -7.0762e-02,  7.0291e-02,  1.9559e-02, -1.3079e-02,\n",
       "         4.1282e-02,  2.7499e-02, -2.9912e-02,  3.7027e-02,  3.1392e-02,\n",
       "        -2.2717e-02, -2.1907e-02, -3.8723e-02,  3.6187e-02,  3.2346e-02,\n",
       "        -2.2022e-02,  1.2279e-02, -3.3051e-02,  4.2645e-02, -4.9042e-03,\n",
       "        -4.9510e-02,  1.2501e-02,  6.0554e-03,  3.0526e-07, -2.3824e-03,\n",
       "         9.5230e-03,  3.2790e-02,  9.5943e-03,  1.2097e-02, -1.5921e-02,\n",
       "         8.7368e-03,  3.4915e-02, -1.9643e-02, -2.7682e-02, -1.6473e-02,\n",
       "         5.3190e-02,  2.1628e-02,  4.1474e-03, -7.8086e-02, -2.9998e-02,\n",
       "        -4.8392e-02,  4.0636e-03, -5.4968e-02, -4.8424e-02,  4.9766e-02,\n",
       "         3.1075e-02, -9.5157e-03, -9.3982e-03,  3.7362e-03, -4.7331e-02,\n",
       "         9.4434e-02,  1.1354e-02, -2.6432e-02,  2.2621e-02,  5.1113e-02,\n",
       "         4.2515e-02, -2.4915e-03,  1.3958e-02, -5.0613e-02,  2.1003e-02,\n",
       "        -9.9116e-03,  6.1511e-02,  3.6245e-02, -7.0713e-02,  4.0453e-03,\n",
       "        -9.9432e-04,  2.6487e-03, -5.1918e-02,  6.0157e-02, -2.7023e-02,\n",
       "        -3.1130e-03,  2.7035e-02, -2.9100e-02, -1.4998e-03, -1.4055e-02,\n",
       "        -2.5132e-02, -3.8105e-02,  2.7375e-02,  4.2169e-03,  4.8753e-02,\n",
       "        -1.3521e-02, -9.1289e-02, -3.1964e-02,  9.7594e-03, -2.7228e-02,\n",
       "        -3.4317e-02, -6.2294e-02, -2.0338e-02,  4.7201e-04, -5.7367e-02,\n",
       "        -1.4569e-02,  3.2761e-34,  1.5900e-02,  3.5694e-03,  5.4900e-03,\n",
       "         1.5853e-03,  2.1172e-02, -1.2441e-03,  2.0081e-03,  1.2108e-02,\n",
       "         2.4547e-02, -6.9855e-02, -4.5444e-02], device='cuda:0')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 準備embedding model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ailab\\anaconda3\\envs\\MYRAG\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import util, SentenceTransformer\n",
    "\n",
    "embedding_model = SentenceTransformer(model_name_or_path=\"all-mpnet-base-v2\", \n",
    "                                      device=device) # choose the device to load the model to\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: Retrieval Augmentation generation\n",
      "Time take to get scores on 65 embeddings: 0.00017 seconds.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.return_types.topk(\n",
       "values=tensor([0.5734, 0.5266, 0.5069, 0.5056, 0.4899], device='cuda:0'),\n",
       "indices=tensor([ 7, 39,  0,  6, 26], device='cuda:0'))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Define the query\n",
    "# Note: This could be anything. But since we're working with a nutrition textbook, we'll stick with nutrition-based queries.\n",
    "query = \"Retrieval Augmentation generation\"\n",
    "print(f\"Query: {query}\")\n",
    "\n",
    "# 2. Embed the query to the same numerical space as the text examples \n",
    "# Note: It's important to embed your query with the same model you embedded your examples with.\n",
    "query_embedding = embedding_model.encode(query, convert_to_tensor=True)\n",
    "\n",
    "# 3. Get similarity scores with the dot product (we'll time this for fun)\n",
    "from time import perf_counter as timer\n",
    "\n",
    "start_time = timer()\n",
    "dot_scores = util.dot_score(a=query_embedding, b=embeddings)[0]\n",
    "end_time = timer()\n",
    "\n",
    "print(f\"Time take to get scores on {len(embeddings)} embeddings: {end_time-start_time:.5f} seconds.\")\n",
    "\n",
    "# 4. Get the top-k results (we'll keep this to 5)\n",
    "top_results_dot_product = torch.topk(dot_scores, k=5)\n",
    "top_results_dot_product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define helper function to print wrapped text \n",
    "import textwrap\n",
    "\n",
    "def print_wrapped(text, wrap_length=80):\n",
    "    wrapped_text = textwrap.fill(text, wrap_length)\n",
    "    print(wrapped_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: 'Retrieval Augmentation generation'\n",
      "\n",
      "Results:\n",
      "Score: 0.5734\n",
      "Text:\n",
      "It has obtained state-of-the-art results on a diverse set of generation tasks\n",
      "and outperforms comparably-sized T5 models [32]. We refer to the BART generator\n",
      "parameters ✓ as the parametric memory henceforth.2.4 Training We jointly train\n",
      "the retriever and generator components without any direct supervision on what\n",
      "document should be retrieved. Given a ﬁne-tuning training corpus of input/output\n",
      "pairs (xj, yj), we 3\n",
      "Page number: 2\n",
      "\n",
      "\n",
      "Score: 0.5266\n",
      "Text:\n",
      "[19] Kelvin Guu, Tatsunori B. Hashimoto, Yonatan Oren, and Percy Liang.\n",
      "Generating sentences by editing prototypes. Transactions of the Association for\n",
      "Computational Linguistics, 6:437–450, 2018.doi: 10.1162/tacl_a_00030. URL\n",
      "https://www.aclweb.org/anthology/Q18-1031. [20] Kelvin Guu, Kenton Lee, Zora\n",
      "Tung, Panupong Pasupat, and Ming-Wei Chang. REALM: Retrieval-augmented language\n",
      "model pre-training. ArXiv, abs/2002.08909, 2020. URL https:\n",
      "//arxiv.org/abs/2002.08909. [21] Tatsunori B Hashimoto, Kelvin Guu, Yonatan\n",
      "Oren, and Percy S Liang.\n",
      "Page number: 11\n",
      "\n",
      "\n",
      "Score: 0.5069\n",
      "Text:\n",
      "Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks Patrick\n",
      "Lewis†‡, Ethan Perez?,Aleksandra Piktus†, Fabio Petroni†, Vladimir Karpukhin†,\n",
      "Naman Goyal†, Heinrich Küttler†, Mike Lewis†, Wen-tau Yih†, Tim Rocktäschel†‡,\n",
      "Sebastian Riedel†‡, Douwe Kiela† †Facebook AI Research; ‡University College\n",
      "London; ?New York University; plewis@fb.com Abstract Large pre-trained language\n",
      "models have been shown to store factual knowledge in their parameters, and\n",
      "achieve state-of-the-art results when ﬁne-tuned on down- stream NLP tasks.\n",
      "However, their ability to access and precisely manipulate knowledge is still\n",
      "limited, and hence on knowledge-intensive tasks, their perfor- mance lags behind\n",
      "task-speciﬁc architectures. Additionally, providing provenance for their\n",
      "decisions and updating their world knowledge remain open research prob- lems.\n",
      "Pre-trained models with a differentiable access mechanism to explicit non-\n",
      "parametric memory can overcome this issue, but have so far been only\n",
      "investigated for extractive downstream tasks. We explore a general-purpose ﬁne-\n",
      "tuning recipe for retrieval-augmented generation (RAG) — models which combine\n",
      "pre-trained parametric and non-parametric memory for language generation. We\n",
      "introduce RAG models where the parametric memory is a pre-trained seq2seq model\n",
      "and the non-parametric memory is a dense vector index of Wikipedia, accessed\n",
      "with a pre-trained neural retriever. We compare two RAG formulations, one which\n",
      "conditions on the same retrieved passages across the whole generated sequence,\n",
      "and another which can use different passages per token. We ﬁne-tune and evaluate\n",
      "our models on a wide range of knowledge-intensive NLP tasks and set the state of\n",
      "the art on three open domain QA tasks, outperforming parametric seq2seq models\n",
      "and task-speciﬁc retrieve-and-extract architectures.\n",
      "Page number: 0\n",
      "\n",
      "\n",
      "Score: 0.5056\n",
      "Text:\n",
      "2.2 Retriever: DPR The retrieval component p⌘(z|x) is based on DPR [26]. DPR\n",
      "follows a bi-encoder architecture: p⌘(z|x) / exp # d(z)>q(x) $ d(z) = BERTd(z),\n",
      "q(x) = BERTq(x) where d(z) is a dense representation of a document produced by a\n",
      "BERTBASE document encoder [8], and q(x) a query representation produced by a\n",
      "query encoder, also based on BERTBASE. Calculating top-k(p⌘(·|x)), the list of k\n",
      "documents z with highest prior probability p⌘(z|x), is a Maximum Inner Product\n",
      "Search (MIPS) problem, which can be approximately solved in sub-linear time\n",
      "[23]. We use a pre-trained bi-encoder from DPR to initialize our retriever and\n",
      "to build the document index. This retriever was trained to retrieve documents\n",
      "which contain answers to TriviaQA [24] questions and Natural Questions [29]. We\n",
      "refer to the document index as the non-parametric memory.2.3 Generator: BART The\n",
      "generator component p✓(yi|x, z, y1:i−1) could be modelled using any encoder-\n",
      "decoder. We use BART-large [32], a pre-trained seq2seq transformer [58] with\n",
      "400M parameters. To combine the input x with the retrieved content z when\n",
      "generating from BART, we simply concatenate them. BART was pre-trained using a\n",
      "denoising objective and a variety of different noising functions.\n",
      "Page number: 2\n",
      "\n",
      "\n",
      "Score: 0.4899\n",
      "Text:\n",
      "General-Purpose Architectures for NLP Prior work on general-purpose\n",
      "architectures for NLP tasks has shown great success without the use of\n",
      "retrieval. A single, pre-trained language model has been shown to achieve strong\n",
      "performance on various classiﬁcation tasks in the GLUE bench- marks [60, 61]\n",
      "after ﬁne-tuning [49, 8]. GPT-2 [50] later showed that a single, left-to-right,\n",
      "pre-trained language model could achieve strong performance across both\n",
      "discriminative and generative tasks. For further improvement, BART [32] and T5\n",
      "[51, 52] propose a single, pre-trained encoder-decoder model that leverages bi-\n",
      "directional attention to achieve stronger performance on discriminative and\n",
      "generative tasks. Our work aims to expand the space of possible tasks with a\n",
      "single, uniﬁed architecture, by learning a retrieval module to augment pre-\n",
      "trained, generative language models. Learned Retrieval There is signiﬁcant work\n",
      "on learning to retrieve documents in information retrieval, more recently with\n",
      "pre-trained, neural language models [44, 26] similar to ours. Some work\n",
      "optimizes the retrieval module to aid in a speciﬁc, downstream task such as\n",
      "question answering, using search [46], reinforcement learning [6, 63, 62], or a\n",
      "latent variable approach [31, 20] as in our work. These successes leverage\n",
      "different retrieval-based architectures and optimization techniques to achieve\n",
      "strong performance on a single task, while we show that a single retrieval-based\n",
      "architecture can be ﬁne-tuned for strong performance on a variety of tasks.\n",
      "Memory-based Architectures Our document index can be seen as a large external\n",
      "memory for neural networks to attend to, analogous to memory networks [64, 55].\n",
      "Concurrent work [14] learns to retrieve a trained embedding for each entity in\n",
      "the input, rather than to retrieve raw text as in our work.\n",
      "Page number: 8\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Query: '{query}'\\n\")\n",
    "print(\"Results:\")\n",
    "# Loop through zipped together scores and indicies from torch.topk\n",
    "for score, idx in zip(top_results_dot_product[0], top_results_dot_product[1]):\n",
    "    print(f\"Score: {score:.4f}\")\n",
    "    # Print relevant sentence chunk (since the scores are in descending order, the most relevant chunk will be first)\n",
    "    print(\"Text:\")\n",
    "    print_wrapped(pages_and_chunks[idx][\"sentence_chunk\"])\n",
    "    # Print the page number too so we can reference the textbook further (and check the results)\n",
    "    print(f\"Page number: {pages_and_chunks[idx]['page_number']}\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "相似度計算: 點積dot product & Cosine similarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "\n",
    "# def dot_product(vector1, vector2):\n",
    "#     return torch.dot(vector1, vector2)\n",
    "\n",
    "# def cosine_similarity(vector1, vector2):\n",
    "#     dot_product = torch.dot(vector1, vector2)\n",
    "\n",
    "#     # Get Euclidean/L2 norm of each vector (removes the magnitude, keeps direction)\n",
    "#     norm_vector1 = torch.sqrt(torch.sum(vector1**2))\n",
    "#     norm_vector2 = torch.sqrt(torch.sum(vector2**2))\n",
    "\n",
    "#     return dot_product / (norm_vector1 * norm_vector2)\n",
    "\n",
    "# # Example tensors\n",
    "# vector1 = torch.tensor([1, 2, 3], dtype=torch.float32)\n",
    "# vector2 = torch.tensor([1, 2, 3], dtype=torch.float32)\n",
    "# vector3 = torch.tensor([8, 16, 24], dtype=torch.float32)\n",
    "# vector4 = torch.tensor([1, 2, 3], dtype=torch.float32)\n",
    "\n",
    "# # Calculate dot product\n",
    "# print(\"Dot product between vector1 and vector2:\", dot_product(vector1, vector2))\n",
    "# print(\"Dot product between vector1 and vector3:\", dot_product(vector1, vector3))\n",
    "# print(\"Dot product between vector1 and vector4:\", dot_product(vector1, vector4))\n",
    "\n",
    "# # Calculate cosine similarity\n",
    "# print(\"Cosine similarity between vector1 and vector2:\", cosine_similarity(vector1, vector2))\n",
    "# print(\"Cosine similarity between vector1 and vector3:\", cosine_similarity(vector1, vector3))\n",
    "# print(\"Cosine similarity between vector1 and vector4:\", cosine_similarity(vector1, vector4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定義\"相似語意搜尋\"的函數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_relevant_resources(query: str,\n",
    "                                embeddings: torch.tensor,\n",
    "                                model: SentenceTransformer=embedding_model,\n",
    "                                n_resources_to_return: int=5,\n",
    "                                print_time: bool=True):\n",
    "    \"\"\"\n",
    "    Embeds a query with model and returns top k scores and indices from embeddings.\n",
    "    \"\"\"\n",
    "\n",
    "    # Embed the query\n",
    "    query_embedding = model.encode(query, \n",
    "                                   convert_to_tensor=True) \n",
    "\n",
    "    # Get dot product scores on embeddings\n",
    "    start_time = timer()\n",
    "    dot_scores = util.dot_score(query_embedding, embeddings)[0]\n",
    "    end_time = timer()\n",
    "\n",
    "    if print_time:\n",
    "        print(f\"[INFO] Time taken to get scores on {len(embeddings)} embeddings: {end_time-start_time:.5f} seconds.\")\n",
    "\n",
    "    scores, indices = torch.topk(input=dot_scores, \n",
    "                                 k=n_resources_to_return)\n",
    "\n",
    "    return scores, indices\n",
    "\n",
    "def print_top_results_and_scores(query: str,\n",
    "                                 embeddings: torch.tensor,\n",
    "                                 pages_and_chunks: list[dict]=pages_and_chunks,\n",
    "                                 n_resources_to_return: int=5):\n",
    "    \"\"\"\n",
    "    Takes a query, retrieves most relevant resources and prints them out in descending order.\n",
    "\n",
    "    Note: Requires pages_and_chunks to be formatted in a specific way (see above for reference).\n",
    "    \"\"\"\n",
    "    \n",
    "    scores, indices = retrieve_relevant_resources(query=query,\n",
    "                                                  embeddings=embeddings,\n",
    "                                                  n_resources_to_return=n_resources_to_return)\n",
    "    \n",
    "    print(f\"Query: {query}\\n\")\n",
    "    print(\"Results:\")\n",
    "    # Loop through zipped together scores and indicies\n",
    "    for score, index in zip(scores, indices):\n",
    "        print(f\"Score: {score:.4f}\")\n",
    "        # Print relevant sentence chunk (since the scores are in descending order, the most relevant chunk will be first)\n",
    "        print_wrapped(pages_and_chunks[index][\"sentence_chunk\"])\n",
    "        # Print the page number too so we can reference the textbook further and check the results\n",
    "        print(f\"Page number: {pages_and_chunks[index]['page_number']}\")\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Excellent! Now let's test our functions out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Time taken to get scores on 65 embeddings: 0.00005 seconds.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([0.4710, 0.3714, 0.3547, 0.3463, 0.3426], device='cuda:0'),\n",
       " tensor([ 6,  4, 25, 48,  5], device='cuda:0'))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"data retrieval\"\n",
    "\n",
    "# Get just the scores and indices of top related results\n",
    "scores, indices = retrieve_relevant_resources(query=query,\n",
    "                                              embeddings=embeddings)\n",
    "scores, indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Time taken to get scores on 65 embeddings: 0.00005 seconds.\n",
      "Query: data retrieval\n",
      "\n",
      "Results:\n",
      "Score: 0.4710\n",
      "2.2 Retriever: DPR The retrieval component p⌘(z|x) is based on DPR [26]. DPR\n",
      "follows a bi-encoder architecture: p⌘(z|x) / exp # d(z)>q(x) $ d(z) = BERTd(z),\n",
      "q(x) = BERTq(x) where d(z) is a dense representation of a document produced by a\n",
      "BERTBASE document encoder [8], and q(x) a query representation produced by a\n",
      "query encoder, also based on BERTBASE. Calculating top-k(p⌘(·|x)), the list of k\n",
      "documents z with highest prior probability p⌘(z|x), is a Maximum Inner Product\n",
      "Search (MIPS) problem, which can be approximately solved in sub-linear time\n",
      "[23]. We use a pre-trained bi-encoder from DPR to initialize our retriever and\n",
      "to build the document index. This retriever was trained to retrieve documents\n",
      "which contain answers to TriviaQA [24] questions and Natural Questions [29]. We\n",
      "refer to the document index as the non-parametric memory.2.3 Generator: BART The\n",
      "generator component p✓(yi|x, z, y1:i−1) could be modelled using any encoder-\n",
      "decoder. We use BART-large [32], a pre-trained seq2seq transformer [58] with\n",
      "400M parameters. To combine the input x with the retrieved content z when\n",
      "generating from BART, we simply concatenate them. BART was pre-trained using a\n",
      "denoising objective and a variety of different noising functions.\n",
      "Page number: 2\n",
      "\n",
      "\n",
      "Score: 0.3714\n",
      "For FEVER [56] fact veriﬁcation, we achieve results within 4.3% of state-of-the-\n",
      "art pipeline models which use strong retrieval supervision. Finally, we\n",
      "demonstrate that the non-parametric memory can be replaced to update the models’\n",
      "knowledge as the world changes.1 2 Methods We explore RAG models, which use the\n",
      "input sequence x to retrieve text documents z and use them as additional context\n",
      "when generating the target sequence y. As shown in Figure 1, our models leverage\n",
      "two components: (i) a retriever p⌘(z|x) with parameters ⌘ that returns (top-K\n",
      "truncated) distributions over text passages given a query x and (ii) a generator\n",
      "p✓(yi|x, z, y1:i−1) parametrized 1Code to run experiments with RAG has been\n",
      "open-sourced as part of the HuggingFace Transform- ers Library [66] and can be\n",
      "found at https://github.com/huggingface/transformers/blob/master/ examples/rag/.\n",
      "An interactive demo of RAG models can be found at https://huggingface.co/rag/ 2\n",
      "Page number: 1\n",
      "\n",
      "\n",
      "Score: 0.3547\n",
      "We have the ﬂexibility to adjust the number of retrieved documents at test time,\n",
      "which can affect performance and runtime. Figure 3 (left) shows that retrieving\n",
      "more documents at test time monotonically improves Open-domain QA results for\n",
      "RAG-Sequence, but performance peaks for RAG-Token at 10 retrieved documents.\n",
      "Figure 3 (right) shows that retrieving more documents leads to higher Rouge-L\n",
      "for RAG-Token at the expense of Bleu-1, but the effect is less pronounced for\n",
      "RAG-Sequence.10 20 30 40 50 K Retrieved Docs 39 40 41 42 43 44 NQ Exact Match\n",
      "RAG-Tok RAG-Seq 10 20 30 40 50 K Retrieved Docs 40 50 60 70 80 NQ Answer Recall\n",
      "@ K RAG-Tok RAG-Seq Fixed DPR BM25 10 20 30 40 50 K Retrieved Docs 48 50 52 54\n",
      "56 Bleu-1 / Rouge-L score RAG-Tok R-L RAG-Tok B-1 RAG-Seq R-L RAG-Seq B-1 Figure\n",
      "3: Left: NQ performance as more documents are retrieved. Center: Retrieval\n",
      "recall perfor- mance in NQ. Right: MS-MARCO Bleu-1 and Rouge-L as more documents\n",
      "are retrieved.5 Related Work Single-Task Retrieval Prior work has shown that\n",
      "retrieval improves performance across a variety of NLP tasks when considered in\n",
      "isolation. Such tasks include open-domain question answering [5, 29], fact\n",
      "checking [56], fact completion [48], long-form question answering [12],\n",
      "Wikipedia article generation [36], dialogue [41, 65, 9, 13], translation [17],\n",
      "and language modeling [19, 27]. Our work uniﬁes previous successes in\n",
      "incorporating retrieval into individual tasks, showing that a single retrieval-\n",
      "based architecture is capable of achieving strong performance across several\n",
      "tasks.8\n",
      "Page number: 7\n",
      "\n",
      "\n",
      "Score: 0.3463\n",
      "id=Hyg0vbWC-. [37] Yury A. Malkov and D. A. Yashunin. Efﬁcient and robust\n",
      "approximate nearest neighbor search using hierarchical navigable small world\n",
      "graphs. IEEE Transactions on Pattern Analysis and Machine Intelligence,\n",
      "42:824–836, 2016. URL https://arxiv.org/abs/1603.09320. [38] Gary Marcus. The\n",
      "next decade in ai: four steps towards robust artiﬁcial intelligence.arXiv\n",
      "preprint arXiv:2002.06177, 2020. URL https://arxiv.org/abs/2002.06177. [39] Luca\n",
      "Massarelli, Fabio Petroni, Aleksandra Piktus, Myle Ott, Tim Rocktäschel,\n",
      "Vassilis Plachouras, Fabrizio Silvestri, and Sebastian Riedel.\n",
      "Page number: 12\n",
      "\n",
      "\n",
      "Score: 0.3426\n",
      "by ✓ that generates a current token based on a context of the previous i − 1\n",
      "tokens y1:i−1, the original input x and a retrieved passage z. To train the\n",
      "retriever and generator end-to-end, we treat the retrieved document as a latent\n",
      "variable. We propose two models that marginalize over the latent documents in\n",
      "different ways to produce a distribution over generated text. In one approach,\n",
      "RAG-Sequence, the model uses the same document to predict each target token. The\n",
      "second approach, RAG-Token, can predict each target token based on a different\n",
      "document. In the following, we formally introduce both models and then describe\n",
      "the p⌘ and p✓ components, as well as the training and decoding procedure.2.1\n",
      "Models RAG-Sequence Model The RAG-Sequence model uses the same retrieved\n",
      "document to generate the complete sequence. Technically, it treats the retrieved\n",
      "document as a single latent variable that is marginalized to get the seq2seq\n",
      "probability p(y|x) via a top-K approximation. Concretely, the top K documents\n",
      "are retrieved using the retriever, and the generator produces the output\n",
      "sequence probability for each document, which are then marginalized, pRAG-\n",
      "Sequence(y|x) ⇡ X z2top-k(p(·|x)) p⌘(z|x)p✓(y|x, z) = X z2top-k(p(·|x)) p⌘(z|x)\n",
      "N Y i p✓(yi|x, z, y1:i−1) RAG-Token Model In the RAG-Token model we can draw a\n",
      "different latent document for each target token and marginalize accordingly.\n",
      "This allows the generator to choose content from several documents when\n",
      "producing an answer. Concretely, the top K documents are retrieved using the\n",
      "retriever, and then the generator produces a distribution for the next output\n",
      "token for each document, before marginalizing, and repeating the process with\n",
      "the following output token, Formally, we deﬁne: pRAG-Token(y|x) ⇡ N Y i X\n",
      "z2top-k(p(·|x)) p⌘(z|x)p✓(yi|x, zi, y1:i−1) Finally, we note that RAG can be\n",
      "used for sequence classiﬁcation tasks by considering the target class as a\n",
      "target sequence of length one, in which case RAG-Sequence and RAG-Token are\n",
      "equivalent.\n",
      "Page number: 2\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print out the texts of the top scores\n",
    "print_top_results_and_scores(query=query,\n",
    "                             embeddings=embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(延伸)語義搜索/向量搜索 \n",
    "\n",
    "數據集小--> 可將查詢跟每一個可能的結果比較  \n",
    "大規模數據集-->Inedx。\n",
    "\n",
    "Index--> embeddings的排序\n",
    "\n",
    "因此它可以縮小搜索範圍。\n",
    "\n",
    "例如，要在字典中搜索每個單詞以找到單詞「duck」是低效的，相反，你會直接去查找字母D，甚至直接到字母D的後半部分，找到接近「duck」的單詞，然後找到它。\n",
    "\n",
    "這就是索引在不影響速度或質量太多的情況下幫助搜索許多例子的方式（有關此的更多信息，請查看最近鄰搜索）。\n",
    "\n",
    "最受歡迎的索引庫之一是 `Faiss`。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 選擇LLM --> Llama-3-8B-instruct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available GPU memory: 12 GB\n"
     ]
    }
   ],
   "source": [
    "# Get GPU available memory\n",
    "import torch\n",
    "gpu_memory_bytes = torch.cuda.get_device_properties(0).total_memory\n",
    "gpu_memory_gb = round(gpu_memory_bytes / (2**30))\n",
    "print(f\"Available GPU memory: {gpu_memory_gb} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory: 12 | Recommended model: Gemma 2B in float16 or Gemma 7B in 4-bit precision.\n",
      "use_quantization_config set to: False\n",
      "model_id set to: meta-llama/Meta-Llama-3-8B-instruct\n"
     ]
    }
   ],
   "source": [
    "# Note: the following is Gemma focused, however, there are more and more LLMs of the 2B and 7B size appearing for local use.\n",
    "if gpu_memory_gb < 5.1:\n",
    "    print(f\"Your available GPU memory is {gpu_memory_gb}GB, you may not have enough memory to run a Gemma LLM locally without quantization.\")\n",
    "elif gpu_memory_gb < 8.1:\n",
    "    print(f\"GPU memory: {gpu_memory_gb} | Recommended model: Gemma 2B in 4-bit precision.\")\n",
    "    use_quantization_config = True \n",
    "    model_id = \"google/gemma-2b-it\"\n",
    "elif gpu_memory_gb < 19.0:\n",
    "    print(f\"GPU memory: {gpu_memory_gb} | Recommended model: Gemma 2B in float16 or Gemma 7B in 4-bit precision.\")\n",
    "    use_quantization_config = False \n",
    "    model_id = \"meta-llama/Meta-Llama-3-8B-instruct\"\n",
    "elif gpu_memory_gb > 19.0:\n",
    "    print(f\"GPU memory: {gpu_memory_gb} | Recommend model: Gemma 7B in 4-bit or float16 precision.\")\n",
    "    use_quantization_config = False \n",
    "    model_id = \"google/gemma-7b-it\"\n",
    "\n",
    "print(f\"use_quantization_config set to: {use_quantization_config}\")\n",
    "print(f\"model_id set to: {model_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6245f1386e4345fca9e61af2c55ce88c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using attention implementation: sdpa\n",
      "[INFO] Using model_id: meta-llama/Meta-Llama-3-8B-instruct\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "922caf7b17134c958b1514a7520dc462",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/51.0k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ailab\\anaconda3\\envs\\MYRAG\\Lib\\site-packages\\huggingface_hub\\file_download.py:157: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\ailab\\.cache\\huggingface\\hub\\models--meta-llama--Meta-Llama-3-8B-instruct. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2572fe9ce7c492ebf041b75532af4b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cf54cfdbe19431e86b443bfd295956e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/73.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03e391f2f7bd4f5f94c0f2032be868fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/654 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e56d9be22ed4f0fb38426f58d3c5e92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/23.9k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cd363db1802423e84e29f417bac68cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4fe9b403e0f4317adadf21b4cfda7f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00004.safetensors:   0%|          | 0.00/4.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error while downloading from https://cdn-lfs-us-1.huggingface.co/repos/55/ac/55acddbb5c2ac2041b89a858eeba82e6130c6160294d75fe51bfa8bd7a4e4518/d8cf9c4d0dd972e1a2131bfe656235ee98221679711a3beef6d46dadf0f20b5c?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27model-00001-of-00004.safetensors%3B+filename%3D%22model-00001-of-00004.safetensors%22%3B&Expires=1715871355&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcxNTg3MTM1NX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmh1Z2dpbmdmYWNlLmNvL3JlcG9zLzU1L2FjLzU1YWNkZGJiNWMyYWMyMDQxYjg5YTg1OGVlYmE4MmU2MTMwYzYxNjAyOTRkNzVmZTUxYmZhOGJkN2E0ZTQ1MTgvZDhjZjljNGQwZGQ5NzJlMWEyMTMxYmZlNjU2MjM1ZWU5ODIyMTY3OTcxMWEzYmVlZjZkNDZkYWRmMGYyMGI1Yz9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoifV19&Signature=QeprbWGRW9SUz3JolPpCvaSTsdRXx4Wbbsx5M%7EEHm0qou0QL8C0QieuXN8E5af4FNxLbuc5gAIegZfPvKlYnI2nzLnbiE-X2wHCMzpqsWpCNyv9FWtkKSsPZNU-oYHneu-9v4dPfJk0tHK0tfknKGkCzqLHeHEYuM5VAGuTrZUwzR2k26qMZ5l8bN891xkPgOwgLaZqXCjLYHs%7E7ibSQ1-gEaVB%7EtkKPM7-aQ1hEomnE8xiOSimUzEoODTVyptE%7EWSyWw7N2gl05Up8TWKlLg4-jSfg6iszN0oPTtI3uiYjEE32hVeFb6aZxS4PlmK0C1buSAVjCgSgZOhFjrqrtbQ__&Key-Pair-Id=KCD77M1F0VK2B: HTTPSConnectionPool(host='cdn-lfs-us-1.huggingface.co', port=443): Read timed out.\n",
      "Trying to resume download...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c814f233abfd44deb7f501e45aa4d245",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00004.safetensors:  41%|####      | 2.03G/4.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error while downloading from https://cdn-lfs-us-1.huggingface.co/repos/55/ac/55acddbb5c2ac2041b89a858eeba82e6130c6160294d75fe51bfa8bd7a4e4518/d8cf9c4d0dd972e1a2131bfe656235ee98221679711a3beef6d46dadf0f20b5c?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27model-00001-of-00004.safetensors%3B+filename%3D%22model-00001-of-00004.safetensors%22%3B&Expires=1715871355&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcxNTg3MTM1NX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmh1Z2dpbmdmYWNlLmNvL3JlcG9zLzU1L2FjLzU1YWNkZGJiNWMyYWMyMDQxYjg5YTg1OGVlYmE4MmU2MTMwYzYxNjAyOTRkNzVmZTUxYmZhOGJkN2E0ZTQ1MTgvZDhjZjljNGQwZGQ5NzJlMWEyMTMxYmZlNjU2MjM1ZWU5ODIyMTY3OTcxMWEzYmVlZjZkNDZkYWRmMGYyMGI1Yz9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoifV19&Signature=QeprbWGRW9SUz3JolPpCvaSTsdRXx4Wbbsx5M%7EEHm0qou0QL8C0QieuXN8E5af4FNxLbuc5gAIegZfPvKlYnI2nzLnbiE-X2wHCMzpqsWpCNyv9FWtkKSsPZNU-oYHneu-9v4dPfJk0tHK0tfknKGkCzqLHeHEYuM5VAGuTrZUwzR2k26qMZ5l8bN891xkPgOwgLaZqXCjLYHs%7E7ibSQ1-gEaVB%7EtkKPM7-aQ1hEomnE8xiOSimUzEoODTVyptE%7EWSyWw7N2gl05Up8TWKlLg4-jSfg6iszN0oPTtI3uiYjEE32hVeFb6aZxS4PlmK0C1buSAVjCgSgZOhFjrqrtbQ__&Key-Pair-Id=KCD77M1F0VK2B: HTTPSConnectionPool(host='cdn-lfs-us-1.huggingface.co', port=443): Read timed out.\n",
      "Trying to resume download...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f491f6bbba5e41938a0b78263c09ce71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00004.safetensors:  60%|######    | 3.01G/4.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error while downloading from https://cdn-lfs-us-1.huggingface.co/repos/55/ac/55acddbb5c2ac2041b89a858eeba82e6130c6160294d75fe51bfa8bd7a4e4518/d8cf9c4d0dd972e1a2131bfe656235ee98221679711a3beef6d46dadf0f20b5c?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27model-00001-of-00004.safetensors%3B+filename%3D%22model-00001-of-00004.safetensors%22%3B&Expires=1715871355&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcxNTg3MTM1NX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmh1Z2dpbmdmYWNlLmNvL3JlcG9zLzU1L2FjLzU1YWNkZGJiNWMyYWMyMDQxYjg5YTg1OGVlYmE4MmU2MTMwYzYxNjAyOTRkNzVmZTUxYmZhOGJkN2E0ZTQ1MTgvZDhjZjljNGQwZGQ5NzJlMWEyMTMxYmZlNjU2MjM1ZWU5ODIyMTY3OTcxMWEzYmVlZjZkNDZkYWRmMGYyMGI1Yz9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoifV19&Signature=QeprbWGRW9SUz3JolPpCvaSTsdRXx4Wbbsx5M%7EEHm0qou0QL8C0QieuXN8E5af4FNxLbuc5gAIegZfPvKlYnI2nzLnbiE-X2wHCMzpqsWpCNyv9FWtkKSsPZNU-oYHneu-9v4dPfJk0tHK0tfknKGkCzqLHeHEYuM5VAGuTrZUwzR2k26qMZ5l8bN891xkPgOwgLaZqXCjLYHs%7E7ibSQ1-gEaVB%7EtkKPM7-aQ1hEomnE8xiOSimUzEoODTVyptE%7EWSyWw7N2gl05Up8TWKlLg4-jSfg6iszN0oPTtI3uiYjEE32hVeFb6aZxS4PlmK0C1buSAVjCgSgZOhFjrqrtbQ__&Key-Pair-Id=KCD77M1F0VK2B: HTTPSConnectionPool(host='cdn-lfs-us-1.huggingface.co', port=443): Read timed out.\n",
      "Trying to resume download...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fc80e93ad4f4be586d2b4ef7da42a56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00004.safetensors:  80%|########  | 4.00G/4.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error while downloading from https://cdn-lfs-us-1.huggingface.co/repos/55/ac/55acddbb5c2ac2041b89a858eeba82e6130c6160294d75fe51bfa8bd7a4e4518/d8cf9c4d0dd972e1a2131bfe656235ee98221679711a3beef6d46dadf0f20b5c?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27model-00001-of-00004.safetensors%3B+filename%3D%22model-00001-of-00004.safetensors%22%3B&Expires=1715871355&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcxNTg3MTM1NX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmh1Z2dpbmdmYWNlLmNvL3JlcG9zLzU1L2FjLzU1YWNkZGJiNWMyYWMyMDQxYjg5YTg1OGVlYmE4MmU2MTMwYzYxNjAyOTRkNzVmZTUxYmZhOGJkN2E0ZTQ1MTgvZDhjZjljNGQwZGQ5NzJlMWEyMTMxYmZlNjU2MjM1ZWU5ODIyMTY3OTcxMWEzYmVlZjZkNDZkYWRmMGYyMGI1Yz9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoifV19&Signature=QeprbWGRW9SUz3JolPpCvaSTsdRXx4Wbbsx5M%7EEHm0qou0QL8C0QieuXN8E5af4FNxLbuc5gAIegZfPvKlYnI2nzLnbiE-X2wHCMzpqsWpCNyv9FWtkKSsPZNU-oYHneu-9v4dPfJk0tHK0tfknKGkCzqLHeHEYuM5VAGuTrZUwzR2k26qMZ5l8bN891xkPgOwgLaZqXCjLYHs%7E7ibSQ1-gEaVB%7EtkKPM7-aQ1hEomnE8xiOSimUzEoODTVyptE%7EWSyWw7N2gl05Up8TWKlLg4-jSfg6iszN0oPTtI3uiYjEE32hVeFb6aZxS4PlmK0C1buSAVjCgSgZOhFjrqrtbQ__&Key-Pair-Id=KCD77M1F0VK2B: HTTPSConnectionPool(host='cdn-lfs-us-1.huggingface.co', port=443): Read timed out.\n",
      "Trying to resume download...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75d6871c342e477eac359c8491613f7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00004.safetensors:  90%|######### | 4.49G/4.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e1760c96b884d34b6fcb292617fe0bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00004.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d6acccf459d40b1b027b8059747d78e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00004.safetensors:   0%|          | 0.00/4.92G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error while downloading from https://cdn-lfs-us-1.huggingface.co/repos/55/ac/55acddbb5c2ac2041b89a858eeba82e6130c6160294d75fe51bfa8bd7a4e4518/3acdd690e65c24f42a24581b8467af98bd3ca357444580f8012aacd2bd607921?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27model-00003-of-00004.safetensors%3B+filename%3D%22model-00003-of-00004.safetensors%22%3B&Expires=1715873731&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcxNTg3MzczMX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmh1Z2dpbmdmYWNlLmNvL3JlcG9zLzU1L2FjLzU1YWNkZGJiNWMyYWMyMDQxYjg5YTg1OGVlYmE4MmU2MTMwYzYxNjAyOTRkNzVmZTUxYmZhOGJkN2E0ZTQ1MTgvM2FjZGQ2OTBlNjVjMjRmNDJhMjQ1ODFiODQ2N2FmOThiZDNjYTM1NzQ0NDU4MGY4MDEyYWFjZDJiZDYwNzkyMT9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoifV19&Signature=AmyqPWCD4f-EauJ-ZeTuXF1lXeLghLwWptahrTYNiHORb4G2jrHCkDBNcD5C7LEAEC9faC2kdyMSus4rRARYgNwF76ul62slmEpDLLjreAXEJ1SuvIcurjQdy%7EuZZDANquhPtak7J9Yrb8uCYuLAI5Co6sZke48E7-N7NP4i6o%7EdM3OULGFCt0sVsTI-vQhQMX%7E2WIy4B71eT4pmHXyNEj9dxxOkSM-pnC7dDdOGxLsFaRLoPRh964VYnOPCmQ4KA3M72oJZoExD74J-8pM6beKmNKoWhNVhUKu89uNl%7EfI7f9YhhRPlRhyS-DRMt6EH2lezN5Mg3RkrFqKAL4sSjg__&Key-Pair-Id=KCD77M1F0VK2B: HTTPSConnectionPool(host='cdn-lfs-us-1.huggingface.co', port=443): Read timed out.\n",
      "Trying to resume download...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59909837b2334c429fa02972a3f4baa9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00004.safetensors:  78%|#######8  | 3.85G/4.92G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b66f2f58f5c4bc78a18ff48cc013462",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00004-of-00004.safetensors:   0%|          | 0.00/1.17G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1432316588f8442da4f59f07f5d0c9d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a50f02d529db44e8a7393ded1dc5ae1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/187 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from transformers.utils import is_flash_attn_2_available \n",
    "from transformers import BitsAndBytesConfig\n",
    "# 量化模型權重&激活函數 4bit/16位float\n",
    "quantization_config = BitsAndBytesConfig(load_in_4bit=True,                            \n",
    "                                         bnb_4bit_compute_dtype=torch.float16)\n",
    "#GPU優化\n",
    "if (is_flash_attn_2_available()) and (torch.cuda.get_device_capability(0)[0] >= 8):\n",
    "  attn_implementation = \"flash_attention_2\"\n",
    "else:\n",
    "  attn_implementation = \"sdpa\"\n",
    "print(f\"[INFO] Using attention implementation: {attn_implementation}\")\n",
    "\n",
    "print(f\"[INFO] Using model_id: {model_id}\")\n",
    "model_id = 'meta-llama/Meta-Llama-3-8B-instruct'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "llm_model = AutoModelForCausalLM.from_pretrained(pretrained_model_name_or_path=model_id, \n",
    "                                                 torch_dtype=torch.float16, # datatype to use, we want float16\n",
    "                                                 quantization_config=quantization_config if use_quantization_config else None,\n",
    "                                                 low_cpu_mem_usage=False, # use full memory \n",
    "                                                 attn_implementation=attn_implementation) # which attention version to use\n",
    "\n",
    "if not use_quantization_config:\n",
    "    llm_model.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "檢查是否成功載入我的LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LlamaForCausalLM(\n",
       "  (model): LlamaModel(\n",
       "    (embed_tokens): Embedding(128256, 4096)\n",
       "    (layers): ModuleList(\n",
       "      (0-31): 32 x LlamaDecoderLayer(\n",
       "        (self_attn): LlamaSdpaAttention(\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "          (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm()\n",
       "        (post_attention_layernorm): LlamaRMSNorm()\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=4096, out_features=128256, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Llama-3-8B-instruct模型有15.145 GB大"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size: 15.145 GB\n"
     ]
    }
   ],
   "source": [
    "param_size = 0\n",
    "buffer_size = 0\n",
    "for param in llm_model.parameters():\n",
    "    param_size += param.nelement() * param.element_size()\n",
    "\n",
    "for buffer in llm_model.buffers():\n",
    "    buffer_size += buffer.nelement() * buffer.element_size()\n",
    "\n",
    "size_all_mb = (param_size + buffer_size) / 1024**2\n",
    "print('Size: {:.3f} GB'.format(size_all_mb/1024))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "查看參數量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8030261248"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_model_num_params(model: torch.nn.Module):\n",
    "    return sum([param.numel() for param in model.parameters()])\n",
    "\n",
    "get_model_num_params(llm_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `Generation` 用LLM生成回覆"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input text:\n",
      "Waht is 'Open-domain Question Answering' from the experience of RAG?\n",
      "\n",
      "Prompt (formatted):\n",
      "<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Waht is 'Open-domain Question Answering' from the experience of RAG?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input_text = \"Waht is 'Open-domain Question Answering' from the experience of RAG?\"\n",
    "print(f\"Input text:\\n{input_text}\")\n",
    "\n",
    "# Create prompt template for instruction-tuned model\n",
    "dialogue_template = [\n",
    "    {\"role\": \"user\",\n",
    "     \"content\": input_text}\n",
    "]\n",
    "\n",
    "# Apply the chat template\n",
    "prompt = tokenizer.apply_chat_template(conversation=dialogue_template,\n",
    "                                       tokenize=False, # keep as raw text (not tokenized)\n",
    "                                       add_generation_prompt=True)\n",
    "print(f\"\\nPrompt (formatted):\\n{prompt}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tokenize --> LLM generate --> decode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model input (tokenized):\n",
      "{'input_ids': tensor([[128000, 128000, 128006,    882, 128007,    271,  99327,    427,    374,\n",
      "            364,   5109,  73894,  16225,  22559,    287,      6,    505,    279,\n",
      "           3217,    315,    432,   1929,     30, 128009, 128006,  78191, 128007,\n",
      "            271]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1]], device='cuda:0')}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ailab\\anaconda3\\envs\\MYRAG\\Lib\\site-packages\\transformers\\models\\llama\\modeling_llama.py:671: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at ..\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:455.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model output (tokens):\n",
      "tensor([128000, 128000, 128006,    882, 128007,    271,  99327,    427,    374,\n",
      "           364,   5109,  73894,  16225,  22559,    287,      6,    505,    279,\n",
      "          3217,    315,    432,   1929,     30, 128009, 128006,  78191, 128007,\n",
      "           271,   3915,    279,  13356,    315,    432,   1929,    320,    697,\n",
      "          8532,  22559,  24367,    705,   5377,  73894,  16225,  22559,    287,\n",
      "           320,   5109,  48622,      8,    374,    264,    955,    315,   5933,\n",
      "          4221,   8863,    320,     45,  12852,      8,   3465,    430,  18065,\n",
      "         24038,  11503,    311,   4860,  15107,    505,    264,  13057,     11,\n",
      "          1825,  84175,   6677,   2385,    477,  43194,     13,   1115,   3465,\n",
      "          7612,    279,   1646,    311,  17622,   9959,   2038,    505,    279,\n",
      "         13057,   3392,    315,   1495,    828,   2561,    389,    279,   7757,\n",
      "            11,   6603,     11,    477,   1023,   8336,     11,    323,   1243,\n",
      "          7068,  13687,    323,   9959,  11503,    311,    279,   4860,    382,\n",
      "           644,   5377,  48622,     11,    279,   1646,    374,    539,   7347,\n",
      "           311,    264,   3230,   8106,    477,   6677,   2385,     11,  20426,\n",
      "          1023,   4595,    315,   3488,  36864,   9256,     11,   1778,    439,\n",
      "          5405,   3059,   7177,    477,   5361,  63726,   4860,     13,  12361,\n",
      "            11,    433,   2011,    387,   3025,    311,  93640,   4028,   5370,\n",
      "         13650,     11,  31576,     11,    323,  20447,    311,   3493,  11503,\n",
      "           430,    527,  13687,     11,  39319,     11,    323,   9959,    311,\n",
      "           279,   3488,    382,     49,   1929,     11,    439,    264,  88516,\n",
      "         22559,  24367,   1646,     11,    374,   6319,    311,  22118,    420,\n",
      "         17436,   3465,    555,  77582,   1202,   5845,    311,   1473,     16,\n",
      "            13,   3146,  88765,   9959,   2038,  96618,    432,   1929,    649,\n",
      "          8819,   9959,  23719,     11,  32847,     11,    477,  47869,    505,\n",
      "           264,  11191,  43194,    315,   1495,    828,     11,    902,    527,\n",
      "          1243,   1511,    311,   7068,    279,   4320,    627,     17,     13,\n",
      "          3146,  16648,   2752,    279,   3488,  96618,    432,   1929,    649,\n",
      "         58389,    279,   3488,    323,  10765,    279,   1401,  15086,     11,\n",
      "         19476,     11,    323,  12135,   6532,     11,  28462,    433,    311,\n",
      "          5357,    389,    279,   9959,   2038,    627,     18,     13,   3146,\n",
      "         32215,    279,   4320,  96618,    432], device='cuda:0')\n",
      "\n",
      "CPU times: total: 3min 39s\n",
      "Wall time: 2min 15s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "input_ids = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "print(f\"Model input (tokenized):\\n{input_ids}\\n\")\n",
    "\n",
    "outputs = llm_model.generate(**input_ids,\n",
    "                             max_new_tokens=256) \n",
    "print(f\"Model output (tokens):\\n{outputs[0]}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model output (decoded):\n",
      "<|begin_of_text|><|begin_of_text|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Waht is 'Open-domain Question Answering' from the experience of RAG?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "From the perspective of RAG (Relevant Answer Generation), Open-domain Question Answering (OpenQA) is a type of natural language processing (NLP) task that involves generating answers to questions drawn from a vast, open-ended knowledge base or corpus. This task requires the model to retrieve relevant information from the vast amount of text data available on the internet, books, or other sources, and then generate accurate and relevant answers to the questions.\n",
      "\n",
      "In OpenQA, the model is not limited to a specific domain or knowledge base, unlike other types of question answering tasks, such as cloze tests or multiple-choice questions. Instead, it must be able to generalize across various topics, domains, and formats to provide answers that are accurate, informative, and relevant to the question.\n",
      "\n",
      "RAG, as a Relevant Answer Generation model, is designed to tackle this challenging task by leveraging its ability to:\n",
      "\n",
      "1. **Retrieve relevant information**: RAG can extract relevant sentences, phrases, or passages from a massive corpus of text data, which are then used to generate the answer.\n",
      "2. **Understand the question**: RAG can comprehend the question and identify the key entities, concepts, and relationships involved, enabling it to focus on the relevant information.\n",
      "3. **Generate the answer**: R\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Decode the output tokens to text\n",
    "outputs_decoded = tokenizer.decode(outputs[0])\n",
    "print(f\"Model output (decoded):\\n{outputs_decoded}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input text: Waht is 'Open-domain Question Answering' from the experience of RAG?\n",
      "\n",
      "Output text:\n",
      "From the perspective of RAG (Relevant Answer Generation), Open-domain Question Answering (OpenQA) is a type of natural language processing (NLP) task that involves generating answers to questions drawn from a vast, open-ended knowledge base or corpus. This task requires the model to retrieve relevant information from the vast amount of text data available on the internet, books, or other sources, and then generate accurate and relevant answers to the questions.\n",
      "\n",
      "In OpenQA, the model is not limited to a specific domain or knowledge base, unlike other types of question answering tasks, such as cloze tests or multiple-choice questions. Instead, it must be able to generalize across various topics, domains, and formats to provide answers that are accurate, informative, and relevant to the question.\n",
      "\n",
      "RAG, as a Relevant Answer Generation model, is designed to tackle this challenging task by leveraging its ability to:\n",
      "\n",
      "1. **Retrieve relevant information**: RAG can extract relevant sentences, phrases, or passages from a massive corpus of text data, which are then used to generate the answer.\n",
      "2. **Understand the question**: RAG can comprehend the question and identify the key entities, concepts, and relationships involved, enabling it to focus on the relevant information.\n",
      "3. **Generate the answer**: R\n"
     ]
    }
   ],
   "source": [
    "print(f\"Input text: {input_text}\\n\")\n",
    "print(f\"Output text:\\n{outputs_decoded.replace(prompt, '').replace('<|begin_of_text|>', '').replace('<eos>', '')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "已完成`Retrieval`和`Generation`\n",
    "\n",
    "再來是`Augmentation`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt4_questions = [\n",
    "    \"How does RAG differ from traditional language models in terms of architecture and processing flow?\",\n",
    "    \"What are the main challenges in aligning the retrieved documents with the generation process in RAG?\",\n",
    "    \"Can you provide examples of real-world applications where RAG is particularly effective?\",\n",
    "    \"What datasets and benchmarks are most commonly used to train and evaluate RAG models?\",\n",
    "    \"How do advancements in vector search technologies influence the development and performance of RAG systems?\"\n",
    "]\n",
    "\n",
    "# Manually created question list\n",
    "manual_questions = [\n",
    "    \"Please introduce the main technique of RAG.\",\n",
    "    \"What is the pipline of RAG?\",\n",
    "    \"Is there any shortcoming when implementing RAG?\",\n",
    "    \"What is the most-used method of evatulting RAG?\",\n",
    "    \"What is the most special point of RAG?\"\n",
    "]\n",
    "\n",
    "query_list = gpt4_questions + manual_questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now let's check if our `retrieve_relevant_resources()` function works with our list of queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: How does RAG differ from traditional language models in terms of architecture and processing flow?\n",
      "[INFO] Time taken to get scores on 65 embeddings: 0.00059 seconds.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([0.4293, 0.4046, 0.4020, 0.3988, 0.3939], device='cuda:0'),\n",
       " tensor([17,  8, 18, 56,  1], device='cuda:0'))"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "query = random.choice(query_list)\n",
    "\n",
    "print(f\"Query: {query}\")\n",
    "\n",
    "# Get just the scores and indices of top related results\n",
    "scores, indices = retrieve_relevant_resources(query=query,\n",
    "                                              embeddings=embeddings)\n",
    "scores, indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `Augmentation`\n",
    "\n",
    "`prmopt_formatter` : 整理出增強過的新prompt (Query+)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prompt_formatter(query: str, \n",
    "                     context_items: list[dict]) -> str:\n",
    "    \"\"\"\n",
    "    Augments query with text-based context from context_items.\n",
    "    \"\"\"\n",
    "    # Join context items into one dotted paragraph\n",
    "    context = \"- \" + \"\\n- \".join([item[\"sentence_chunk\"] for item in context_items])\n",
    "\n",
    "    # Create a base prompt with examples to help the model\n",
    "    # Note: this is very customizable, I've chosen to use 3 examples of the answer style we'd like.\n",
    "    # We could also write this in a txt file and import it in if we wanted.\n",
    "    base_prompt = \"\"\"Based on the following context items, please answer the query.\n",
    "Give yourself room to think by extracting relevant passages from the context before answering the query.\n",
    "Don't return the thinking, only return the answer.\n",
    "Make sure your answers are as explanatory as possible.\n",
    "Use the following examples as reference for the ideal answer style.\n",
    "\\nExample 1:\n",
    "Query: What is DPR?\n",
    "Answer: DPR is a method used in RAG to retrieve relevant documents or passages from a large database. It uses dense vector embeddings of text, which are generated by a neural network, to find and retrieve content that is semantically related to a given query.\n",
    "\\nExample 2:\n",
    "Query: What is Retrieval Ablations?\n",
    "Answer: Retrieval ablations in RAG refer to experiments or modifications done to analyze the impact of different components of the retrieval system on the overall performance of the model. For instance, changing the way documents are retrieved or altering the embeddings can help understand what aspects are most crucial for accurate information retrieval.\n",
    "\n",
    "\\nNow use the following context items to answer the user query:\n",
    "{context}\n",
    "\\nRelevant passages: <extract relevant passages from the context here>\n",
    "User query: {query}\n",
    "Answer:\"\"\"\n",
    "\n",
    "    # Update base prompt with context items and query   \n",
    "    base_prompt = base_prompt.format(context=context, query=query)\n",
    "\n",
    "    # Create prompt template for instruction-tuned model\n",
    "    dialogue_template = [\n",
    "        {\"role\": \"user\",\n",
    "        \"content\": base_prompt}\n",
    "    ]\n",
    "\n",
    "    # Apply the chat template\n",
    "    prompt = tokenizer.apply_chat_template(conversation=dialogue_template,\n",
    "                                          tokenize=False,\n",
    "                                          add_generation_prompt=True)\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: What is the most-used method of evatulting RAG?\n",
      "[INFO] Time taken to get scores on 65 embeddings: 0.00005 seconds.\n",
      "<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Based on the following context items, please answer the query.\n",
      "Give yourself room to think by extracting relevant passages from the context before answering the query.\n",
      "Don't return the thinking, only return the answer.\n",
      "Make sure your answers are as explanatory as possible.\n",
      "Use the following examples as reference for the ideal answer style.\n",
      "\n",
      "Example 1:\n",
      "Query: What is DPR?\n",
      "Answer: DPR is a method used in RAG to retrieve relevant documents or passages from a large database. It uses dense vector embeddings of text, which are generated by a neural network, to find and retrieve content that is semantically related to a given query.\n",
      "\n",
      "Example 2:\n",
      "Query: What is Retrieval Ablations?\n",
      "Answer: Retrieval ablations in RAG refer to experiments or modifications done to analyze the impact of different components of the retrieval system on the overall performance of the model. For instance, changing the way documents are retrieved or altering the embeddings can help understand what aspects are most crucial for accurate information retrieval.\n",
      "\n",
      "\n",
      "Now use the following context items to answer the user query:\n",
      "- 14.7 21.4 40.8 44.2 to more effective marginalization over documents. Furthermore, RAG can generate correct answers even when the correct answer is not in any retrieved document, achieving 11.8% accuracy in such cases for NQ, where an extractive model would score 0%.4.2 Abstractive Question Answering As shown in Table 2, RAG-Sequence outperforms BART on Open MS-MARCO NLG by 2.6 Bleu points and 2.6 Rouge-L points. RAG approaches state-of-the-art model performance, which is impressive given that (i) those models access gold passages with speciﬁc information required to generate the reference answer, (ii) many questions are unanswerable without the gold passages, and (iii) not all questions are answerable from Wikipedia alone. Table 3 shows some generated answers from our models. Qualitatively, we ﬁnd that RAG models hallucinate less and generate factually correct text more often than BART. Later, we also show that RAG generations are more diverse than BART generations (see §4.5).4.3 Jeopardy Question Generation Table 2 shows that RAG-Token performs better than RAG-Sequence on Jeopardy question generation, with both models outperforming BART on Q-BLEU-1. Table 4 shows human evaluation results, over 452 pairs of generations from BART and RAG-Token. Evaluators indicated that BART was more factual than RAG in only 7.1% of cases, while RAG was more factual in 42.7% of cases, and both RAG and BART were factual in a further 17% of cases, clearly demonstrating the effectiveness of RAG on the task over a state-of-the-art generation model.\n",
      "- RAG combines the generation ﬂexibility of the “closed-book” (parametric only) approaches and the performance of \"open-book\" retrieval-based approaches. Unlike REALM and T5+SSM, RAG enjoys strong results without expensive, specialized “salient span masking” pre-training [20]. It is worth noting that RAG’s retriever is initialized using DPR’s retriever, which uses retrieval supervision on Natural Questions and TriviaQA. RAG compares favourably to the DPR QA system, which uses a BERT-based “cross- encoder” to re-rank documents, along with an extractive reader. RAG demonstrates that neither a re-ranker nor extractive reader is necessary for state-of-the-art performance. There are several advantages to generating answers even when it is possible to extract them. Docu- ments with clues about the answer but do not contain the answer verbatim can still contribute towards a correct answer being generated, which is not possible with standard extractive approaches, leading 5\n",
      "- minimize the negative marginal log-likelihood of each target, P j − log p(yj|xj) using stochastic gradient descent with Adam [28]. Updating the document encoder BERTd during training is costly as it requires the document index to be periodically updated as REALM does during pre-training [20]. We do not ﬁnd this step necessary for strong performance, and keep the document encoder (and index) ﬁxed, only ﬁne-tuning the query encoder BERTq and the BART generator.2.5 Decoding At test time, RAG-Sequence and RAG-Token require different ways to approximate arg maxy p(y|x). RAG-Token The RAG-Token model can be seen as a standard, autoregressive seq2seq genera- tor with transition probability: p0 ✓(yi|x, y1:i−1) = P z2top-k(p(·|x)) p⌘(zi|x)p✓(yi|x, zi, y1:i−1) To decode, we can plug p0 ✓(yi|x, y1:i−1) into a standard beam decoder. RAG-Sequence For RAG-Sequence, the likelihood p(y|x) does not break into a conventional per- token likelihood, hence we cannot solve it with a single beam search. Instead, we run beam search for each document z, scoring each hypothesis using p✓(yi|x, z, y1:i−1). This yields a set of hypotheses Y , some of which may not have appeared in the beams of all documents. To estimate the probability of an hypothesis y we run an additional forward pass for each document z for which y does not appear in the beam, multiply generator probability with p⌘(z|x) and then sum the probabilities across beams for the marginals. We refer to this decoding procedure as “Thorough Decoding.”\n",
      "- We have the ﬂexibility to adjust the number of retrieved documents at test time, which can affect performance and runtime. Figure 3 (left) shows that retrieving more documents at test time monotonically improves Open-domain QA results for RAG-Sequence, but performance peaks for RAG-Token at 10 retrieved documents. Figure 3 (right) shows that retrieving more documents leads to higher Rouge-L for RAG-Token at the expense of Bleu-1, but the effect is less pronounced for RAG-Sequence.10 20 30 40 50 K Retrieved Docs 39 40 41 42 43 44 NQ Exact Match RAG-Tok RAG-Seq 10 20 30 40 50 K Retrieved Docs 40 50 60 70 80 NQ Answer Recall @ K RAG-Tok RAG-Seq Fixed DPR BM25 10 20 30 40 50 K Retrieved Docs 48 50 52 54 56 Bleu-1 / Rouge-L score RAG-Tok R-L RAG-Tok B-1 RAG-Seq R-L RAG-Seq B-1 Figure 3: Left: NQ performance as more documents are retrieved. Center: Retrieval recall perfor- mance in NQ. Right: MS-MARCO Bleu-1 and Rouge-L as more documents are retrieved.5 Related Work Single-Task Retrieval Prior work has shown that retrieval improves performance across a variety of NLP tasks when considered in isolation. Such tasks include open-domain question answering [5, 29], fact checking [56], fact completion [48], long-form question answering [12], Wikipedia article generation [36], dialogue [41, 65, 9, 13], translation [17], and language modeling [19, 27]. Our work uniﬁes previous successes in incorporating retrieval into individual tasks, showing that a single retrieval-based architecture is capable of achieving strong performance across several tasks.8\n",
      "- As CT and WQ are small, we follow DPR [26] by initializing CT and WQ models with our NQ RAG model. We use the same train/dev/test splits as prior work [31, 26] and report Exact Match (EM) scores. For TQA, to compare with T5 [52], we also evaluate on the TQA Wiki test set.3.2 Abstractive Question Answering RAG models can go beyond simple extractive QA and answer questions with free-form, abstractive text generation. To test RAG’s natural language generation (NLG) in a knowledge-intensive setting, we use the MSMARCO NLG task v2.1 [43]. The task consists of questions, ten gold passages retrieved from a search engine for each question, and a full sentence answer annotated from the retrieved passages. We do not use the supplied passages, only the questions and answers, to treat 4\n",
      "\n",
      "Relevant passages: <extract relevant passages from the context here>\n",
      "User query: What is the most-used method of evatulting RAG?\n",
      "Answer:<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = random.choice(query_list)\n",
    "print(f\"Query: {query}\")\n",
    "\n",
    "# Get relevant resources\n",
    "scores, indices = retrieve_relevant_resources(query=query,\n",
    "                                              embeddings=embeddings)\n",
    "    \n",
    "# Create a list of context items\n",
    "context_items = [pages_and_chunks[i] for i in indices]\n",
    "\n",
    "# Format prompt with context items\n",
    "prompt = prompt_formatter(query=query,\n",
    "                          context_items=context_items)\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 架構:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: What is the most-used method of evatulting RAG?\n",
      "RAG answer:\n",
      "<|begin_of_text|><|begin_of_text|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Based on the following context items, please answer the query.\n",
      "Give yourself room to think by extracting relevant passages from the context before answering the query.\n",
      "Don't return the thinking, only return the answer.\n",
      "Make sure your answers are as explanatory as possible.\n",
      "Use the following examples as reference for the ideal answer style.\n",
      "\n",
      "Example 1:\n",
      "Query: What is DPR?\n",
      "Answer: DPR is a method used in RAG to retrieve relevant documents or passages from a large database. It uses dense vector embeddings of text, which are generated by a neural network, to find and retrieve content that is semantically related to a given query.\n",
      "\n",
      "Example 2:\n",
      "Query: What is Retrieval Ablations?\n",
      "Answer: Retrieval ablations in RAG refer to experiments or modifications done to analyze the impact of different components of the retrieval system on the overall performance of the model. For instance, changing the way documents are retrieved or altering the embeddings can help understand what aspects are most crucial for accurate information retrieval.\n",
      "\n",
      "\n",
      "Now use the following context items to answer the user query:\n",
      "- 14.7 21.4 40.8 44.2 to more effective marginalization over documents. Furthermore, RAG can generate correct answers even when the correct answer is not in any retrieved document, achieving 11.8% accuracy in such cases for NQ, where an extractive model would score 0%.4.2 Abstractive Question Answering As shown in Table 2, RAG-Sequence outperforms BART on Open MS-MARCO NLG by 2.6 Bleu points and 2.6 Rouge-L points. RAG approaches state-of-the-art model performance, which is impressive given that (i) those models access gold passages with speciﬁc information required to generate the reference answer, (ii) many questions are unanswerable without the gold passages, and (iii) not all questions are answerable from Wikipedia alone. Table 3 shows some generated answers from our models. Qualitatively, we ﬁnd that RAG models hallucinate less and generate factually correct text more often than BART. Later, we also show that RAG generations are more diverse than BART generations (see §4.5).4.3 Jeopardy Question Generation Table 2 shows that RAG-Token performs better than RAG-Sequence on Jeopardy question generation, with both models outperforming BART on Q-BLEU-1. Table 4 shows human evaluation results, over 452 pairs of generations from BART and RAG-Token. Evaluators indicated that BART was more factual than RAG in only 7.1% of cases, while RAG was more factual in 42.7% of cases, and both RAG and BART were factual in a further 17% of cases, clearly demonstrating the effectiveness of RAG on the task over a state-of-the-art generation model.\n",
      "- RAG combines the generation ﬂexibility of the “closed-book” (parametric only) approaches and the performance of \"open-book\" retrieval-based approaches. Unlike REALM and T5+SSM, RAG enjoys strong results without expensive, specialized “salient span masking” pre-training [20]. It is worth noting that RAG’s retriever is initialized using DPR’s retriever, which uses retrieval supervision on Natural Questions and TriviaQA. RAG compares favourably to the DPR QA system, which uses a BERT-based “cross- encoder” to re-rank documents, along with an extractive reader. RAG demonstrates that neither a re-ranker nor extractive reader is necessary for state-of-the-art performance. There are several advantages to generating answers even when it is possible to extract them. Docu- ments with clues about the answer but do not contain the answer verbatim can still contribute towards a correct answer being generated, which is not possible with standard extractive approaches, leading 5\n",
      "- minimize the negative marginal log-likelihood of each target, P j − log p(yj|xj) using stochastic gradient descent with Adam [28]. Updating the document encoder BERTd during training is costly as it requires the document index to be periodically updated as REALM does during pre-training [20]. We do not ﬁnd this step necessary for strong performance, and keep the document encoder (and index) ﬁxed, only ﬁne-tuning the query encoder BERTq and the BART generator.2.5 Decoding At test time, RAG-Sequence and RAG-Token require different ways to approximate arg maxy p(y|x). RAG-Token The RAG-Token model can be seen as a standard, autoregressive seq2seq genera- tor with transition probability: p0 ✓(yi|x, y1:i−1) = P z2top-k(p(·|x)) p⌘(zi|x)p✓(yi|x, zi, y1:i−1) To decode, we can plug p0 ✓(yi|x, y1:i−1) into a standard beam decoder. RAG-Sequence For RAG-Sequence, the likelihood p(y|x) does not break into a conventional per- token likelihood, hence we cannot solve it with a single beam search. Instead, we run beam search for each document z, scoring each hypothesis using p✓(yi|x, z, y1:i−1). This yields a set of hypotheses Y, some of which may not have appeared in the beams of all documents. To estimate the probability of an hypothesis y we run an additional forward pass for each document z for which y does not appear in the beam, multiply generator probability with p⌘(z|x) and then sum the probabilities across beams for the marginals. We refer to this decoding procedure as “Thorough Decoding.”\n",
      "- We have the ﬂexibility to adjust the number of retrieved documents at test time, which can affect performance and runtime. Figure 3 (left) shows that retrieving more documents at test time monotonically improves Open-domain QA results for RAG-Sequence, but performance peaks for RAG-Token at 10 retrieved documents. Figure 3 (right) shows that retrieving more documents leads to higher Rouge-L for RAG-Token at the expense of Bleu-1, but the effect is less pronounced for RAG-Sequence.10 20 30 40 50 K Retrieved Docs 39 40 41 42 43 44 NQ Exact Match RAG-Tok RAG-Seq 10 20 30 40 50 K Retrieved Docs 40 50 60 70 80 NQ Answer Recall @ K RAG-Tok RAG-Seq Fixed DPR BM25 10 20 30 40 50 K Retrieved Docs 48 50 52 54 56 Bleu-1 / Rouge-L score RAG-Tok R-L RAG-Tok B-1 RAG-Seq R-L RAG-Seq B-1 Figure 3: Left: NQ performance as more documents are retrieved. Center: Retrieval recall perfor- mance in NQ. Right: MS-MARCO Bleu-1 and Rouge-L as more documents are retrieved.5 Related Work Single-Task Retrieval Prior work has shown that retrieval improves performance across a variety of NLP tasks when considered in isolation. Such tasks include open-domain question answering [5, 29], fact checking [56], fact completion [48], long-form question answering [12], Wikipedia article generation [36], dialogue [41, 65, 9, 13], translation [17], and language modeling [19, 27]. Our work uniﬁes previous successes in incorporating retrieval into individual tasks, showing that a single retrieval-based architecture is capable of achieving strong performance across several tasks.8\n",
      "- As CT and WQ are small, we follow DPR [26] by initializing CT and WQ models with our NQ RAG model. We use the same train/dev/test splits as prior work [31, 26] and report Exact Match (EM) scores. For TQA, to compare with T5 [52], we also evaluate on the TQA Wiki test set.3.2 Abstractive Question Answering RAG models can go beyond simple extractive QA and answer questions with free-form, abstractive text generation. To test RAG’s natural language generation (NLG) in a knowledge-intensive setting, we use the MSMARCO NLG task v2.1 [43]. The task consists of questions, ten gold passages retrieved from a search engine for each question, and a full sentence answer annotated from the retrieved passages. We do not use the supplied passages, only the questions and answers, to treat 4\n",
      "\n",
      "Relevant passages: <extract relevant passages from the context here>\n",
      "User query: What is the most-used method of evatulting RAG?\n",
      "Answer:<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "The most-used method of evaluating RAG is not explicitly mentioned in the context. However, it can be inferred that RAG is evaluated using various metrics such as Exact Match (EM) scores, NQ Exact Match, Answer Recall, Bleu-1, Rouge-L, and human evaluation results.<|eot_id|>\n",
      "CPU times: total: 1min 41s\n",
      "Wall time: 1min 14s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "input_ids = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "outputs = llm_model.generate(**input_ids,\n",
    "                             temperature=0.7, # lower temperature = more deterministic outputs, higher temperature = more creative outputs\n",
    "                             do_sample=True, # whether or not to use sampling, see https://huyenchip.com/2024/01/16/sampling.html for more\n",
    "                             max_new_tokens=256) # how many new tokens to generate from prompt \n",
    "\n",
    "# Turn the output tokens into text\n",
    "output_text = tokenizer.decode(outputs[0])\n",
    "\n",
    "print(f\"Query: {query}\")\n",
    "print(f\"RAG answer:\\n{output_text.replace(prompt, ' ')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "簡化`Generation`階段  (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask(query, \n",
    "        temperature=0.7,\n",
    "        max_new_tokens=512,\n",
    "        format_answer_text=True, \n",
    "        return_answer_only=True):\n",
    "    \"\"\"\n",
    "    Takes a query, finds relevant resources/context and generates an answer to the query based on the relevant resources.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get just the scores and indices of top related results\n",
    "    scores, indices = retrieve_relevant_resources(query=query,\n",
    "                                                  embeddings=embeddings)\n",
    "    \n",
    "    # Create a list of context items\n",
    "    context_items = [pages_and_chunks[i] for i in indices]\n",
    "\n",
    "    # Add score to context item\n",
    "    for i, item in enumerate(context_items):\n",
    "        item[\"score\"] = scores[i].cpu() # return score back to CPU \n",
    "        \n",
    "    # Format the prompt with context items\n",
    "    prompt = prompt_formatter(query=query,\n",
    "                              context_items=context_items)\n",
    "    \n",
    "    # Tokenize the prompt\n",
    "    input_ids = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "    # Generate an output of tokens\n",
    "    outputs = llm_model.generate(**input_ids,\n",
    "                                 temperature=temperature,\n",
    "                                 do_sample=True,\n",
    "                                 max_new_tokens=max_new_tokens)\n",
    "    \n",
    "    # Turn the output tokens into text\n",
    "    output_text = tokenizer.decode(outputs[0])\n",
    "\n",
    "    if format_answer_text:\n",
    "        # Replace special tokens and unnecessary help message\n",
    "        output_text = output_text.replace(prompt, \"\").replace(\"<bos>\", \"\").replace(\"<eos>\", \"\").replace(\"Sure, here is the answer to the user query:\\n\\n\", \"\")\n",
    "\n",
    "    # Only return the answer without the context items\n",
    "    if return_answer_only:\n",
    "        return output_text\n",
    "    \n",
    "    return output_text, context_items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "測試query_list的隨機問題"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: How does RAG differ from traditional language models in terms of architecture and processing flow?\n",
      "[INFO] Time taken to get scores on 65 embeddings: 0.00007 seconds.\n",
      "Answer:\n",
      "\n",
      "<|begin_of_text|><|begin_of_text|><|start_header_id|>user<|end_header_id|>\n",
      "Based on the following context items, please answer the query. Give yourself\n",
      "room to think by extracting relevant passages from the context before answering\n",
      "the query. Don't return the thinking, only return the answer. Make sure your\n",
      "answers are as explanatory as possible. Use the following examples as reference\n",
      "for the ideal answer style.  Example 1: Query: What is DPR? Answer: DPR is a\n",
      "method used in RAG to retrieve relevant documents or passages from a large\n",
      "database. It uses dense vector embeddings of text, which are generated by a\n",
      "neural network, to find and retrieve content that is semantically related to a\n",
      "given query.  Example 2: Query: What is Retrieval Ablations? Answer: Retrieval\n",
      "ablations in RAG refer to experiments or modifications done to analyze the\n",
      "impact of different components of the retrieval system on the overall\n",
      "performance of the model. For instance, changing the way documents are retrieved\n",
      "or altering the embeddings can help understand what aspects are most crucial for\n",
      "accurate information retrieval.   Now use the following context items to answer\n",
      "the user query: - 14.7 21.4 40.8 44.2 to more effective marginalization over\n",
      "documents. Furthermore, RAG can generate correct answers even when the correct\n",
      "answer is not in any retrieved document, achieving 11.8% accuracy in such cases\n",
      "for NQ, where an extractive model would score 0%.4.2 Abstractive Question\n",
      "Answering As shown in Table 2, RAG-Sequence outperforms BART on Open MS-MARCO\n",
      "NLG by 2.6 Bleu points and 2.6 Rouge-L points. RAG approaches state-of-the-art\n",
      "model performance, which is impressive given that (i) those models access gold\n",
      "passages with speciﬁc information required to generate the reference answer,\n",
      "(ii) many questions are unanswerable without the gold passages, and (iii) not\n",
      "all questions are answerable from Wikipedia alone. Table 3 shows some generated\n",
      "answers from our models. Qualitatively, we ﬁnd that RAG models hallucinate less\n",
      "and generate factually correct text more often than BART. Later, we also show\n",
      "that RAG generations are more diverse than BART generations (see §4.5).4.3\n",
      "Jeopardy Question Generation Table 2 shows that RAG-Token performs better than\n",
      "RAG-Sequence on Jeopardy question generation, with both models outperforming\n",
      "BART on Q-BLEU-1. Table 4 shows human evaluation results, over 452 pairs of\n",
      "generations from BART and RAG-Token. Evaluators indicated that BART was more\n",
      "factual than RAG in only 7.1% of cases, while RAG was more factual in 42.7% of\n",
      "cases, and both RAG and BART were factual in a further 17% of cases, clearly\n",
      "demonstrating the effectiveness of RAG on the task over a state-of-the-art\n",
      "generation model. - minimize the negative marginal log-likelihood of each\n",
      "target, P j − log p(yj|xj) using stochastic gradient descent with Adam [28].\n",
      "Updating the document encoder BERTd during training is costly as it requires the\n",
      "document index to be periodically updated as REALM does during pre-training\n",
      "[20]. We do not ﬁnd this step necessary for strong performance, and keep the\n",
      "document encoder (and index) ﬁxed, only ﬁne-tuning the query encoder BERTq and\n",
      "the BART generator.2.5 Decoding At test time, RAG-Sequence and RAG-Token require\n",
      "different ways to approximate arg maxy p(y|x). RAG-Token The RAG-Token model can\n",
      "be seen as a standard, autoregressive seq2seq genera- tor with transition\n",
      "probability: p0 ✓(yi|x, y1:i−1) = P z2top-k(p(·|x)) p⌘(zi|x)p✓(yi|x, zi, y1:i−1)\n",
      "To decode, we can plug p0 ✓(yi|x, y1:i−1) into a standard beam decoder. RAG-\n",
      "Sequence For RAG-Sequence, the likelihood p(y|x) does not break into a\n",
      "conventional per- token likelihood, hence we cannot solve it with a single beam\n",
      "search. Instead, we run beam search for each document z, scoring each hypothesis\n",
      "using p✓(yi|x, z, y1:i−1). This yields a set of hypotheses Y, some of which may\n",
      "not have appeared in the beams of all documents. To estimate the probability of\n",
      "an hypothesis y we run an additional forward pass for each document z for which\n",
      "y does not appear in the beam, multiply generator probability with p⌘(z|x) and\n",
      "then sum the probabilities across beams for the marginals. We refer to this\n",
      "decoding procedure as “Thorough Decoding.” - Evaluators also ﬁnd RAG generations\n",
      "to be more speciﬁc by a large margin. Table 3 shows typical generations from\n",
      "each model. Jeopardy questions often contain two separate pieces of information,\n",
      "and RAG-Token may perform best because it can generate responses that combine\n",
      "content from several documents. Figure 2 shows an example. When generating\n",
      "“Sun”, the posterior is high for document 2 which mentions “The Sun Also Rises”.\n",
      "Similarly, document 1 dominates the posterior when “A Farewell to Arms” is\n",
      "generated. Intriguingly, after the ﬁrst token of each book is generated, the\n",
      "document posterior ﬂattens. This observation suggests that the generator can\n",
      "complete the titles without depending on speciﬁc documents. In other words, the\n",
      "model’s parametric knowledge is sufﬁcient to complete the titles. We ﬁnd\n",
      "evidence for this hypothesis by feeding the BART-only baseline with the partial\n",
      "decoding \"The Sun. - Trends Inf. Retr.,3(4):333–389, April 2009. ISSN\n",
      "1554-0669.doi: 10.1561/ 1500000019. URL https://doi.org/10.1561/1500000019. [54]\n",
      "Irene Solaiman, Miles Brundage, Jack Clark, Amanda Askell, Ariel Herbert-Voss,\n",
      "Jeff Wu, Alec Radford, and Jian-Bing Wang. Release strategies and the social\n",
      "impacts of language models. ArXiv, abs/1908.09203, 2019.14 - For language\n",
      "generation tasks, we ﬁnd that RAG models generate more speciﬁc, diverse and\n",
      "factual language than a state-of-the-art parametric-only seq2seq baseline.1\n",
      "Introduction Pre-trained neural language models have been shown to learn a\n",
      "substantial amount of in-depth knowl- edge from data [47]. They can do so\n",
      "without any access to an external memory, as a parameterized implicit knowledge\n",
      "base [51, 52]. While this development is exciting, such models do have down-\n",
      "sides: They cannot easily expand or revise their memory, can’t straightforwardly\n",
      "provide insight into their predictions, and may produce “hallucinations” [38].\n",
      "Hybrid models that combine parametric memory with non-parametric (i.e.,\n",
      "retrieval-based) memories [20, 26, 48] can address some of these issues because\n",
      "knowledge can be directly revised and expanded, and accessed knowledge can be\n",
      "inspected and interpreted. REALM [20] and ORQA [31], two recently introduced\n",
      "models that combine masked language models [8] with a differentiable retriever,\n",
      "have shown promising results, 34th Conference on Neural Information Processing\n",
      "Systems (NeurIPS 2020), Vancouver, Canada.  Relevant passages: <extract relevant\n",
      "passages from the context here> User query: How does RAG differ from traditional\n",
      "language models in terms of architecture and processing flow?\n",
      "Answer:<|eot_id|><|start_header_id|>assistant<|end_header_id|>  Here are the\n",
      "relevant passages from the context:  * RAG can generate correct answers even\n",
      "when the correct answer is not in any retrieved document, achieving 11.8%\n",
      "accuracy in such cases for NQ, where an extractive model would score 0%. * RAG\n",
      "approaches state-of-the-art model performance, which is impressive given that\n",
      "(i) those models access gold passages with specific information required to\n",
      "generate the reference answer, (ii) many questions are unanswerable without the\n",
      "gold passages, and (iii) not all questions are answerable from Wikipedia alone.\n",
      "* The document encoder BERTd during training is costly as it requires the\n",
      "document index to be periodically updated as REALM does during pre-training. We\n",
      "do not find this step necessary for strong performance, and keep the document\n",
      "encoder (and index) fixed, only fine-tuning the query encoder BERTq and the BART\n",
      "generator. * RAG-Token can be seen as a standard, autoregressive seq2seq\n",
      "generator with transition probability: p0(yi|x, y1:i−1) = P z2top-k(p(·|x))\n",
      "p⌘(zi|x)p✓(yi|x, zi, y1:i−1) To decode, we can plug p0(yi|x, y1:i−1) into a\n",
      "standard beam decoder. RAG-Sequence For RAG-Sequence, the likelihood p(y|x) does\n",
      "not break into a conventional per-token likelihood, hence we cannot solve it\n",
      "with a single beam search. Instead, we run beam search for each document z,\n",
      "scoring each hypothesis using p✓(yi|x, z, y1:i−1). This yields a set of\n",
      "hypotheses Y, some of which may not have appeared in the beams of all documents.\n",
      "Answer:  RAG differs from traditional language models in terms of architecture\n",
      "and processing flow. Traditional language models, such as BART, are parametric-\n",
      "only models that generate text based on their internal knowledge base. In\n",
      "contrast, RAG combines a parametric query encoder and generator with a non-\n",
      "parametric retriever, which retrieves relevant documents from a large database.\n",
      "This allows RAG to access external knowledge and generate text that is more\n",
      "specific, diverse, and factual. Additionally, RAG's processing flow is different\n",
      "from traditional language models, as it involves retrieving relevant documents\n",
      "and then generating text based on those documents, rather than solely relying on\n",
      "internal knowledge.<|eot_id|>\n",
      "Context items:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'page_number': 5,\n",
       "  'sentence_chunk': '14.7 21.4 40.8 44.2 to more effective marginalization over documents. Furthermore, RAG can generate correct answers even when the correct answer is not in any retrieved document, achieving 11.8% accuracy in such cases for NQ, where an extractive model would score 0%.4.2 Abstractive Question Answering As shown in Table 2, RAG-Sequence outperforms BART on Open MS-MARCO NLG by 2.6 Bleu points and 2.6 Rouge-L points. RAG approaches state-of-the-art model performance, which is impressive given that (i) those models access gold passages with speciﬁc information required to generate the reference answer, (ii) many questions are unanswerable without the gold passages, and (iii) not all questions are answerable from Wikipedia alone. Table 3 shows some generated answers from our models. Qualitatively, we ﬁnd that RAG models hallucinate less and generate factually correct text more often than BART. Later, we also show that RAG generations are more diverse than BART generations (see §4.5).4.3 Jeopardy Question Generation Table 2 shows that RAG-Token performs better than RAG-Sequence on Jeopardy question generation, with both models outperforming BART on Q-BLEU-1. Table 4 shows human evaluation results, over 452 pairs of generations from BART and RAG-Token. Evaluators indicated that BART was more factual than RAG in only 7.1% of cases, while RAG was more factual in 42.7% of cases, and both RAG and BART were factual in a further 17% of cases, clearly demonstrating the effectiveness of RAG on the task over a state-of-the-art generation model.',\n",
       "  'chunk_char_count': 1553,\n",
       "  'chunk_word_count': 238,\n",
       "  'chunk_token_count': 388.25,\n",
       "  'embedding': array([ 4.31170985e-02,  2.64043007e-02,  2.02301843e-03, -1.13822725e-02,\n",
       "         -4.44857068e-02,  3.02337599e-03,  6.17722049e-03, -1.79233181e-03,\n",
       "         -2.45360024e-02, -4.93760221e-02,  2.82795746e-02, -1.63114872e-02,\n",
       "         -2.63323355e-02, -2.89770849e-02,  2.49552205e-02, -3.80551592e-02,\n",
       "          6.36958852e-02, -2.16109566e-02,  4.37189313e-03, -2.97691226e-02,\n",
       "         -2.33321618e-02,  7.89279211e-03, -1.73691455e-02,  1.08750565e-02,\n",
       "         -1.96849089e-02, -9.82686225e-03, -8.62549338e-03, -1.01582836e-02,\n",
       "         -5.91102149e-03, -2.14738604e-02, -2.05695443e-02,  7.91109055e-02,\n",
       "         -1.27867749e-02,  3.15832198e-02,  1.91226741e-06, -6.65756613e-02,\n",
       "          1.69683658e-02, -1.06966719e-02, -4.63518500e-02,  6.04315428e-03,\n",
       "          2.83440892e-02,  9.29883122e-02,  1.54909976e-02,  2.80518867e-02,\n",
       "         -5.36448881e-02, -3.03722965e-03,  1.41377300e-02,  3.61414850e-02,\n",
       "          3.15853544e-02,  4.31746729e-02,  1.74102485e-02, -3.22118886e-02,\n",
       "          6.99299052e-02,  6.43147854e-03,  1.30229637e-01, -4.09164242e-02,\n",
       "         -1.98845891e-03,  5.78246266e-02,  2.64259949e-02, -2.90544946e-02,\n",
       "          3.58875579e-04,  3.90617400e-02,  2.85317264e-02,  1.61557680e-03,\n",
       "          3.78994234e-02,  3.28759924e-02, -6.68641254e-02, -9.58480500e-03,\n",
       "          1.43903932e-02,  4.45773415e-02,  7.29966834e-02, -1.48143936e-02,\n",
       "         -1.07312864e-02,  6.31938949e-02,  4.33481857e-02,  6.99080527e-02,\n",
       "         -3.58246230e-02,  4.32834886e-02, -4.85817939e-02, -1.66563168e-02,\n",
       "          3.95116769e-02,  7.97120109e-03, -8.07114970e-03,  6.31008064e-03,\n",
       "          7.54186651e-04,  6.91266581e-02,  2.49672532e-02, -1.40389781e-02,\n",
       "         -5.61885256e-03,  1.74888894e-02, -2.42553130e-02, -7.68525377e-02,\n",
       "          1.58786979e-02,  2.12493222e-02, -3.82357463e-02,  1.69861056e-02,\n",
       "         -5.49965203e-02, -2.26767808e-02,  3.82172726e-02,  1.43224616e-02,\n",
       "         -7.66196800e-03,  1.91332791e-02,  8.31903704e-03,  2.49606036e-02,\n",
       "         -3.18131819e-02,  1.50344362e-02, -8.27342086e-03,  1.09240133e-02,\n",
       "         -5.05077094e-02, -9.70934890e-03, -4.51842621e-02, -2.42234673e-02,\n",
       "         -3.29257473e-02,  6.98374733e-02, -5.44884689e-02, -2.05734279e-02,\n",
       "         -2.05753762e-02,  5.80970244e-03,  3.40724476e-02, -1.37386099e-02,\n",
       "         -1.57637168e-02,  3.38683166e-02, -5.18537797e-02,  2.86890604e-02,\n",
       "         -8.53806362e-02,  4.83472133e-03, -5.29194139e-02,  1.35955224e-02,\n",
       "          6.17565960e-02, -3.68609875e-02,  1.31123904e-02, -7.17335474e-03,\n",
       "          2.24836636e-02, -3.05705592e-02,  1.68428589e-02,  1.20732365e-02,\n",
       "         -2.14926396e-02,  1.04700178e-02, -3.96593288e-02, -5.31675592e-02,\n",
       "         -1.31882429e-02, -5.73383160e-02,  1.16931694e-03, -8.83234516e-02,\n",
       "          1.58737134e-02,  2.03821156e-02, -4.34755236e-02,  1.20315058e-02,\n",
       "          6.05133921e-03,  4.91014495e-02, -1.94705687e-02,  1.94744710e-02,\n",
       "         -7.93572981e-03, -1.84894947e-03,  4.91153002e-02,  1.30915511e-02,\n",
       "          4.42178063e-02,  6.49479916e-03, -1.10058123e-02,  2.53855027e-02,\n",
       "          4.81365360e-02,  1.21738110e-02, -2.77281199e-02, -3.26027581e-03,\n",
       "          1.58094652e-02, -5.05940872e-04,  1.61123499e-02,  3.17451805e-02,\n",
       "          4.02527377e-02,  3.79925929e-02,  3.70479114e-02,  7.22916648e-02,\n",
       "         -2.90787667e-02, -2.18154229e-02,  6.30300343e-02,  3.67514081e-02,\n",
       "          1.10281128e-02,  3.54364999e-02,  4.42884229e-02,  5.02980035e-03,\n",
       "          4.98841479e-02,  7.17706829e-02, -2.56600939e-02,  2.92370636e-02,\n",
       "         -5.46585061e-02,  4.67515290e-02,  4.94281054e-02,  2.45277304e-02,\n",
       "         -2.11528298e-02, -3.80339622e-02, -1.94645766e-02,  2.36361716e-02,\n",
       "         -3.12141720e-02,  1.79064628e-02, -2.59877904e-03,  3.28647681e-02,\n",
       "         -3.93293127e-02,  3.32074463e-02, -4.68972092e-03, -5.29914126e-02,\n",
       "          3.18515487e-02, -5.39951697e-02,  7.00844601e-02,  4.20709290e-02,\n",
       "          5.62164485e-02, -1.24232071e-02, -2.16498859e-02, -2.11231336e-02,\n",
       "         -8.80438089e-03,  3.85234952e-02,  4.26992700e-02, -2.95252595e-02,\n",
       "         -2.34416164e-02, -1.61360968e-02,  5.33181243e-04,  2.13992153e-03,\n",
       "          3.73902963e-04,  9.19559691e-03,  1.36339488e-02,  3.34573886e-03,\n",
       "         -8.76141153e-03, -5.52893728e-02, -1.00193825e-02,  5.37419245e-02,\n",
       "         -5.41898347e-02, -3.72862965e-02, -3.23958173e-02, -4.88264626e-03,\n",
       "          1.97119005e-02,  4.16472815e-02, -1.01528866e-02,  4.06315587e-02,\n",
       "          4.59023565e-02, -1.64344702e-02, -3.98895070e-02, -1.55188758e-02,\n",
       "         -5.17605059e-02, -3.22745852e-02,  4.44825180e-02, -4.38396297e-02,\n",
       "         -4.20756778e-03,  3.31678875e-02,  4.74759843e-03, -2.38591749e-02,\n",
       "         -2.38753501e-02, -5.72414286e-02, -1.87989864e-02, -6.24903589e-02,\n",
       "         -1.63639318e-02,  3.43499072e-02, -8.35200865e-03, -4.69978675e-02,\n",
       "          9.80548039e-02, -8.32561683e-03,  2.59928126e-02,  3.38276327e-02,\n",
       "          2.65574292e-03,  1.30955584e-03, -6.84510916e-02, -5.03881928e-03,\n",
       "         -1.13780554e-02, -1.03638815e-02,  1.55402748e-02,  2.70769410e-02,\n",
       "         -3.03999637e-03, -6.56532720e-02,  2.91086757e-03, -8.32737088e-02,\n",
       "          3.36021483e-02, -2.55522076e-02,  2.31463239e-02,  2.11831052e-02,\n",
       "         -9.18580685e-03, -1.28347892e-02,  1.04537038e-02, -6.10982478e-02,\n",
       "         -1.84820537e-02,  4.09667753e-02,  3.09339687e-02,  3.59489955e-02,\n",
       "          2.42341198e-02,  5.23229763e-02, -1.83129869e-02, -2.49923505e-02,\n",
       "         -8.99952080e-04,  2.60658488e-02,  1.67663526e-02,  2.64384449e-02,\n",
       "         -5.43308146e-02,  9.63754579e-03, -6.39043525e-02,  9.82617866e-03,\n",
       "          2.40226705e-02, -6.41967077e-03,  6.96408330e-03, -2.35889517e-02,\n",
       "          6.84215128e-02,  3.54255959e-02,  5.65097183e-02, -1.56464949e-02,\n",
       "         -6.51326356e-03, -4.92179813e-03, -2.95867659e-02,  9.98899713e-03,\n",
       "         -3.48605327e-02,  1.16102090e-02, -1.68430409e-03, -6.50869608e-02,\n",
       "          1.09970495e-02,  2.17014216e-02,  3.43555585e-02, -7.97163288e-04,\n",
       "         -2.07817499e-02,  4.44404297e-02,  1.23920953e-02, -5.14267199e-02,\n",
       "         -2.93168314e-02, -2.81503368e-02, -2.78389994e-02,  4.22593914e-02,\n",
       "         -2.95514241e-02, -6.36266498e-03,  6.20419718e-02, -1.70190334e-02,\n",
       "          2.34609097e-02, -7.67060593e-02,  4.62528616e-02, -3.04895057e-03,\n",
       "          5.78456745e-02, -2.54699606e-02,  2.87991837e-02, -7.06506241e-03,\n",
       "         -3.21523361e-02, -6.98002204e-02,  9.30460263e-03,  2.91217417e-02,\n",
       "         -3.64020914e-02,  5.18979467e-02, -2.67243572e-02, -4.81546298e-03,\n",
       "         -1.47715993e-02, -4.20604646e-03, -4.27042469e-02, -4.03028950e-02,\n",
       "          4.59515899e-02,  2.53239926e-02, -2.10652500e-02,  2.42593866e-02,\n",
       "         -2.34927200e-02,  4.94872965e-03,  4.70164195e-02, -4.29530442e-03,\n",
       "         -5.79813533e-02, -1.56573728e-02, -1.39318639e-02,  8.58341008e-02,\n",
       "          6.64305910e-02,  8.43479298e-03,  5.98159134e-02,  2.88182497e-02,\n",
       "         -3.42527695e-04,  6.43509924e-02,  5.87680824e-02, -2.54864758e-03,\n",
       "          4.45209853e-02, -1.38839763e-02,  1.17203658e-02, -6.31561354e-02,\n",
       "         -5.19125946e-02,  2.79971790e-02,  5.67889102e-02, -4.60612960e-02,\n",
       "         -2.81754993e-02,  9.13594067e-02,  4.02723774e-02,  2.23355349e-02,\n",
       "         -2.32601371e-02, -2.70999949e-02,  2.45836452e-02,  1.48037188e-02,\n",
       "          3.40480432e-02, -7.56630450e-02, -5.84519189e-03, -4.83327825e-03,\n",
       "          3.70542482e-02,  8.63758940e-03, -5.27220145e-02,  2.92908289e-02,\n",
       "         -1.30360231e-01,  3.52782458e-02,  7.32875150e-03, -4.62697931e-02,\n",
       "         -2.01566163e-02, -2.49090213e-02, -2.91871708e-02,  3.87144499e-02,\n",
       "          3.11290883e-02,  5.20586669e-02, -1.93154216e-02,  4.33913805e-02,\n",
       "          4.04675603e-02,  2.10271273e-02, -6.01570960e-03,  1.94587670e-02,\n",
       "         -3.19660418e-02,  2.61323731e-02,  4.53641191e-02,  2.59764083e-02,\n",
       "         -1.90748796e-02, -6.43272400e-02,  8.11153557e-03, -5.40376194e-02,\n",
       "          2.87139695e-03, -7.26794032e-03,  6.70046359e-02, -1.70812160e-02,\n",
       "          2.26153694e-02, -6.46609515e-02,  2.83182487e-02,  1.23788966e-02,\n",
       "          1.43049164e-02,  1.02229202e-02,  4.65430282e-02, -1.94271225e-02,\n",
       "         -1.71431005e-02, -4.36607487e-02,  8.31770897e-03,  8.15057289e-03,\n",
       "          6.83382973e-02,  2.31307503e-02, -1.47841843e-02, -3.12645733e-02,\n",
       "         -2.21077073e-02,  1.94796808e-02, -5.68175390e-02, -2.96917371e-02,\n",
       "          5.52006215e-02, -1.34543600e-02, -6.05089478e-02, -1.07815608e-01,\n",
       "         -6.23182170e-02, -2.76632290e-02,  6.51551783e-02, -9.25041083e-03,\n",
       "          1.37648899e-02, -3.63322496e-02,  7.09995860e-04, -4.38185409e-02,\n",
       "         -5.84899820e-03, -3.05783693e-02, -2.03134250e-02, -1.94159187e-02,\n",
       "         -1.93948653e-02,  1.17374351e-02, -4.83808108e-02, -2.88597234e-02,\n",
       "         -5.19904215e-03, -4.07617725e-02, -3.46450210e-02,  5.94966672e-02,\n",
       "          6.37220740e-02,  3.20389941e-02, -3.58217629e-03, -6.07740460e-03,\n",
       "         -2.17634477e-02,  3.23270597e-02,  3.61108221e-02, -4.10500392e-02,\n",
       "          1.44405169e-02, -3.35052051e-02, -1.58981867e-02, -1.92147158e-02,\n",
       "          1.07159745e-02, -4.34181839e-02,  1.19422777e-02, -2.52960939e-02,\n",
       "          5.05100377e-02, -1.31489581e-03,  6.91911066e-03,  2.67212670e-02,\n",
       "          3.89699079e-02,  4.35690489e-03,  7.60320283e-04, -2.05214098e-02,\n",
       "         -1.24987140e-02,  7.46632088e-03, -1.99824944e-02, -1.21284192e-02,\n",
       "          1.42248766e-02,  5.39761363e-03,  4.07342413e-05,  5.19581977e-03,\n",
       "          2.01955419e-02, -6.92708464e-03, -4.20977399e-02,  6.46477565e-02,\n",
       "         -6.57925755e-02, -2.68137804e-03,  4.50668335e-02,  6.17836490e-02,\n",
       "          8.47037695e-03, -2.11872999e-02, -6.06353320e-02, -1.58330202e-02,\n",
       "          5.69497119e-04,  6.69362620e-02, -2.68697236e-02,  3.32549289e-02,\n",
       "         -1.50580856e-03, -1.17058493e-02,  2.31109858e-02,  8.85506999e-03,\n",
       "         -9.60069746e-02, -1.71086080e-02, -1.65415872e-02,  2.90526766e-02,\n",
       "          2.44809128e-02,  2.37567890e-02, -1.11615728e-03,  1.14165675e-02,\n",
       "         -7.21899699e-03, -7.00538279e-03, -1.24888169e-02,  4.79743816e-02,\n",
       "         -1.74608771e-02,  3.80928889e-02,  9.69636906e-03, -1.23448027e-02,\n",
       "         -1.44472588e-02,  5.21093011e-02, -2.84403074e-03,  3.08467951e-02,\n",
       "         -7.37846131e-03, -4.87746559e-02, -4.99466434e-02, -7.04564676e-02,\n",
       "         -3.51569988e-02,  7.30140554e-03, -1.92834605e-02, -7.43610505e-03,\n",
       "         -8.38158205e-02, -3.29103805e-02,  8.57892074e-03,  2.80179251e-02,\n",
       "          2.95449123e-02, -1.81545168e-02,  4.13284861e-02,  7.85060301e-02,\n",
       "          1.11211399e-02, -4.59135510e-02, -4.62333076e-02,  9.39791352e-02,\n",
       "         -1.00287668e-01, -1.40077423e-03,  1.43502979e-02, -6.33524893e-33,\n",
       "         -4.39478420e-02, -4.50201444e-02,  3.15498896e-02, -4.78362627e-02,\n",
       "         -2.76603270e-02, -1.27455806e-02, -2.70624533e-02,  4.90512559e-03,\n",
       "         -4.53966781e-02, -1.13188652e-02, -3.12639959e-02, -1.21161621e-02,\n",
       "          2.30426155e-02,  6.46555983e-03,  4.98758210e-03, -3.44790667e-02,\n",
       "          3.52793038e-02,  2.36148061e-03, -4.91436273e-02,  2.21375041e-02,\n",
       "          5.30437231e-02,  1.61902234e-02,  4.42485362e-02, -2.17768759e-03,\n",
       "          2.68970001e-02, -5.10674119e-02,  2.43479703e-02, -2.03153249e-02,\n",
       "         -1.79480296e-02,  5.15911058e-02, -9.16718598e-03,  3.27488072e-02,\n",
       "          1.60576515e-02, -3.75998318e-02, -7.78240850e-03,  5.70000429e-03,\n",
       "         -1.02313772e-01, -3.55456993e-02,  2.00574361e-02, -2.21455917e-02,\n",
       "         -4.24810499e-02, -3.58808078e-02,  2.63085794e-02,  1.99382845e-03,\n",
       "         -1.57788750e-02, -8.91836360e-03,  2.61966493e-02, -1.68429017e-02,\n",
       "         -3.94838341e-02, -4.21131849e-02, -3.98672707e-02,  3.16353352e-03,\n",
       "          2.24265363e-02,  8.12268909e-03, -4.92947400e-02,  7.13870898e-02,\n",
       "          1.30449533e-02, -3.90916914e-02, -4.66212109e-02,  7.98177999e-03,\n",
       "         -7.39716459e-03,  6.33531809e-02,  5.45383468e-02, -9.97471903e-03,\n",
       "         -1.26409822e-03,  4.50330526e-02,  2.33823750e-02, -2.27637049e-02,\n",
       "         -2.26818025e-02, -4.60143061e-03, -1.65672973e-02,  2.27321703e-02,\n",
       "          5.84331043e-02,  4.10054438e-02,  3.78076099e-02, -4.44195047e-03,\n",
       "         -6.10036738e-02,  6.51428625e-02,  4.67393436e-02,  4.49724421e-02,\n",
       "          1.77701823e-02, -3.52498181e-02, -2.68347766e-02,  2.26607937e-02,\n",
       "         -4.23343815e-02, -2.73219571e-02, -1.38980234e-02, -2.87930574e-02,\n",
       "          4.10278514e-02, -9.02719703e-03, -3.66548598e-02,  3.73900193e-03,\n",
       "          3.56980637e-02,  2.10278835e-02, -9.57051106e-03,  2.69323569e-02,\n",
       "         -2.13435534e-02,  2.73451465e-03, -3.51994857e-02, -4.97695699e-04,\n",
       "         -5.46223484e-02,  4.30468619e-02,  4.06159237e-02,  2.83252951e-02,\n",
       "          6.27233880e-03,  2.63144635e-02,  8.13610293e-03,  3.37099913e-03,\n",
       "         -6.14954606e-02,  6.01451332e-03, -3.61747146e-02,  5.96221015e-02,\n",
       "          2.32201684e-02, -1.59928277e-02,  4.44110222e-02, -6.50620833e-03,\n",
       "          7.94333592e-03,  1.25005823e-02,  1.21671270e-04, -4.26804088e-03,\n",
       "         -4.34007533e-02, -2.31753141e-02,  3.02598756e-02, -2.12625554e-03,\n",
       "         -2.00946312e-02,  3.69124748e-02, -3.66239324e-02,  7.56395832e-02,\n",
       "         -3.79419066e-02, -1.58961378e-02, -7.44108297e-03,  3.81140485e-02,\n",
       "          2.51479179e-07,  4.41443063e-02,  9.63096507e-03,  6.02316670e-02,\n",
       "          1.50045184e-02,  2.38370267e-03,  7.76367867e-03,  2.55894009e-02,\n",
       "          5.31187374e-03,  4.20882031e-02, -6.72868919e-04, -6.57130172e-03,\n",
       "          1.13916947e-02,  1.08605474e-02,  5.41394874e-02, -1.01370871e-01,\n",
       "         -9.13439021e-02, -4.88413423e-02,  3.38168889e-02, -4.75513823e-02,\n",
       "         -5.59533434e-03,  6.51740804e-02,  4.57304791e-02, -6.26103766e-03,\n",
       "         -4.42480184e-02, -9.37305391e-03, -3.22693884e-02,  2.38575023e-02,\n",
       "          4.29692157e-02, -3.27555798e-02,  9.30694491e-03,  9.03008692e-03,\n",
       "          2.79754773e-03,  2.24087611e-02,  2.66681593e-02, -2.25443803e-02,\n",
       "         -1.58860511e-03,  9.41551942e-03,  3.84132452e-02,  5.95216814e-04,\n",
       "         -6.72199279e-02, -4.34014611e-02, -2.13338844e-02,  4.34862450e-02,\n",
       "         -6.92104250e-02,  6.86025694e-02,  3.06360312e-02, -1.01271905e-02,\n",
       "          1.42526859e-02, -5.87492846e-02, -4.67000529e-03, -6.51682308e-03,\n",
       "         -1.28946919e-02, -3.39448713e-02,  2.11227536e-02, -4.12153313e-04,\n",
       "          1.45324068e-02, -1.17061920e-02, -4.32578363e-02, -1.26737617e-02,\n",
       "         -1.27061913e-02, -4.49228287e-02, -8.58513042e-02, -8.76721833e-03,\n",
       "          2.35838871e-02, -2.06788816e-02, -6.06922582e-02, -1.85746159e-02,\n",
       "          2.58604165e-34,  2.19971575e-02,  3.96404453e-02,  2.92627905e-02,\n",
       "         -2.88599078e-03,  1.77943744e-02, -1.67198498e-02, -2.15533040e-02,\n",
       "         -2.21801437e-02,  1.63125824e-02, -6.56862408e-02, -5.03478572e-02]),\n",
       "  'score': tensor(0.4293)},\n",
       " {'page_number': 3,\n",
       "  'sentence_chunk': 'minimize the negative marginal log-likelihood of each target, P j − log p(yj|xj) using stochastic gradient descent with Adam [28]. Updating the document encoder BERTd during training is costly as it requires the document index to be periodically updated as REALM does during pre-training [20]. We do not ﬁnd this step necessary for strong performance, and keep the document encoder (and index) ﬁxed, only ﬁne-tuning the query encoder BERTq and the BART generator.2.5 Decoding At test time, RAG-Sequence and RAG-Token require different ways to approximate arg maxy p(y|x). RAG-Token The RAG-Token model can be seen as a standard, autoregressive seq2seq genera- tor with transition probability: p0 ✓(yi|x, y1:i−1) = P z2top-k(p(·|x)) p⌘(zi|x)p✓(yi|x, zi, y1:i−1) To decode, we can plug p0 ✓(yi|x, y1:i−1) into a standard beam decoder. RAG-Sequence For RAG-Sequence, the likelihood p(y|x) does not break into a conventional per- token likelihood, hence we cannot solve it with a single beam search. Instead, we run beam search for each document z, scoring each hypothesis using p✓(yi|x, z, y1:i−1). This yields a set of hypotheses Y , some of which may not have appeared in the beams of all documents. To estimate the probability of an hypothesis y we run an additional forward pass for each document z for which y does not appear in the beam, multiply generator probability with p⌘(z|x) and then sum the probabilities across beams for the marginals. We refer to this decoding procedure as “Thorough Decoding.”',\n",
       "  'chunk_char_count': 1507,\n",
       "  'chunk_word_count': 240,\n",
       "  'chunk_token_count': 376.75,\n",
       "  'embedding': array([-2.53203022e-03,  6.97798580e-02,  4.40409221e-02, -3.25043174e-03,\n",
       "         -1.23778852e-02,  1.31757259e-02, -9.02457349e-03,  2.30115298e-02,\n",
       "         -1.09822214e-01, -6.72988221e-03, -7.16825202e-03, -8.31160787e-03,\n",
       "         -7.23617151e-03,  1.43623324e-02,  1.47601422e-02, -7.54584931e-03,\n",
       "          4.09869105e-02, -1.65563263e-02, -1.26469955e-02, -2.77677905e-02,\n",
       "          1.42524019e-03,  8.92348308e-03, -2.77485680e-02,  4.08448167e-02,\n",
       "         -3.30613963e-02,  4.68079932e-03, -3.88361923e-02,  4.85440977e-02,\n",
       "         -7.42215803e-03, -2.27206517e-02, -1.77512132e-02,  5.33373021e-02,\n",
       "          2.45127622e-02,  3.92662361e-02,  2.01830426e-06, -2.66915765e-02,\n",
       "         -2.43750028e-02, -1.09622709e-03, -4.07652147e-02,  1.67579968e-02,\n",
       "          2.85452046e-02, -3.50116263e-03, -1.07827066e-02,  1.02196811e-02,\n",
       "          3.58590996e-03, -8.15081522e-02,  4.91015278e-02,  1.84953418e-02,\n",
       "          6.27873419e-03,  6.56820610e-02, -3.71793611e-03, -4.13821861e-02,\n",
       "          2.29912270e-02, -3.49580869e-02,  9.79028717e-02, -9.63069499e-02,\n",
       "          1.37262633e-02, -1.64910387e-02,  3.58323306e-02, -2.22547613e-02,\n",
       "         -3.17637213e-02,  4.33897972e-02,  9.05071292e-03,  1.42464749e-04,\n",
       "          1.91544034e-02,  2.91933808e-02, -4.90444452e-02, -3.34219225e-02,\n",
       "          2.10425467e-03, -6.66370057e-03,  3.95321399e-02, -4.13867384e-02,\n",
       "          7.10890675e-03,  4.38382700e-02, -8.86448007e-03,  3.92947532e-02,\n",
       "         -2.08643936e-02,  8.27117730e-03, -3.84099670e-02,  6.55995263e-03,\n",
       "          3.99147021e-03,  1.47380016e-03,  3.02168378e-03, -2.40460634e-02,\n",
       "         -4.14603986e-02,  4.08826768e-02,  3.39020975e-02, -1.64508410e-02,\n",
       "         -1.50800468e-02,  1.07199675e-03, -2.59122588e-02, -4.12956737e-02,\n",
       "          1.73441675e-02, -1.05472999e-02, -3.59375700e-02,  1.04141468e-03,\n",
       "         -7.46661201e-02, -4.95323725e-02, -1.61825195e-02,  1.68944299e-02,\n",
       "         -4.71144821e-03,  2.07530838e-02,  1.92448646e-02,  4.40010354e-02,\n",
       "         -1.39726661e-02,  2.12022923e-02,  2.04160649e-04, -1.64927375e-02,\n",
       "         -7.03507438e-02, -3.63969132e-02, -1.54529465e-02, -9.84567776e-03,\n",
       "         -7.79452622e-02,  2.38264482e-02, -3.78793664e-02, -4.54342291e-02,\n",
       "         -2.71884818e-02, -5.44302119e-03,  6.08635843e-02, -1.82963051e-02,\n",
       "         -3.32929157e-02,  1.11193173e-02, -1.09794445e-01,  1.55193312e-02,\n",
       "          2.13680789e-02,  6.25108695e-03, -2.01709028e-02, -6.77474029e-03,\n",
       "         -9.31555405e-03, -3.33020948e-02, -2.19899639e-02,  4.57098484e-02,\n",
       "          1.48710553e-02, -1.94301996e-02, -1.77114066e-02,  1.37746213e-02,\n",
       "         -4.58386587e-03, -2.28271373e-02, -1.54133199e-03, -1.45384343e-02,\n",
       "          2.46011419e-03, -4.30884119e-03,  2.49441322e-02, -6.38186112e-02,\n",
       "          1.42083429e-02,  3.21471840e-02,  5.99940028e-03,  2.33046729e-02,\n",
       "         -5.61039569e-03, -3.37258801e-02,  1.74930617e-02,  3.21669839e-02,\n",
       "          1.63594037e-02, -4.27884469e-03,  4.09245044e-02,  1.56607367e-02,\n",
       "          4.87090601e-03,  9.32601169e-02, -5.65489521e-03,  5.26753217e-02,\n",
       "          2.91198734e-02, -1.03108604e-02, -1.56259891e-02,  4.30422984e-02,\n",
       "          3.12873423e-02,  7.78192561e-03, -1.60865337e-02,  2.55014910e-03,\n",
       "          4.12699282e-02,  1.10431360e-02,  6.41646013e-02, -3.89534165e-03,\n",
       "         -6.50775731e-02, -3.60696949e-02, -7.28920149e-03,  7.28298500e-02,\n",
       "          6.50419742e-02,  3.52239935e-03,  1.66888312e-02,  1.65902507e-02,\n",
       "         -1.40977623e-02,  2.99940687e-02,  4.28807139e-02,  1.29310852e-02,\n",
       "         -2.92793736e-02, -2.40595378e-02,  5.96563667e-02, -2.82339519e-03,\n",
       "         -4.18755636e-02,  2.57961582e-02, -2.04465650e-02, -4.91748285e-03,\n",
       "         -5.52305691e-02, -2.45808456e-02,  6.84087798e-02,  2.05371226e-03,\n",
       "         -5.93239591e-02,  3.80681977e-02,  1.14956312e-02, -3.88683900e-02,\n",
       "          9.86382458e-03, -3.47354747e-02,  7.31023867e-03, -1.58046354e-02,\n",
       "          8.98707807e-02, -3.08636017e-02, -1.78049169e-02,  5.35889936e-04,\n",
       "         -2.95503978e-02,  2.62855534e-02,  7.18306378e-03, -2.44709235e-02,\n",
       "          2.86347922e-02, -3.20127793e-02, -4.49180864e-02,  5.32553867e-02,\n",
       "         -3.47576686e-04,  3.21874730e-02, -6.82850555e-03,  5.62141836e-03,\n",
       "         -1.52523872e-02, -3.99837084e-02, -1.85629004e-04,  2.26761047e-02,\n",
       "         -4.67443541e-02, -1.84076186e-02,  2.87082754e-02, -1.73610356e-03,\n",
       "          8.31252262e-02,  3.29380459e-03, -1.91651657e-02,  1.52773848e-02,\n",
       "          6.52428418e-02, -2.70414427e-02, -3.48655470e-02,  3.19326594e-02,\n",
       "         -4.50612884e-03, -6.73096702e-02,  7.78797874e-03, -4.86893766e-02,\n",
       "          2.60799099e-02,  5.00707561e-03, -1.73863377e-02, -3.70879918e-02,\n",
       "          2.09969766e-02, -7.43960068e-02,  4.52780053e-02, -4.56671454e-02,\n",
       "          1.09417550e-03,  5.33575891e-03, -1.00636147e-02, -1.02435509e-02,\n",
       "          1.21276965e-02, -2.07878985e-02,  3.75849307e-02, -5.04481606e-02,\n",
       "         -1.71755208e-03,  3.15944590e-02, -3.62512432e-02,  2.36609634e-02,\n",
       "          1.61536727e-02, -3.07067856e-02, -1.79917756e-02,  4.55994941e-02,\n",
       "          1.97009631e-02,  2.35250667e-02, -1.62338205e-02, -7.60475397e-02,\n",
       "         -1.11190858e-03, -3.14242654e-02,  3.21757384e-02,  9.46099963e-03,\n",
       "          1.59594289e-03, -1.79814473e-02, -2.85218703e-03, -1.18106660e-02,\n",
       "         -3.90705606e-03, -1.11097340e-02,  1.22132292e-02,  2.67045735e-03,\n",
       "          1.46180727e-02, -2.80726217e-02,  2.39392184e-03, -3.89084592e-02,\n",
       "          2.04202570e-02,  6.09587282e-02, -1.77677851e-02, -3.22231166e-02,\n",
       "         -7.34991580e-02, -4.64156875e-03,  1.21465446e-02,  1.81051102e-02,\n",
       "         -7.97594059e-03, -3.96006070e-02,  2.06571110e-02, -3.98552045e-02,\n",
       "          7.63526186e-02,  2.94903070e-02,  9.63228568e-03,  4.28269990e-02,\n",
       "         -4.60585840e-02,  6.96424907e-03, -5.45526855e-02, -4.99211624e-03,\n",
       "         -2.25571468e-02,  3.11984178e-02, -3.35244685e-02, -6.73327446e-02,\n",
       "          5.76984771e-02,  2.91032009e-02, -8.40746332e-03,  9.44825634e-03,\n",
       "         -4.63040844e-02, -2.99905054e-02,  1.82749387e-02, -8.07316229e-02,\n",
       "         -1.09672714e-02, -4.48052920e-02,  9.60038230e-03,  3.05735487e-02,\n",
       "          1.87091455e-02, -1.14147260e-03,  4.82778847e-02, -4.92034703e-02,\n",
       "         -2.16766540e-02, -8.01380351e-02,  3.60217951e-02, -1.97382029e-02,\n",
       "         -1.97407547e-02, -1.93802435e-02,  4.23878692e-02, -5.39288409e-02,\n",
       "         -5.73906153e-02,  9.88587644e-03, -2.94687343e-04,  2.74864119e-02,\n",
       "         -1.58769311e-04, -1.34902531e-02,  2.61072498e-02,  2.89154034e-02,\n",
       "         -3.47840674e-02, -2.25677919e-02, -6.14773156e-03, -1.69128664e-02,\n",
       "          8.07469785e-02,  5.11443149e-03, -2.13344395e-02, -1.02400156e-02,\n",
       "         -8.83520842e-02,  3.81676853e-02,  8.99197627e-03,  3.98698673e-02,\n",
       "         -3.67748961e-02, -3.79187870e-03, -1.94608811e-02,  6.90761432e-02,\n",
       "          2.40007471e-02, -6.44751340e-02,  3.43340337e-02, -1.43637217e-03,\n",
       "         -3.12659964e-02,  5.34505099e-02,  8.78365338e-02,  5.70423305e-02,\n",
       "         -1.82803385e-02, -6.16911706e-03,  5.56851104e-02, -8.27952381e-03,\n",
       "         -1.17001375e-02,  1.62515976e-02,  6.26160353e-02,  5.25343698e-03,\n",
       "         -3.37294079e-02,  8.66689682e-02,  1.13942651e-02, -3.79773714e-02,\n",
       "         -1.43704331e-02,  1.94866571e-03,  4.65257168e-02,  8.06016568e-03,\n",
       "          9.38050915e-03, -8.74593928e-02, -1.57117695e-02,  3.31802256e-02,\n",
       "          8.58501494e-02,  2.66699418e-02,  2.11354368e-03,  3.24716084e-02,\n",
       "         -8.47504959e-02,  3.54680903e-02,  1.18939495e-02,  1.60558634e-02,\n",
       "         -4.00145054e-02, -5.07530570e-02, -2.99089793e-02,  7.60027999e-03,\n",
       "         -5.16168401e-03,  4.97395806e-02, -2.46108533e-03,  3.08616497e-02,\n",
       "          4.55979072e-02,  5.34771942e-02, -4.00184318e-02, -1.40600903e-02,\n",
       "         -4.57442701e-02,  3.56536359e-02,  1.07509546e-01,  3.39330034e-03,\n",
       "         -5.18762833e-03, -2.45041195e-02,  2.90792789e-02,  4.69371257e-03,\n",
       "         -2.48991381e-02, -2.96680089e-02, -1.82572808e-02, -2.16608737e-02,\n",
       "          2.14675944e-02, -2.27641426e-02,  3.88724431e-02, -2.78016645e-03,\n",
       "          3.92223895e-03, -2.11785026e-02,  2.47409511e-02, -2.53943708e-02,\n",
       "          1.34248193e-03, -3.63654457e-02,  2.09398959e-02,  2.72646137e-02,\n",
       "          7.26295263e-02,  1.82701871e-02,  2.57131853e-03, -1.50210168e-02,\n",
       "         -1.20122470e-02,  4.66240942e-02, -1.00888126e-02,  2.59911139e-02,\n",
       "          2.13337988e-02, -2.15877984e-02, -1.03526443e-01, -7.29817599e-02,\n",
       "         -2.36493070e-02, -1.16991589e-03,  7.78331012e-02, -1.90828983e-02,\n",
       "         -1.91402566e-02, -4.47325334e-02, -2.38181297e-02, -3.73260900e-02,\n",
       "         -9.76430718e-03,  6.62440946e-03, -1.42699806e-02, -5.59581630e-02,\n",
       "          2.66128238e-02,  3.98099609e-02, -3.24089080e-02, -2.54480466e-02,\n",
       "          2.44758241e-02, -5.81898950e-02, -3.90228704e-02,  3.64745818e-02,\n",
       "          2.20061578e-02,  3.04622296e-02,  1.92555059e-02, -3.08817234e-02,\n",
       "         -5.62653169e-02,  3.78728919e-02,  6.62553459e-02, -6.07316494e-02,\n",
       "          3.58969420e-02,  3.55644599e-02, -2.72695143e-02, -2.61657070e-02,\n",
       "          2.26933882e-02, -3.00613344e-02,  3.41201499e-02, -3.78350518e-03,\n",
       "          4.29194272e-02,  6.21658238e-03,  4.74715605e-03,  1.49743138e-02,\n",
       "          1.09533174e-02,  3.88179235e-02, -1.87155306e-02, -5.35161905e-02,\n",
       "         -1.02800019e-02,  3.69975530e-02, -3.25447472e-04,  2.75040288e-02,\n",
       "         -1.26762586e-02,  2.34503504e-02,  8.58079828e-03, -3.50023136e-02,\n",
       "          7.78348884e-03,  4.97581549e-02, -1.98835358e-02,  3.94047871e-02,\n",
       "         -5.23519702e-02,  4.65080589e-02,  2.98267305e-02,  4.84286100e-02,\n",
       "          2.08081007e-02, -4.25825901e-02, -5.66669274e-03,  4.81100101e-03,\n",
       "          2.79662684e-02,  3.67060527e-02, -4.79549691e-02,  1.63112469e-02,\n",
       "          3.38022374e-02,  3.29333916e-02,  5.00799641e-02, -4.48690075e-03,\n",
       "         -5.84052056e-02, -1.37272319e-02, -2.21056025e-02,  3.99116240e-02,\n",
       "          3.11749298e-02,  4.71625328e-02,  3.46726812e-02, -6.98587671e-03,\n",
       "          1.26327416e-02, -2.71750875e-02,  1.24139767e-02,  6.02601911e-04,\n",
       "          4.89108777e-03,  4.10222076e-02,  1.93746146e-02, -4.87880828e-03,\n",
       "          1.24192461e-02,  6.03015274e-02,  3.89361419e-02,  5.28352857e-02,\n",
       "         -6.88180421e-03, -3.64970155e-02, -3.68844904e-02, -4.42422256e-02,\n",
       "          6.14730604e-02,  7.63786072e-03, -5.31505086e-02,  1.39019070e-02,\n",
       "         -1.39269717e-02,  9.54904407e-03,  9.55983344e-03,  6.75339252e-04,\n",
       "          4.97985585e-03,  9.24954005e-03,  2.30517834e-02,  7.70066902e-02,\n",
       "         -2.48824395e-02,  5.47213573e-03, -2.42058211e-03,  5.02047613e-02,\n",
       "         -3.89772430e-02, -3.28054875e-02,  4.78330888e-02, -6.62506779e-33,\n",
       "         -4.09838073e-02, -4.89821332e-03, -1.07328892e-02, -5.03360741e-02,\n",
       "         -4.70466632e-03, -1.44183384e-02, -1.61565281e-03, -5.42780347e-02,\n",
       "          2.63229404e-02, -1.38507774e-02, -1.74000748e-02,  2.02515703e-02,\n",
       "          2.22952776e-02,  1.53890662e-02, -1.91681962e-02,  2.72528734e-02,\n",
       "          5.19546866e-02, -8.84360354e-03, -3.25210616e-02,  4.23892103e-02,\n",
       "          5.65023609e-02,  3.74546796e-02,  5.05429842e-02,  1.24869095e-02,\n",
       "         -3.14373486e-02, -9.96577460e-03, -4.16683586e-04, -2.74127256e-02,\n",
       "          1.47951578e-04,  3.53595577e-02, -3.33800800e-02, -3.69324125e-02,\n",
       "         -3.14174965e-02, -3.93327475e-02, -1.47494217e-02, -1.65155847e-02,\n",
       "         -9.18907896e-02, -1.49883637e-02, -2.70089228e-02,  3.14653777e-02,\n",
       "          5.76803787e-03, -1.70124620e-02,  5.75239630e-03,  8.74226354e-03,\n",
       "         -7.10296407e-02,  1.95863340e-02,  6.31659292e-03,  3.36821750e-03,\n",
       "         -5.61064743e-02, -9.29424912e-02, -1.67155843e-02,  3.32329050e-02,\n",
       "         -2.77076359e-03, -1.57230571e-02,  1.91613361e-02,  3.59719358e-02,\n",
       "          1.17602488e-02, -1.78591684e-02, -5.31461872e-02,  9.95724648e-03,\n",
       "         -1.53257735e-02,  1.05043441e-01,  1.59129314e-02, -4.66880295e-03,\n",
       "          4.82547889e-03,  3.86919379e-02,  6.54762313e-02, -5.98105416e-02,\n",
       "          5.20039983e-02, -3.78435059e-03,  1.65638644e-02, -1.37499096e-02,\n",
       "          2.72540376e-03, -1.33052971e-02,  9.10179466e-02,  2.36423556e-02,\n",
       "         -1.01137005e-01,  6.06908686e-02,  3.94360423e-02,  7.32162222e-02,\n",
       "          4.96267453e-02,  4.99500297e-02, -3.07432413e-02,  2.34590936e-02,\n",
       "         -1.69541109e-02, -6.63773865e-02, -5.83879231e-03, -1.12675810e-02,\n",
       "          1.12143876e-02,  3.95954810e-02, -3.04988902e-02,  3.31518054e-02,\n",
       "          8.50616544e-02,  3.24761425e-03, -1.78622324e-02,  3.58720012e-02,\n",
       "         -2.41175145e-02, -8.12450307e-04, -4.50038873e-02,  3.66823375e-02,\n",
       "         -1.78826600e-02, -2.47006826e-02,  1.19548358e-01, -1.81894505e-03,\n",
       "          9.34001151e-03, -1.32212872e-02,  3.80057767e-02,  2.13673245e-02,\n",
       "         -6.13534525e-02, -2.71749366e-02, -3.77598293e-02,  2.03668792e-02,\n",
       "         -3.31807067e-03,  1.77944899e-02,  6.57614321e-02, -2.57080309e-02,\n",
       "          1.06126079e-02,  1.92322992e-02,  8.08005594e-03, -8.15432146e-03,\n",
       "         -3.13833468e-02, -6.06892339e-04,  1.78757906e-02,  8.98311380e-03,\n",
       "         -2.70948727e-02,  1.56877469e-02, -5.93400896e-02, -2.15174779e-02,\n",
       "          2.47647148e-03, -3.21399644e-02, -2.73115113e-02,  4.32684682e-02,\n",
       "          2.74573068e-07,  2.05505639e-02,  6.20701769e-03,  9.16504487e-02,\n",
       "          6.77854102e-03,  1.49004562e-02, -1.03909988e-03, -3.56671736e-02,\n",
       "          7.37582892e-02,  9.20130964e-03,  5.31338295e-03, -1.18663860e-02,\n",
       "         -5.63712278e-03,  3.06082889e-02,  2.85205524e-02, -8.32862705e-02,\n",
       "         -3.50131430e-02, -4.75574099e-02,  3.73117439e-02, -8.71177763e-02,\n",
       "         -1.94756687e-02,  3.83511279e-03,  7.68829733e-02, -2.72089858e-02,\n",
       "         -2.84902398e-02,  4.17618714e-02, -1.91660356e-02,  2.91636363e-02,\n",
       "          5.45621365e-02, -2.96047442e-02,  2.95141805e-02, -1.45942182e-03,\n",
       "         -4.36333381e-02, -6.81543536e-03, -1.55383376e-02, -6.72269100e-03,\n",
       "          8.70508328e-03, -2.68686027e-03,  5.39340675e-02, -1.50125688e-02,\n",
       "         -7.43306205e-02,  2.34632771e-02,  3.11354604e-02, -1.76382810e-02,\n",
       "          9.61286016e-03,  4.96291332e-02,  5.22898547e-02, -3.51683795e-02,\n",
       "          2.87983678e-02, -3.00776660e-02, -3.95143870e-03, -2.26688702e-02,\n",
       "         -3.20444107e-02, -7.03237625e-03,  1.94949228e-02,  2.28432827e-02,\n",
       "          5.43964270e-04, -1.17395250e-02, -4.40728366e-02,  2.05043331e-02,\n",
       "         -5.47343194e-02, -5.19833155e-02, -2.84709223e-02, -2.54467614e-02,\n",
       "          8.11596885e-02, -1.16439713e-02, -5.25452048e-02, -3.11260074e-02,\n",
       "          3.22405407e-34,  3.83442119e-02,  3.09157632e-02, -3.27320062e-02,\n",
       "          2.17803493e-02,  1.69446766e-02, -5.63993491e-02, -5.47745675e-02,\n",
       "          3.35333087e-02,  1.01881968e-02, -1.01821959e-01, -5.13204485e-02]),\n",
       "  'score': tensor(0.4046)},\n",
       " {'page_number': 5,\n",
       "  'sentence_chunk': 'Evaluators also ﬁnd RAG generations to be more speciﬁc by a large margin. Table 3 shows typical generations from each model. Jeopardy questions often contain two separate pieces of information, and RAG-Token may perform best because it can generate responses that combine content from several documents. Figure 2 shows an example. When generating “Sun”, the posterior is high for document 2 which mentions “The Sun Also Rises”. Similarly, document 1 dominates the posterior when “A Farewell to Arms” is generated. Intriguingly, after the ﬁrst token of each book is generated, the document posterior ﬂattens. This observation suggests that the generator can complete the titles without depending on speciﬁc documents. In other words, the model’s parametric knowledge is sufﬁcient to complete the titles. We ﬁnd evidence for this hypothesis by feeding the BART-only baseline with the partial decoding \"The Sun.',\n",
       "  'chunk_char_count': 908,\n",
       "  'chunk_word_count': 139,\n",
       "  'chunk_token_count': 227.0,\n",
       "  'embedding': array([ 3.92181352e-02,  5.18996082e-02, -1.48379346e-02, -3.13439802e-03,\n",
       "         -4.30148318e-02,  8.43076222e-03,  9.13779158e-03,  1.52818123e-02,\n",
       "         -3.78429592e-02, -1.12139601e-02,  2.21446026e-02, -2.00165901e-02,\n",
       "         -1.39898118e-02, -5.39988792e-03,  1.37750739e-02, -2.65621003e-02,\n",
       "          4.96780314e-02, -3.98173407e-02,  1.98573191e-02, -4.04969901e-02,\n",
       "         -4.22450379e-02, -4.51931311e-03, -7.70605076e-03,  1.14442920e-02,\n",
       "         -7.13571254e-03, -3.01129883e-04, -1.62245408e-02,  1.67799406e-02,\n",
       "         -2.55497117e-02, -2.95192953e-02, -3.74541841e-02,  6.35563508e-02,\n",
       "         -9.45771113e-03,  6.59486279e-02,  1.87068440e-06, -5.74601442e-02,\n",
       "         -1.71929679e-03, -1.48427235e-02, -3.61537375e-02,  7.13820988e-03,\n",
       "          7.13750198e-02,  7.74711967e-02,  1.84418913e-02, -5.19461604e-03,\n",
       "         -4.41884063e-02, -7.02368189e-03,  3.72456796e-02,  1.34831257e-02,\n",
       "         -1.23078479e-02,  4.83509116e-02,  8.13283492e-03, -6.18650811e-03,\n",
       "          6.39444813e-02, -1.60626881e-02,  1.25754088e-01, -5.82046881e-02,\n",
       "         -2.30744146e-02,  1.40220029e-02,  4.44807764e-03, -2.34683906e-03,\n",
       "         -2.61059981e-02,  2.52648685e-02,  2.79251300e-02,  2.64239777e-02,\n",
       "          2.71733236e-02,  2.59811152e-02, -3.66559103e-02,  5.05533349e-03,\n",
       "         -7.15728616e-03,  1.56088965e-02,  1.19801603e-01, -4.25092131e-03,\n",
       "         -2.82523893e-02,  3.08216047e-02,  4.57685404e-02,  5.68155646e-02,\n",
       "         -5.76299578e-02,  2.47152131e-02, -4.72777225e-02, -1.16557172e-02,\n",
       "          6.29437342e-02,  1.12807052e-02, -4.46885545e-03, -7.68055208e-04,\n",
       "         -1.07668247e-02,  6.55966476e-02,  2.08972543e-02, -2.67506521e-02,\n",
       "         -2.22712085e-02,  1.46019831e-02, -1.76691748e-02, -6.79794550e-02,\n",
       "          1.68122817e-03, -1.20982807e-02, -3.18235718e-02,  1.71931926e-02,\n",
       "         -2.82247998e-02, -1.23766558e-02,  2.59365588e-02,  7.43423495e-03,\n",
       "          2.59870272e-02,  8.87937006e-03, -6.61606062e-03,  4.27730046e-02,\n",
       "          8.65924358e-03,  2.73574609e-02,  1.35129010e-02, -4.28984780e-03,\n",
       "         -6.85495883e-02, -1.35970553e-02, -3.94449420e-02, -1.21221123e-02,\n",
       "         -1.61131881e-02,  5.83004355e-02, -5.43806851e-02, -4.10724506e-02,\n",
       "         -2.42371541e-02, -8.59198440e-03,  4.18600254e-02, -7.63185369e-03,\n",
       "         -1.53903281e-02,  3.47664431e-02, -6.68069124e-02,  2.53172684e-02,\n",
       "         -8.14408734e-02,  8.66485853e-03, -5.76702766e-02,  5.16723376e-03,\n",
       "          2.83597391e-02, -2.24901792e-02, -5.45063987e-03, -2.30238284e-03,\n",
       "          2.45446954e-02, -3.48311141e-02,  2.03025024e-02,  8.21423810e-03,\n",
       "          3.47446580e-03, -8.52042064e-03, -1.31700737e-02, -4.94625382e-02,\n",
       "         -3.24311294e-02, -5.69958761e-02,  3.26254591e-02, -6.61823750e-02,\n",
       "          1.71020031e-02,  4.88886051e-03, -1.67033672e-02,  2.17061341e-02,\n",
       "         -8.06632265e-03,  2.25603785e-02, -4.13116775e-02,  5.54772615e-02,\n",
       "          2.49428414e-02,  1.32285589e-02, -8.30219127e-03, -2.44319323e-04,\n",
       "          1.16249276e-02,  6.70240968e-02, -9.35368612e-03,  5.48659116e-02,\n",
       "          3.65124196e-02,  1.38312369e-03, -1.02516171e-02,  7.18276715e-03,\n",
       "         -3.97075294e-03,  3.22541930e-02, -6.25825720e-03,  2.32816488e-02,\n",
       "          2.36238465e-02,  2.82840673e-02,  3.89800631e-02,  3.56988274e-02,\n",
       "         -3.87436152e-02,  2.52476204e-02,  5.54359369e-02,  3.36054116e-02,\n",
       "          2.51765903e-02,  2.78036129e-02,  4.46249582e-02,  5.58153515e-05,\n",
       "          1.26155764e-02,  9.32580084e-02, -1.15874643e-02,  3.27781495e-03,\n",
       "         -6.29556701e-02,  1.93468183e-02,  1.84645336e-02, -2.06962060e-02,\n",
       "         -2.40050405e-02, -3.95697728e-02, -2.42045745e-02,  5.34813292e-02,\n",
       "         -2.49297358e-02,  1.19572589e-02,  3.03585753e-02,  4.60085981e-02,\n",
       "         -4.60313410e-02, -4.77288058e-03, -3.46915185e-04, -4.13421504e-02,\n",
       "          1.40637634e-02, -4.07635793e-02,  5.45337386e-02,  4.23806496e-02,\n",
       "          6.49858266e-02,  4.64336394e-04, -1.28308628e-02,  9.69335623e-03,\n",
       "          6.85356138e-03,  3.20966244e-02,  7.32684955e-02, -2.30158661e-02,\n",
       "         -6.05014246e-03, -9.03074723e-03, -1.97425764e-02, -4.96934587e-03,\n",
       "          1.63010415e-02,  3.85391116e-02, -3.10630444e-02, -2.44313129e-03,\n",
       "         -2.06748154e-02, -3.61699164e-02, -3.60501930e-03,  3.66386287e-02,\n",
       "         -3.33875604e-02, -5.82609363e-02, -2.70540696e-02, -9.83666256e-03,\n",
       "          6.92352280e-02,  1.93254910e-02,  5.27411513e-03,  2.69121826e-02,\n",
       "          3.81238759e-02, -1.95751106e-03, -2.59245653e-02,  2.31590793e-02,\n",
       "         -3.25599201e-02, -3.96445990e-02,  7.07840919e-03, -5.25106043e-02,\n",
       "          1.81190502e-02, -2.93499581e-03,  1.87783372e-02, -3.60113680e-02,\n",
       "          4.28104354e-03, -2.02123951e-02,  2.34432351e-02, -3.10209822e-02,\n",
       "         -8.66400718e-04, -9.01890732e-03, -1.74363423e-02, -4.55860943e-02,\n",
       "          9.56140012e-02,  1.28998728e-02,  3.30296420e-02, -1.41271790e-02,\n",
       "         -1.86795685e-02,  8.96173296e-04, -4.68889326e-02,  5.40723139e-03,\n",
       "         -1.07712671e-02, -9.55525972e-03, -1.06778806e-02,  2.72558201e-02,\n",
       "          1.63543868e-04, -3.85252312e-02, -9.61396750e-03, -1.26857936e-01,\n",
       "          3.15439701e-02, -7.25996401e-03,  8.38771462e-03, -2.39652046e-03,\n",
       "         -2.79388614e-02, -2.35298350e-02,  1.36324679e-02, -4.04541865e-02,\n",
       "         -2.27313656e-02,  3.49065028e-02,  4.18801717e-02, -4.18639695e-03,\n",
       "          1.62156913e-02,  3.85035165e-02, -2.16482487e-02, -1.76074393e-02,\n",
       "         -2.12460253e-02,  5.11582382e-02,  5.09804338e-02,  5.18551357e-02,\n",
       "         -5.55057079e-02,  1.58968300e-03, -4.13557738e-02, -3.59715172e-03,\n",
       "          2.47222418e-03, -2.24213209e-03,  1.62406079e-02, -2.45292559e-02,\n",
       "          4.78877388e-02, -4.33046167e-04,  1.86506230e-02,  1.88946761e-02,\n",
       "         -7.72357732e-03, -3.25686969e-02, -2.67103612e-02,  1.96585078e-02,\n",
       "         -4.67892699e-02,  3.16270743e-03, -2.24557165e-02, -8.15380290e-02,\n",
       "          6.43718475e-03,  8.92857090e-03,  3.35024185e-02, -2.71153194e-03,\n",
       "         -3.44877094e-02,  7.55968764e-02, -3.83712165e-03, -5.64483479e-02,\n",
       "         -4.35686707e-02, -4.98664081e-02, -2.81727128e-02,  6.08132780e-02,\n",
       "         -1.87121984e-02, -2.85329968e-02,  5.44488356e-02, -2.52979994e-02,\n",
       "          1.29082613e-03, -9.17538926e-02,  6.71079010e-02, -2.34309416e-02,\n",
       "          9.28402990e-02, -1.70912798e-02,  2.69645248e-02,  1.45758866e-04,\n",
       "         -4.44513075e-02, -8.77190828e-02,  3.64632010e-02,  4.93060313e-02,\n",
       "         -8.18714686e-03,  3.06313094e-02, -1.35431280e-02, -2.48840433e-02,\n",
       "          1.87122205e-04, -1.21642388e-02, -3.03477664e-02, -3.45309079e-02,\n",
       "          4.60220538e-02,  4.12490917e-03,  3.84440646e-03,  2.41622813e-02,\n",
       "         -3.39096747e-02,  4.99215769e-03,  7.13172602e-03, -2.18580030e-02,\n",
       "         -5.91124892e-02, -1.75668132e-02, -2.44753119e-02,  6.18343093e-02,\n",
       "          6.55892715e-02, -3.19652110e-02,  5.30922450e-02, -2.09265612e-02,\n",
       "          1.62652321e-03,  2.45222636e-02,  6.45906925e-02,  7.98266567e-03,\n",
       "          2.67760642e-02,  1.16338274e-02,  3.61339338e-02, -2.95878220e-02,\n",
       "         -4.24311161e-02,  2.85755247e-02,  5.43252267e-02, -3.89749520e-02,\n",
       "          1.02377729e-02,  9.39437896e-02,  3.33181210e-02, -4.23178950e-04,\n",
       "         -1.21660484e-02, -2.92687137e-02,  6.23590359e-03,  1.65537894e-02,\n",
       "          1.43264970e-02, -6.14439212e-02,  2.13829428e-02,  1.33960815e-02,\n",
       "          3.75979245e-02,  6.88477745e-03, -4.30130213e-02,  7.20317662e-03,\n",
       "         -1.04172632e-01,  6.01579100e-02,  1.10077914e-02, -4.17412594e-02,\n",
       "          1.45048881e-02, -7.79355178e-03, -2.63757575e-02,  7.06922321e-04,\n",
       "          2.83527058e-02,  4.13797870e-02, -2.51250956e-02,  2.72268038e-02,\n",
       "          6.22385473e-04,  6.59968331e-02,  4.17351024e-03,  1.18659651e-02,\n",
       "         -5.38509190e-02,  2.81271320e-02,  3.81463468e-02,  2.75331065e-02,\n",
       "         -2.67607793e-02, -4.23311926e-02, -1.76714566e-02, -5.62953316e-02,\n",
       "          1.18875806e-03, -3.42100416e-03,  6.76852688e-02,  1.04790507e-02,\n",
       "          2.63951756e-02, -5.05507663e-02,  1.04419189e-02,  1.95598416e-03,\n",
       "          1.67672653e-02,  8.43743235e-03,  1.43113183e-02, -1.99082419e-02,\n",
       "         -5.10894097e-02, -4.12347727e-02,  5.32113807e-03, -1.17430864e-02,\n",
       "          8.38033557e-02,  3.61451209e-02, -2.61690281e-02, -2.37514544e-03,\n",
       "         -2.17183344e-02,  3.87666896e-02, -2.96247117e-02,  1.55154401e-02,\n",
       "          3.52066085e-02, -3.64752635e-02, -8.25986415e-02, -8.98980349e-02,\n",
       "         -5.37623651e-02, -2.42140554e-02,  8.89911875e-02,  1.33736786e-02,\n",
       "          1.75804440e-02, -7.02903569e-02, -2.29296740e-02, -1.59727186e-02,\n",
       "          3.73980589e-02, -1.50791509e-02, -5.40649891e-02, -2.46284530e-02,\n",
       "         -2.33415700e-02,  1.01696579e-02, -7.22204968e-02, -5.11782579e-02,\n",
       "         -9.05085690e-05, -6.82537407e-02, -2.62902286e-02,  5.60547002e-02,\n",
       "          3.13183367e-02,  4.65013534e-02,  2.78831576e-04, -3.34964097e-02,\n",
       "         -1.53897824e-02,  2.97670327e-02,  6.46848558e-03, -3.32914405e-02,\n",
       "          3.89716364e-02, -2.16366500e-02, -1.37343323e-02, -2.64459644e-02,\n",
       "          1.74304508e-02, -2.29941085e-02,  3.27639878e-02,  1.41391093e-02,\n",
       "          3.40977162e-02,  2.28673648e-02,  2.48873327e-02,  1.68222338e-02,\n",
       "          3.02121844e-02,  5.59526086e-02, -2.93315426e-02, -4.97264266e-02,\n",
       "         -5.70074376e-03,  1.76882476e-03, -2.32785940e-02, -7.85633270e-03,\n",
       "          8.58410727e-03, -1.24985157e-02, -3.21870926e-03,  1.46389529e-02,\n",
       "         -9.06156469e-03,  7.53159169e-03, -3.67756337e-02,  1.07089929e-01,\n",
       "         -8.78020301e-02, -1.20925112e-02,  7.32088462e-02,  3.55723985e-02,\n",
       "          1.80875696e-02,  3.83664912e-04, -1.85967553e-02,  2.06766203e-02,\n",
       "         -5.15081687e-03,  3.02644484e-02, -1.20374085e-02,  3.21937725e-02,\n",
       "          2.16623768e-04, -8.88989307e-03, -1.31895440e-02, -6.70850230e-03,\n",
       "         -1.13582507e-01, -4.42844406e-02,  1.02169793e-02,  4.41717617e-02,\n",
       "          1.50126386e-02, -6.38047978e-03, -9.53099225e-03,  2.70587835e-03,\n",
       "          7.38538569e-03, -5.38249806e-05, -2.57712435e-02,  4.42751013e-02,\n",
       "         -1.91348121e-02,  2.38037799e-02,  2.46876981e-02, -9.82495770e-03,\n",
       "         -3.65527859e-03,  6.11684136e-02,  9.63569619e-03,  3.73644568e-02,\n",
       "         -1.92657784e-02, -3.29232104e-02, -4.62724864e-02, -5.68399578e-02,\n",
       "         -9.08113830e-03,  4.06815000e-02, -1.05192270e-02,  8.28550570e-03,\n",
       "         -9.49003845e-02, -7.22225755e-03,  6.32417668e-03,  2.12478023e-02,\n",
       "          2.53892299e-02, -1.51372515e-02,  2.99669597e-02,  1.20178074e-01,\n",
       "         -1.75093729e-02, -5.06426208e-02, -2.61231940e-02,  6.05340526e-02,\n",
       "         -8.24110359e-02, -8.76076985e-03,  1.28531037e-02, -6.25860596e-33,\n",
       "         -4.46131788e-02, -5.14378259e-03,  2.70817745e-02, -3.50170173e-02,\n",
       "         -2.54508499e-02, -7.84722343e-03, -2.26360839e-02, -2.95123039e-03,\n",
       "         -1.25316940e-02, -2.83703785e-02, -4.02946807e-02, -7.39288842e-03,\n",
       "          2.27672737e-02, -1.49210440e-02,  3.04181557e-02, -5.26393950e-02,\n",
       "          5.53305484e-02,  5.35131432e-03, -4.92196046e-02,  2.10860390e-02,\n",
       "          4.57371995e-02, -1.35143477e-04,  4.17939425e-02,  9.73773189e-03,\n",
       "          4.40988764e-02, -3.20348628e-02, -1.62778068e-02, -3.16052772e-02,\n",
       "         -3.67960730e-03,  6.75312728e-02, -9.42391250e-03,  1.88767035e-02,\n",
       "          1.27266413e-02, -2.60257050e-02, -6.28730864e-04, -5.64080942e-03,\n",
       "         -7.15170801e-02, -3.13965790e-02,  4.71539982e-02, -2.10630782e-02,\n",
       "         -7.12996582e-03, -6.84983581e-02,  4.22068462e-02,  7.94797577e-03,\n",
       "         -3.88106778e-02,  7.52889737e-03,  3.86860296e-02, -3.24035920e-02,\n",
       "         -4.24241722e-02, -4.87670116e-02, -4.63828407e-02, -8.11000075e-03,\n",
       "          1.78212058e-02,  2.56682206e-02, -2.51177698e-03,  5.54745011e-02,\n",
       "          2.98103485e-02,  1.74823254e-02, -1.07904365e-02,  3.06648500e-02,\n",
       "         -8.93517118e-03,  5.00760414e-02,  2.66568270e-02, -6.80748373e-03,\n",
       "          1.92684913e-03,  4.31300662e-02,  3.53920721e-02,  4.50968789e-03,\n",
       "          9.14277043e-03, -7.97852781e-03,  1.74106210e-02,  3.69297378e-02,\n",
       "          5.53600937e-02,  5.42538241e-02,  6.64627030e-02, -1.92912351e-02,\n",
       "         -2.89277472e-02,  4.46166508e-02,  5.37557416e-02,  2.22875793e-02,\n",
       "          1.39428964e-02, -2.39118487e-02, -5.23155443e-02,  6.31169137e-03,\n",
       "         -4.54620607e-02, -5.58447056e-02, -3.86948064e-02, -2.23884601e-02,\n",
       "          1.88175496e-02,  5.76092117e-03, -2.79668011e-02, -5.30568091e-03,\n",
       "          5.12874573e-02,  9.21278447e-03, -2.57103927e-02,  8.91646929e-03,\n",
       "         -2.19024122e-02,  2.62524188e-02, -1.51140802e-02,  1.84087139e-02,\n",
       "         -3.29846852e-02,  3.00740171e-02,  5.49650267e-02,  3.42038386e-02,\n",
       "          1.69960260e-02,  2.94841621e-02,  2.34886277e-02,  8.04475974e-03,\n",
       "         -6.01391532e-02, -1.47488723e-02, -2.11349130e-02,  2.65565570e-02,\n",
       "          2.37692222e-02, -2.81779747e-02,  5.68627119e-02,  1.10839494e-02,\n",
       "          2.29455810e-02, -7.16120936e-03,  2.21887995e-02,  2.24929284e-02,\n",
       "         -5.31941205e-02, -2.05718223e-02, -1.75447273e-03,  1.58595797e-02,\n",
       "         -4.87975124e-03,  3.42304003e-03, -1.46791218e-02,  1.11095188e-02,\n",
       "          1.08942641e-02, -1.71246044e-02, -3.89500633e-02,  4.58927378e-02,\n",
       "          2.57499465e-07,  2.57583372e-02,  3.91425677e-02,  1.92493796e-02,\n",
       "          9.18134581e-03,  2.04953086e-02,  1.90199856e-02, -2.61020102e-03,\n",
       "          1.56429391e-02,  3.96240316e-02,  2.04408914e-02,  1.04344320e-02,\n",
       "         -1.01465238e-02,  1.33864852e-02,  6.92663044e-02, -1.33198977e-01,\n",
       "         -9.89016369e-02, -5.00339158e-02,  2.92570367e-02, -6.59235045e-02,\n",
       "          1.40008560e-04,  4.58900072e-02,  5.48399054e-02,  1.55175310e-02,\n",
       "         -3.46405283e-02, -9.48803849e-04, -3.76774706e-02,  2.73508057e-02,\n",
       "         -2.38705613e-03, -3.57465521e-02,  2.87541989e-02, -1.11099044e-02,\n",
       "         -2.20407024e-02,  8.08216259e-03,  4.36911955e-02, -2.54866760e-03,\n",
       "          1.50411138e-02,  7.29884487e-03,  1.50202820e-02,  2.05723736e-02,\n",
       "         -4.59137112e-02, -3.70325632e-02,  1.39575163e-02,  1.68204866e-02,\n",
       "         -6.65176958e-02,  7.96125755e-02,  4.31276485e-02, -5.21151209e-03,\n",
       "         -1.00949891e-02, -5.83829917e-02,  5.02570253e-03,  3.29679833e-03,\n",
       "         -1.14914691e-02, -2.83640902e-02,  2.46029757e-02,  3.84392566e-03,\n",
       "          4.57183784e-03,  7.35552609e-03, -4.34580185e-02,  5.91765717e-03,\n",
       "         -2.07795724e-02, -4.71414477e-02, -9.82311890e-02, -3.81435174e-03,\n",
       "          1.01872347e-02, -8.15307163e-03, -1.36217043e-01, -2.23923083e-02,\n",
       "          2.94438537e-34,  6.34318069e-02,  2.82433238e-02,  6.56821858e-03,\n",
       "         -3.45302001e-02,  1.92550737e-02, -1.92961469e-02, -1.54582961e-02,\n",
       "         -7.56990723e-03,  1.99776255e-02, -8.25680345e-02, -4.31818180e-02]),\n",
       "  'score': tensor(0.4020)},\n",
       " {'page_number': 13,\n",
       "  'sentence_chunk': 'Trends Inf. Retr.,3(4):333–389, April 2009. ISSN 1554-0669.doi: 10.1561/ 1500000019. URL https://doi.org/10.1561/1500000019. [54] Irene Solaiman, Miles Brundage, Jack Clark, Amanda Askell, Ariel Herbert-Voss, Jeff Wu, Alec Radford, and Jian-Bing Wang. Release strategies and the social impacts of language models. ArXiv, abs/1908.09203, 2019.14',\n",
       "  'chunk_char_count': 344,\n",
       "  'chunk_word_count': 41,\n",
       "  'chunk_token_count': 86.0,\n",
       "  'embedding': array([ 7.45605379e-02,  7.66793787e-02, -4.48308140e-02, -1.74432658e-02,\n",
       "         -4.61038612e-02, -2.39896979e-02,  5.80900395e-03,  1.05414381e-02,\n",
       "         -3.48990113e-02, -1.92431584e-02,  3.05133313e-02, -6.65318454e-03,\n",
       "         -1.55363278e-03,  3.26821581e-02,  1.65410042e-02, -5.67183718e-02,\n",
       "          2.79331766e-02, -1.25835333e-02, -1.07511096e-02, -1.55000025e-02,\n",
       "          2.66212150e-02,  3.36215049e-02,  5.98307028e-02,  5.46113662e-02,\n",
       "          2.37039942e-02, -9.79331881e-03, -8.74838792e-04, -4.90554944e-02,\n",
       "         -3.05973738e-03, -9.44400672e-03,  1.58639234e-02,  5.85518032e-02,\n",
       "          1.86804645e-02,  2.24281158e-02,  2.51307824e-06, -3.26789208e-02,\n",
       "          2.97860838e-02, -2.35483819e-03, -3.86924371e-02,  6.61833733e-02,\n",
       "          3.94146256e-02, -1.11171752e-02, -2.92049125e-02,  3.06446711e-03,\n",
       "         -8.80425237e-03, -5.45369089e-03,  4.51091677e-02, -6.77856132e-02,\n",
       "         -1.66173838e-02, -5.15465476e-02, -8.42314027e-03,  2.10856739e-03,\n",
       "          3.35056856e-02, -4.77082022e-02, -3.43930423e-02, -5.54687670e-03,\n",
       "          2.04953104e-02, -3.15542184e-02,  4.35944051e-02,  1.85484067e-02,\n",
       "          2.17907503e-03,  7.89616406e-02,  3.85614410e-02, -3.17760408e-02,\n",
       "         -2.42262185e-02, -1.70045218e-03, -8.17358680e-03, -5.66940494e-02,\n",
       "         -1.03202472e-02,  1.75393224e-02,  8.22393000e-02, -5.48632592e-02,\n",
       "         -1.06554581e-02,  9.02136497e-04,  3.22502516e-02,  6.62680864e-02,\n",
       "         -1.50287552e-02,  2.43552607e-02, -5.47540281e-03,  1.50316171e-02,\n",
       "          3.13175097e-02, -2.84143444e-02, -5.62796323e-03,  1.32014621e-02,\n",
       "          2.50244699e-02,  5.77905588e-02,  1.68543644e-02, -1.03057381e-02,\n",
       "         -1.76198862e-03, -2.08775848e-02, -1.40335048e-02, -1.00368179e-01,\n",
       "         -4.80770133e-03,  1.36268314e-03,  3.41974162e-02,  1.74080301e-02,\n",
       "         -1.01330159e-02, -9.34064388e-03,  8.74181930e-03, -5.37099913e-02,\n",
       "          1.11316433e-02,  2.95336777e-03,  9.73669719e-03,  1.33126481e-02,\n",
       "          8.13916996e-02,  2.68472563e-02, -1.44701554e-02, -2.01376081e-02,\n",
       "         -1.81152876e-02,  3.81947719e-02,  8.45071685e-04, -4.70105708e-02,\n",
       "         -4.18551601e-02, -1.06980773e-02,  1.00785238e-03, -1.04107521e-02,\n",
       "         -3.46967541e-02,  1.13151027e-02, -1.69992503e-02,  4.46349336e-03,\n",
       "         -5.19442484e-02, -5.84932091e-03, -6.34129941e-02,  1.80796944e-02,\n",
       "          1.74241643e-02,  3.06701157e-02, -5.11349104e-02,  3.82838733e-02,\n",
       "          7.48061063e-03, -5.78434505e-02,  2.38219388e-02, -3.99585664e-02,\n",
       "         -2.31489502e-02, -1.77678186e-02, -3.85858491e-02,  4.01531830e-02,\n",
       "          2.37187967e-02,  1.20920232e-02, -4.04907484e-03, -3.51123549e-02,\n",
       "         -3.40081789e-02, -4.52346690e-02, -4.56356965e-02, -8.24912786e-02,\n",
       "         -3.63403484e-02,  5.37056476e-02, -2.40532812e-02, -8.29120949e-02,\n",
       "         -3.35421972e-02, -1.37906233e-02, -2.70591676e-02, -4.72380314e-03,\n",
       "         -1.27666770e-02,  2.82083098e-02,  4.68416549e-02,  1.53932739e-02,\n",
       "          4.57183719e-02,  5.91456555e-02, -3.64773395e-03, -1.40161132e-02,\n",
       "          2.19343565e-02, -5.82731217e-02,  5.02568446e-02,  4.82676439e-02,\n",
       "         -1.17656607e-02,  3.53494883e-02, -3.64806578e-02, -4.23031440e-03,\n",
       "          7.96726532e-03, -3.51858102e-02,  2.97561251e-02,  5.13470024e-02,\n",
       "         -1.31912145e-03, -2.43228860e-03,  3.91634479e-02,  4.48329039e-02,\n",
       "         -2.75942925e-02, -1.76990926e-02, -2.26592761e-03,  4.84215803e-02,\n",
       "          2.08066287e-03,  1.33959008e-02, -1.60423084e-03,  3.03981709e-03,\n",
       "          2.26677582e-02, -1.01575220e-04, -5.42425960e-02,  5.40543301e-03,\n",
       "         -1.35448026e-02, -2.11425275e-02, -1.26550598e-02,  5.26089966e-03,\n",
       "          5.51666915e-02,  2.13675201e-02,  1.71352606e-02,  1.78682581e-02,\n",
       "          1.12165706e-02,  6.47357702e-02,  4.19963114e-02, -3.71851102e-02,\n",
       "         -1.99067947e-02, -4.31738235e-02,  1.86512470e-02,  7.62243662e-03,\n",
       "         -1.92035176e-02, -1.81719963e-03,  2.09800638e-02,  1.51627660e-02,\n",
       "         -2.13355816e-04,  6.65970519e-02,  1.44128315e-02, -2.55368417e-03,\n",
       "         -4.93745878e-02,  2.53875591e-02,  2.56541576e-02, -2.59786528e-02,\n",
       "          5.54501778e-03,  1.14918901e-02, -1.10339187e-02,  4.10664603e-02,\n",
       "         -1.12479655e-02, -8.57728906e-03, -4.84070256e-02, -4.88494290e-03,\n",
       "         -2.84764841e-02,  4.58103837e-03, -8.23531225e-02, -9.15382523e-03,\n",
       "          2.22113971e-02,  2.39527803e-02, -5.31977750e-02,  1.18287941e-02,\n",
       "          2.77969074e-02,  1.56824309e-02,  3.03027201e-02,  4.92653884e-02,\n",
       "          6.78286748e-03,  6.74751177e-02,  4.13178280e-02,  7.35888537e-03,\n",
       "          3.93533781e-02,  9.65339132e-03,  2.57864501e-02,  3.29854675e-02,\n",
       "          1.20162174e-01, -1.90456596e-03,  1.07110061e-01,  1.17814122e-02,\n",
       "          1.82424970e-02, -5.80055416e-02, -1.29933425e-04, -2.17669029e-02,\n",
       "         -2.31563952e-02, -3.59489247e-02,  1.75856631e-02, -8.43259972e-03,\n",
       "         -1.66363772e-02, -1.68160084e-04,  8.84527061e-03, -4.69320044e-02,\n",
       "          5.88428676e-02, -2.83512548e-02,  4.11374345e-02,  4.98219393e-02,\n",
       "         -1.04545914e-02, -2.57600509e-02, -9.80616547e-03, -1.58962142e-02,\n",
       "         -5.32268882e-02,  9.72771668e-04,  8.43371451e-03,  9.42047499e-03,\n",
       "         -1.38239674e-02, -4.14290801e-02,  3.65180038e-02,  2.93966495e-02,\n",
       "         -2.38171797e-02,  3.11981738e-02,  3.17681767e-02, -1.99635257e-03,\n",
       "          4.19380330e-03, -4.03842628e-02, -4.08017486e-02, -2.31951270e-02,\n",
       "          2.76260786e-02, -6.87642535e-03, -1.28631843e-02, -1.72850955e-02,\n",
       "         -1.44853285e-02,  8.62499326e-03, -7.86660388e-02, -1.03471465e-02,\n",
       "         -2.80738771e-02, -4.52167429e-02,  3.80075015e-02,  3.82291153e-02,\n",
       "          1.17440736e-02, -2.91915964e-02, -3.29204947e-02,  1.03702545e-01,\n",
       "          2.46307887e-02, -1.69505775e-02, -6.18983842e-02, -2.77668238e-02,\n",
       "          5.58578828e-03, -6.11162558e-02, -3.33410129e-02, -6.52115941e-02,\n",
       "         -2.34214263e-03,  6.44586980e-02,  3.05791050e-02, -3.76036135e-03,\n",
       "         -1.70338955e-02,  2.28262991e-02, -6.82590753e-02, -4.69772369e-02,\n",
       "          1.03824809e-02, -4.84363101e-02, -4.08782810e-02,  4.09309193e-02,\n",
       "         -2.84297913e-02, -7.01585263e-02,  1.40283257e-02,  1.91360246e-03,\n",
       "          5.17820613e-03, -1.71004441e-02, -2.35070996e-02, -1.01848403e-02,\n",
       "          5.39142527e-02, -1.16184000e-02, -3.44652822e-03,  8.46998841e-02,\n",
       "         -1.07296379e-02, -2.21612807e-02, -9.51349828e-03, -3.90024739e-03,\n",
       "         -1.22266551e-02,  3.76108065e-02, -5.43203466e-02,  1.24665145e-02,\n",
       "          1.09322788e-03, -7.87346158e-03,  3.32122520e-02, -4.59640473e-02,\n",
       "          1.37885357e-03, -7.92427175e-03,  5.20751663e-02, -1.20302411e-02,\n",
       "          6.00395873e-02, -5.41872345e-03,  3.43494006e-02,  7.57810136e-04,\n",
       "          3.86055862e-03,  1.58624761e-02, -1.43175824e-02, -1.29184620e-02,\n",
       "          1.74119826e-02,  9.94369667e-03, -1.40880533e-02, -5.07649146e-02,\n",
       "         -2.29452979e-02,  4.15917337e-02,  1.10059800e-02,  2.12410707e-02,\n",
       "          5.91289904e-03, -5.87803451e-03,  9.71297920e-02, -1.04124309e-03,\n",
       "         -9.00200233e-02,  3.43977883e-02,  5.06336130e-02, -7.15644658e-02,\n",
       "          6.17869385e-03,  5.81686758e-02,  1.21622439e-02,  1.24180634e-02,\n",
       "          4.57240902e-02, -1.79494824e-02,  8.55990276e-02,  1.93578061e-02,\n",
       "          2.32157856e-02, -5.61592020e-02,  5.17550968e-02,  1.38229756e-02,\n",
       "         -8.43445677e-03, -2.83242427e-02, -2.47449544e-03, -4.87636402e-03,\n",
       "         -8.52536485e-02,  3.89170684e-02,  1.78313916e-04, -6.47094026e-02,\n",
       "          5.30070998e-02,  1.01753846e-02,  1.61274876e-02,  4.49914299e-02,\n",
       "         -6.68506557e-03,  2.10265815e-02, -2.67615542e-02, -1.60831877e-03,\n",
       "          7.12398365e-02, -4.97467816e-02, -3.11833695e-02, -2.46877037e-02,\n",
       "         -5.48071228e-02,  3.50844078e-02, -9.08018835e-03,  1.94441080e-02,\n",
       "         -9.26087648e-02, -5.84900798e-03,  4.78805825e-02,  3.50791030e-02,\n",
       "         -4.94381264e-02, -1.61705930e-02, -9.85386036e-03,  2.93273628e-02,\n",
       "          4.76736017e-03, -2.22808868e-02, -6.66786497e-03,  6.04554499e-03,\n",
       "         -3.55728790e-02, -9.24427249e-03,  2.92088203e-02, -5.42728743e-03,\n",
       "         -5.92562817e-02, -3.33680026e-02, -4.14404599e-03, -4.23514694e-02,\n",
       "          5.32363951e-02,  3.66093889e-02, -5.17180301e-02,  8.72234628e-03,\n",
       "         -7.29631707e-02,  6.77708676e-03,  4.09997441e-02, -5.34489267e-02,\n",
       "         -3.24872807e-02,  3.82803683e-03, -7.49928206e-02, -3.17900516e-02,\n",
       "         -7.63234720e-02, -5.35008265e-03,  1.34990446e-03,  4.92475368e-02,\n",
       "         -7.96895102e-03,  1.64651889e-02, -5.48567064e-02, -9.78487637e-03,\n",
       "          5.91842504e-03,  1.25668030e-02,  8.38678854e-04, -6.20938875e-02,\n",
       "         -1.93599071e-02, -1.31930728e-02,  1.70691926e-02, -3.15866619e-02,\n",
       "          6.53989380e-04, -2.82127457e-03, -7.10532665e-02,  6.84770197e-02,\n",
       "          1.26223769e-02,  2.93380953e-02, -4.24497537e-02,  3.14908363e-02,\n",
       "         -5.06441966e-02, -9.19694081e-03,  5.52433021e-02,  3.81236449e-02,\n",
       "          9.75798965e-02,  2.41067223e-02, -2.32745614e-02,  9.16161109e-03,\n",
       "          2.35805362e-02,  2.82846461e-03, -5.81883499e-03,  1.96640436e-02,\n",
       "          9.07592382e-03, -3.89527977e-02, -2.41626091e-02,  6.63839607e-03,\n",
       "         -7.87650351e-04, -1.70587711e-02, -3.97690274e-02, -2.50893962e-02,\n",
       "         -4.68926504e-02, -4.43906486e-02, -2.84592360e-02, -4.29207943e-02,\n",
       "         -3.05622723e-02, -4.47102971e-02,  2.03413777e-02,  4.27186191e-02,\n",
       "         -1.00957537e-02,  3.51138897e-02,  9.06604622e-03,  6.92144036e-02,\n",
       "         -1.22072008e-02,  4.09183130e-02,  3.16918530e-02,  3.00100520e-02,\n",
       "          3.09954360e-02,  3.58710214e-02, -3.96056054e-03,  3.36508341e-02,\n",
       "         -6.41409978e-02,  3.83696966e-02,  7.21172476e-03,  4.61745076e-02,\n",
       "          1.34928646e-02, -2.47382857e-02,  2.82070953e-02,  6.33769843e-04,\n",
       "          1.85642708e-02, -8.14310312e-02, -8.66263919e-03,  2.88822572e-03,\n",
       "         -1.27996283e-03, -3.98412682e-02,  6.62734061e-02, -6.44226791e-03,\n",
       "         -1.81604810e-02, -4.98635583e-02,  8.73063691e-03,  1.43299135e-03,\n",
       "         -6.25629723e-02,  3.09211891e-02, -1.08613155e-03, -2.94133238e-02,\n",
       "         -7.72565079e-04,  7.57140201e-03,  3.52158174e-02,  2.59848535e-02,\n",
       "          8.03448074e-03, -3.58151086e-03,  1.48224868e-02, -1.63641535e-02,\n",
       "         -8.84705631e-04, -3.39066721e-02,  1.61022022e-02,  1.69633813e-02,\n",
       "         -1.10223763e-01, -7.78352097e-02, -2.03743652e-02,  2.05473863e-02,\n",
       "         -4.40355885e-04, -2.03704890e-02,  1.86788142e-02,  7.17426091e-02,\n",
       "          1.01197967e-02, -6.51506409e-02, -7.15508461e-02,  5.64671587e-03,\n",
       "          8.33202247e-03, -2.16080509e-02, -3.74036915e-07, -6.61588718e-33,\n",
       "         -3.19481604e-02,  1.16972532e-03, -3.35130910e-03, -7.52155203e-03,\n",
       "         -3.74651775e-02, -1.69679616e-02, -2.69925632e-02,  4.04820554e-02,\n",
       "         -4.31937501e-02, -8.09908099e-03, -1.87340565e-02, -2.50229798e-02,\n",
       "          8.10834672e-03, -3.68392952e-02,  5.43613769e-02,  4.40185741e-02,\n",
       "          7.68288178e-03, -1.33311208e-02, -2.18541157e-02, -2.86456570e-02,\n",
       "          3.66406552e-02, -1.44700734e-02,  8.95199776e-02, -2.32291855e-02,\n",
       "          7.84176439e-02, -1.64985172e-02, -1.92036685e-02, -1.46702901e-02,\n",
       "          1.94450133e-02, -1.80326663e-02, -1.41092595e-02,  2.43134703e-03,\n",
       "          9.60210105e-04, -5.67957759e-02, -2.51221913e-03,  1.50789507e-02,\n",
       "          4.24411520e-03,  9.26962937e-04,  4.72802296e-02, -2.45852303e-02,\n",
       "          4.32350822e-02, -3.81985083e-02,  1.71699449e-02,  1.36613967e-02,\n",
       "         -8.18316713e-02,  2.72390544e-02,  1.88959744e-02,  7.05987215e-03,\n",
       "         -7.41295936e-03,  7.30616748e-02, -4.85076495e-02,  8.41784757e-03,\n",
       "         -1.04221599e-02,  3.97427939e-02, -6.29169820e-03,  1.72732957e-02,\n",
       "         -3.21970396e-02,  1.98086281e-03, -5.00508063e-02,  2.25716792e-02,\n",
       "          5.81900254e-02,  7.40064830e-02,  5.67414984e-02,  1.58201403e-03,\n",
       "          2.83456706e-02,  2.85526253e-02,  2.88890442e-03,  2.78674811e-02,\n",
       "          3.57219130e-02, -3.61958402e-03,  8.28663260e-02,  2.70074327e-02,\n",
       "          2.05988139e-02, -3.75527161e-04, -1.38069782e-02, -4.27794568e-02,\n",
       "          1.33350110e-02, -4.89434488e-02,  3.06863394e-02,  2.14124825e-02,\n",
       "         -2.83202436e-02,  1.34758232e-02, -6.21774085e-02, -6.53209463e-02,\n",
       "         -3.20642777e-02, -1.82280261e-02,  2.45774854e-02, -1.90603137e-02,\n",
       "          6.72977278e-03, -4.90018353e-02,  3.31091997e-03, -3.11625879e-02,\n",
       "          3.37814763e-02,  3.40999779e-03, -1.10193059e-01,  7.63044693e-03,\n",
       "         -3.94522995e-02,  5.56755625e-02,  1.87774953e-02,  3.61046493e-02,\n",
       "         -9.61035639e-02,  3.26074101e-02, -5.84343337e-02,  3.17292996e-02,\n",
       "          3.78031470e-02,  2.63377596e-02, -3.95950191e-02,  3.27518024e-02,\n",
       "         -3.32784429e-02,  2.45786160e-02, -4.06578230e-03,  1.17113395e-02,\n",
       "          3.11622750e-02, -2.00665630e-02,  2.71692853e-02, -7.11816875e-03,\n",
       "          1.31515693e-02, -1.93809178e-02,  6.77485466e-02, -3.69527447e-03,\n",
       "         -7.52723068e-02,  4.68083993e-02, -3.27148065e-02,  1.31452652e-02,\n",
       "         -1.40507864e-02,  1.28428712e-02, -4.09072228e-02,  1.26715198e-01,\n",
       "          9.03851762e-02, -2.91021559e-02, -3.94511148e-02, -3.03647276e-02,\n",
       "          3.18164268e-07,  2.19096281e-02,  2.01512408e-02,  2.45617013e-02,\n",
       "          6.60803765e-02,  3.35146897e-02,  2.07132604e-02, -4.63666655e-02,\n",
       "          3.74673270e-02,  4.83985506e-02,  2.17595268e-02, -2.58586835e-02,\n",
       "          1.71344224e-02,  2.32447572e-02,  3.94676253e-02, -2.72202529e-02,\n",
       "          1.76219922e-02, -1.02026545e-01, -9.25651100e-03, -3.30852978e-02,\n",
       "         -3.71950376e-03, -5.52939326e-02,  3.74067985e-02,  4.63195145e-02,\n",
       "          1.69507898e-02, -7.84536153e-02, -1.15400841e-02,  1.76414941e-02,\n",
       "         -5.06382063e-02, -9.33330320e-03,  5.25847971e-02,  9.94759798e-03,\n",
       "          1.08257704e-03,  7.29862973e-03, -4.50840592e-02,  2.21003480e-02,\n",
       "         -2.22797468e-02,  7.10709952e-04, -7.96499755e-03,  2.30182186e-02,\n",
       "          3.62600647e-02,  1.91855710e-02, -6.43681316e-03, -3.59735377e-02,\n",
       "         -7.08703175e-02,  4.43109348e-02,  2.27703713e-03, -9.98594705e-03,\n",
       "         -1.71843432e-02, -6.37918264e-02,  8.16904474e-03,  1.18278656e-02,\n",
       "         -2.69967970e-02, -1.94483679e-02,  2.41446309e-02,  1.75541323e-02,\n",
       "         -9.35575273e-03, -1.83543023e-02, -1.82018317e-02, -5.84390797e-02,\n",
       "          1.26649765e-02, -1.88451577e-02, -4.86851595e-02, -3.02899685e-02,\n",
       "          1.44081134e-02, -4.46564555e-02, -2.79619955e-02,  2.13900544e-02,\n",
       "          3.17939722e-34,  3.67154740e-02, -3.09172040e-03,  4.31713350e-02,\n",
       "         -1.02805542e-02,  1.46743599e-02,  1.93587244e-02,  2.23217905e-02,\n",
       "          2.87836734e-02,  1.13753956e-02, -5.61571307e-03, -1.41901465e-03]),\n",
       "  'score': tensor(0.3988)},\n",
       " {'page_number': 0,\n",
       "  'sentence_chunk': 'For language generation tasks, we ﬁnd that RAG models generate more speciﬁc, diverse and factual language than a state-of-the-art parametric-only seq2seq baseline.1 Introduction Pre-trained neural language models have been shown to learn a substantial amount of in-depth knowl- edge from data [47]. They can do so without any access to an external memory, as a parameterized implicit knowledge base [51, 52]. While this development is exciting, such models do have down- sides: They cannot easily expand or revise their memory, can’t straightforwardly provide insight into their predictions, and may produce “hallucinations” [38]. Hybrid models that combine parametric memory with non-parametric (i.e., retrieval-based) memories [20, 26, 48] can address some of these issues because knowledge can be directly revised and expanded, and accessed knowledge can be inspected and interpreted. REALM [20] and ORQA [31], two recently introduced models that combine masked language models [8] with a differentiable retriever, have shown promising results, 34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada.',\n",
       "  'chunk_char_count': 1139,\n",
       "  'chunk_word_count': 162,\n",
       "  'chunk_token_count': 284.75,\n",
       "  'embedding': array([ 1.50031894e-02,  8.06403011e-02, -1.43866343e-02, -8.14234745e-03,\n",
       "         -1.60815455e-02, -1.40327103e-02,  1.21737886e-02, -2.43056342e-02,\n",
       "         -4.12746966e-02, -2.96179932e-02, -5.97226806e-02, -7.21908659e-02,\n",
       "         -1.46565000e-02,  6.29941076e-02,  4.29989807e-02, -4.65109944e-02,\n",
       "          2.71397755e-02, -3.56143825e-02,  1.91282935e-03, -3.94064421e-03,\n",
       "         -3.84637751e-02,  9.98039264e-03,  4.26331442e-03,  2.53242310e-02,\n",
       "         -4.73575071e-02,  1.43900532e-02, -4.67110761e-02, -2.81715347e-03,\n",
       "         -2.22305078e-02,  4.76525369e-04,  2.19096541e-02,  7.37650692e-02,\n",
       "          2.57720500e-02,  4.58704606e-02,  2.14334977e-06, -2.32465286e-02,\n",
       "          1.41624203e-02, -3.11583467e-02, -2.11020689e-02,  4.89464821e-03,\n",
       "          1.91804208e-02,  2.33549327e-02,  1.92550141e-02, -6.26663957e-03,\n",
       "         -4.13335413e-02, -3.21166813e-02,  4.26739193e-02,  1.48485024e-02,\n",
       "          2.07286235e-02,  5.86697944e-02, -4.26274957e-03, -4.34178524e-02,\n",
       "          2.66274773e-02, -4.11852039e-02,  7.52190128e-02,  1.91533510e-02,\n",
       "          1.52240065e-03, -2.76414733e-02, -8.98330566e-03, -1.49479872e-02,\n",
       "         -1.63047537e-02,  2.94947084e-02,  5.19751497e-02,  2.36740001e-02,\n",
       "          6.07552798e-03,  7.53047392e-02, -3.39472592e-02, -4.60224301e-02,\n",
       "         -6.80014724e-03,  4.83198576e-02, -2.41579153e-02, -4.44257371e-02,\n",
       "          9.04139306e-04,  1.50707923e-02,  9.61799826e-03,  3.11601516e-02,\n",
       "         -2.31975112e-02,  4.27056476e-02,  7.94522639e-04,  3.52436001e-03,\n",
       "         -1.55776590e-02,  3.76071185e-02,  2.76520103e-02,  9.82418377e-03,\n",
       "         -1.44962352e-02,  1.99608430e-02,  2.61358991e-02, -1.56304855e-02,\n",
       "         -2.12761015e-03,  2.07010913e-03, -3.21129411e-02, -4.91605438e-02,\n",
       "          1.43962190e-03,  4.34384868e-02, -2.65353662e-03,  3.25834788e-02,\n",
       "         -6.25340939e-02, -5.08337282e-02,  1.20617766e-02, -1.05376178e-02,\n",
       "          4.16698232e-02,  2.47428715e-02, -2.88119055e-02,  4.61662142e-03,\n",
       "         -6.72457218e-02,  1.45633873e-02, -3.44292237e-03,  2.41144337e-02,\n",
       "         -1.58198122e-02,  7.28299608e-03, -2.65054554e-02, -4.20871377e-02,\n",
       "         -5.52520193e-02,  5.43932691e-02, -4.56747971e-02,  3.03100422e-03,\n",
       "         -1.41205499e-02,  6.31035771e-03, -1.73933227e-02, -5.53930993e-04,\n",
       "         -7.79124349e-03,  4.51446325e-02, -5.64938448e-02, -1.36418771e-02,\n",
       "         -2.89733857e-02, -5.88895380e-02, -3.50075890e-03,  1.39268786e-02,\n",
       "          7.08787367e-02, -6.35681450e-02, -1.30073084e-02,  3.87604552e-04,\n",
       "         -1.29896507e-03, -2.34884098e-02,  7.72282295e-03,  2.75900625e-02,\n",
       "         -3.21511030e-02, -1.42144263e-02, -4.33799401e-02, -7.26321191e-02,\n",
       "         -3.68570089e-02, -7.01774880e-02,  4.50623259e-02, -6.89587221e-02,\n",
       "          3.03251669e-02, -7.01545458e-03, -2.96825264e-02, -7.28078038e-02,\n",
       "          1.64716002e-02,  1.74882337e-02, -1.47007778e-02, -1.95970293e-03,\n",
       "          9.45808832e-03, -7.39509705e-03,  2.47670170e-02,  5.02413549e-02,\n",
       "          3.48543637e-02,  3.93204466e-02,  3.31322923e-02,  5.31019568e-02,\n",
       "         -1.42885139e-02,  1.96464872e-03, -2.01121345e-03,  7.14833091e-04,\n",
       "          6.19100668e-02, -1.09336944e-02, -6.80529773e-02, -3.58521119e-02,\n",
       "          9.39004868e-03,  1.53147969e-02,  4.05032001e-02,  7.02645704e-02,\n",
       "         -4.80264686e-02, -4.40976061e-02,  7.15705976e-02, -1.20456554e-02,\n",
       "          2.22687349e-02,  5.20711914e-02,  1.03625610e-01, -1.92854218e-02,\n",
       "          7.85362720e-03,  3.04600634e-02, -2.46452298e-02,  5.00767715e-02,\n",
       "          7.21284095e-03,  5.39030209e-02,  3.41414027e-02,  2.29640659e-02,\n",
       "         -6.57693818e-02, -4.68077660e-02,  8.58493149e-03, -2.29903385e-02,\n",
       "          6.44786330e-03, -8.83399881e-03,  2.94887032e-02,  6.50739223e-02,\n",
       "         -6.28649965e-02,  7.52020925e-02,  1.47457728e-02, -3.96870300e-02,\n",
       "          3.32203135e-02, -4.07545902e-02,  5.33794835e-02,  1.99062973e-02,\n",
       "          1.80061944e-02, -2.06609685e-02, -9.82555095e-03,  7.51806144e-03,\n",
       "         -1.29203321e-02,  8.69965777e-02,  5.34010343e-02,  1.06837470e-02,\n",
       "          1.34091265e-02, -5.54182082e-02,  2.75208820e-02, -4.53549773e-02,\n",
       "          2.98376437e-02,  3.17406692e-02,  3.29988748e-02,  5.15077682e-03,\n",
       "          2.48992890e-02,  9.56093054e-03, -4.87473644e-02,  2.01563183e-02,\n",
       "         -7.19072521e-02, -4.76334505e-02,  9.63103434e-04, -1.55949444e-02,\n",
       "         -3.08251195e-03, -1.14011886e-02, -1.68361869e-02,  6.12986274e-02,\n",
       "          3.19635160e-02, -4.89534922e-02, -3.72212902e-02,  1.21712387e-02,\n",
       "         -1.14865504e-01, -5.01712114e-02,  4.60636831e-04,  4.20402139e-02,\n",
       "          3.86408195e-02,  1.29345059e-03,  1.69004854e-02, -4.29553241e-02,\n",
       "          4.77616675e-02, -2.71333568e-02,  3.10566667e-02, -6.36736304e-02,\n",
       "         -7.87845161e-03,  4.92576733e-02,  3.24455053e-02, -2.41186731e-02,\n",
       "          7.54761994e-02, -1.98265724e-02, -8.97610374e-03,  8.76981206e-03,\n",
       "          3.81913260e-02, -2.10304279e-02, -1.72391646e-02, -7.71233346e-03,\n",
       "         -7.01959850e-03, -7.64745194e-03,  2.98823453e-02, -1.63433840e-03,\n",
       "         -3.25341150e-03, -5.10280989e-02, -4.10821736e-02, -5.27063608e-02,\n",
       "          8.91300477e-03, -2.35543251e-02, -5.24641909e-02,  1.66585390e-02,\n",
       "         -6.01727050e-04, -4.60350141e-03,  2.07914296e-03, -7.12901056e-02,\n",
       "          1.26473345e-02,  1.78124439e-02,  2.52809301e-02,  1.76189784e-02,\n",
       "          3.73747833e-02,  1.97873283e-02, -1.93038452e-02, -2.10964698e-02,\n",
       "          2.40501780e-02,  5.35810813e-02, -1.56071838e-02,  1.79233029e-02,\n",
       "         -2.53549591e-02,  6.75227046e-02, -7.94591457e-02,  2.40241624e-02,\n",
       "          9.72595299e-04, -2.20436621e-02,  1.05275242e-02, -3.43665965e-02,\n",
       "          7.19368830e-02,  2.46325359e-02,  2.51369998e-02,  1.61333159e-02,\n",
       "          5.98125048e-02, -9.91484430e-03, -1.35135381e-02,  1.42257279e-02,\n",
       "         -6.51831105e-02, -1.84475873e-02,  3.56341787e-02, -1.00351870e-02,\n",
       "         -1.12444325e-03,  8.01782683e-02,  2.54505221e-02, -1.99062079e-02,\n",
       "         -9.02196839e-02,  4.16944362e-02,  1.69558898e-02, -6.00317083e-02,\n",
       "         -1.97610538e-02, -1.24900239e-02, -1.84418987e-02,  5.13795763e-02,\n",
       "         -3.05227432e-02, -6.67160973e-02,  5.56347147e-02, -2.36750338e-02,\n",
       "          3.77244246e-03,  3.06905969e-03,  1.81345548e-02,  5.85013116e-03,\n",
       "          4.31974456e-02,  4.18647332e-03,  4.13489006e-02, -9.02161468e-03,\n",
       "         -5.34699764e-03, -6.06375523e-02, -9.74931195e-03, -2.16746703e-02,\n",
       "         -5.10762408e-02,  2.27030236e-02, -4.77005728e-02, -5.87819051e-03,\n",
       "          1.04753477e-02, -3.43986228e-02, -7.40710050e-02, -2.86194682e-02,\n",
       "          4.87857014e-02,  2.69752797e-02, -3.95553075e-02,  1.46706132e-02,\n",
       "          2.88330801e-02, -7.92135764e-03,  2.88427211e-02,  6.90648258e-02,\n",
       "         -3.26696150e-02, -1.44159542e-02, -1.15825115e-02, -3.88355320e-03,\n",
       "          6.68552145e-02, -7.65039236e-04,  3.52980644e-02, -4.41820435e-02,\n",
       "          4.17764559e-02,  3.94670926e-02,  2.77937222e-02,  2.87600537e-03,\n",
       "         -1.75629612e-02,  2.89276354e-02, -1.28390007e-02,  1.56199140e-02,\n",
       "         -1.63197350e-02,  4.41179946e-02,  5.31234741e-02, -4.44058217e-02,\n",
       "         -7.03643262e-02,  9.67158079e-02,  4.18094220e-03, -7.06439046e-03,\n",
       "          1.55959222e-02,  3.75972106e-03,  8.30453262e-02,  8.62039346e-03,\n",
       "          6.04550680e-03, -4.31874655e-02,  2.12159492e-02, -6.44647703e-03,\n",
       "         -2.46597826e-03, -2.27300208e-02, -3.20840143e-02, -1.67150628e-02,\n",
       "         -9.29799676e-02,  2.95515358e-02,  4.03723866e-02, -3.83545086e-02,\n",
       "          6.61516096e-03,  4.52407077e-02, -5.17872870e-02,  5.78336120e-02,\n",
       "          1.59701258e-02,  3.39272656e-02, -1.71158686e-02,  2.20649857e-02,\n",
       "          3.00526172e-02,  4.13630679e-02, -1.42209604e-02,  1.63871292e-02,\n",
       "         -1.86569039e-02,  7.71602662e-03,  1.44690014e-02,  1.00957614e-03,\n",
       "         -1.49723003e-03, -4.42743748e-02,  2.68621407e-02, -1.92870051e-02,\n",
       "          1.37040010e-02,  1.96622740e-02,  3.59214135e-02,  1.51048740e-02,\n",
       "         -1.42855886e-02, -6.54013176e-03,  2.43529212e-02, -2.50027813e-02,\n",
       "         -2.62266044e-02, -3.89334485e-02,  2.34693717e-02, -2.03201417e-02,\n",
       "         -2.05983277e-02,  2.75515113e-03,  2.12313514e-02, -6.36610726e-04,\n",
       "          7.68672004e-02,  3.50980423e-02, -1.02455961e-02, -2.02868618e-02,\n",
       "          3.35611403e-03,  3.01348995e-02, -5.84592633e-02, -3.79328504e-02,\n",
       "          5.70964627e-02,  8.83291382e-03, -5.74782752e-02, -1.09303273e-01,\n",
       "         -5.76010868e-02, -5.61708352e-04,  7.61817470e-02, -1.01473946e-02,\n",
       "         -2.04676203e-02, -8.35676864e-03, -5.71660437e-02, -5.77274896e-02,\n",
       "          9.64663364e-03, -1.38624068e-02, -5.05336635e-02, -2.43990701e-02,\n",
       "         -5.06487004e-02,  5.22411847e-03, -9.02178958e-02, -1.60684790e-02,\n",
       "          1.50572909e-02, -7.69086480e-02, -7.14901090e-02,  4.69027795e-02,\n",
       "          8.04097727e-02,  2.57015582e-02,  4.16779965e-02,  2.17937008e-02,\n",
       "         -1.27687426e-02,  8.94648507e-02,  1.66979730e-02, -4.27129753e-02,\n",
       "          4.05340232e-02, -4.18027164e-03,  4.74808365e-03, -1.60612110e-02,\n",
       "          3.23336758e-02, -3.59672830e-02,  1.22983092e-02,  2.83752438e-02,\n",
       "          1.97658949e-02,  2.37069540e-02,  2.04044078e-02,  4.88298424e-02,\n",
       "         -2.66997684e-02,  3.78218032e-02, -4.85484814e-03,  5.56500303e-03,\n",
       "         -4.08205092e-02, -2.07379535e-02, -2.23569833e-02,  1.32026114e-02,\n",
       "         -3.73347849e-02, -6.96330750e-03,  9.40924697e-03,  1.81441773e-02,\n",
       "         -6.50588376e-03, -2.23155022e-02,  7.92539958e-03,  7.73972571e-02,\n",
       "         -1.87520348e-02, -8.97393450e-02, -1.39275286e-02,  3.32195982e-02,\n",
       "          3.19116488e-02, -7.04428414e-03, -5.65969348e-02,  3.83946523e-02,\n",
       "         -4.19331267e-02,  4.44232821e-02, -1.41742667e-02,  5.26878685e-02,\n",
       "          1.10286698e-02, -1.55235664e-03, -1.50662968e-02,  7.61299720e-03,\n",
       "         -5.46298102e-02, -7.31116012e-02, -1.73603222e-02,  2.63859541e-03,\n",
       "          1.87960938e-02, -2.02204566e-02,  2.27907319e-02, -4.27871011e-02,\n",
       "          2.27980036e-02, -3.21737677e-02,  2.75913421e-02,  2.47108340e-02,\n",
       "         -3.94411609e-02,  1.47258220e-02,  3.97160742e-03, -3.27472910e-02,\n",
       "         -3.11039090e-02,  6.63027242e-02,  5.80103546e-02,  5.77929951e-02,\n",
       "         -5.18692378e-03,  2.63095405e-02, -2.62290277e-02, -3.19303535e-02,\n",
       "          2.71910219e-04,  3.16488207e-03, -1.75180994e-02,  1.25148948e-02,\n",
       "         -6.73135445e-02, -5.07562943e-02,  2.36520115e-02, -7.52612832e-04,\n",
       "          1.85668152e-02,  6.03190670e-03,  5.14698289e-02,  4.12487537e-02,\n",
       "         -4.32032049e-02, -1.61913708e-02, -4.81293723e-02,  5.46391197e-02,\n",
       "          2.97314883e-03,  1.56638604e-02,  4.28404100e-03, -6.87865205e-33,\n",
       "         -2.43854318e-02, -3.46003170e-03,  5.59825525e-02, -5.14821596e-02,\n",
       "         -1.15325404e-02,  2.96988152e-03, -2.81416643e-02,  1.21313743e-02,\n",
       "         -1.00479359e-02,  4.15731408e-03, -9.89503576e-04, -3.51798208e-03,\n",
       "          7.87006319e-03,  4.34394330e-02, -4.88749379e-03, -1.67363863e-02,\n",
       "          5.10884188e-02, -1.25345597e-02, -1.41155999e-02,  6.74870089e-02,\n",
       "          7.08415285e-02,  2.47702040e-02,  6.24249540e-02,  6.61046826e-04,\n",
       "         -1.44154616e-02,  1.74813485e-03,  1.21335825e-02,  4.24784236e-03,\n",
       "         -2.89912485e-02,  3.72565538e-02, -3.66987288e-02,  7.16785388e-03,\n",
       "          1.17901275e-02,  2.06649676e-02, -4.00217585e-02, -4.16978262e-02,\n",
       "         -4.93304431e-02, -4.26417850e-02, -4.89735464e-03, -2.63141394e-02,\n",
       "         -4.84519228e-02, -3.11138127e-02,  5.44764064e-02, -2.84623131e-02,\n",
       "         -2.02041380e-02, -8.42875522e-03, -1.94865260e-02, -3.15672602e-03,\n",
       "         -4.51563522e-02, -3.16133834e-02, -4.54555824e-02, -9.11625009e-03,\n",
       "          3.88291255e-02, -3.32826115e-02, -1.74761880e-02,  4.68281507e-02,\n",
       "         -1.14031676e-02, -6.70647295e-03, -9.42372009e-02,  1.15589648e-02,\n",
       "         -3.57817896e-02,  5.98788932e-02,  3.24857645e-02,  3.59234735e-02,\n",
       "          2.59370171e-02,  6.44817054e-02,  4.06930968e-02,  2.06621606e-02,\n",
       "         -4.30433266e-02,  4.39241156e-02,  3.83505933e-02,  4.16167639e-02,\n",
       "          1.79407652e-02,  1.28777674e-03,  4.86271679e-02, -3.32311727e-02,\n",
       "         -5.52587025e-02,  5.77848079e-03, -2.03685407e-02,  2.64303088e-02,\n",
       "          6.57391399e-02, -3.19776833e-02, -7.64784124e-03, -1.93444118e-02,\n",
       "         -4.89717424e-02, -2.79663061e-03, -2.04298049e-02, -1.51357474e-02,\n",
       "          4.75978740e-02,  5.83300926e-02,  1.02889594e-02, -1.04544740e-02,\n",
       "          3.10318656e-02,  2.94476170e-02,  2.14771833e-02,  1.36976065e-02,\n",
       "         -5.09591140e-02, -2.03502625e-02, -2.41104048e-02,  6.25752378e-03,\n",
       "         -3.47989351e-02, -2.74167955e-02,  4.47428897e-02,  4.39469516e-02,\n",
       "         -7.78694730e-03,  5.79348654e-02,  2.22644880e-02,  3.87625284e-02,\n",
       "         -5.06227463e-02,  2.16647834e-02, -7.25328848e-02,  6.80866763e-02,\n",
       "          3.56303602e-02, -2.32648682e-02,  4.60908078e-02,  1.80927385e-02,\n",
       "         -3.98768485e-02,  4.50312383e-02, -1.35787847e-02, -4.05642949e-02,\n",
       "         -1.72916036e-02,  1.23471338e-02,  2.18792818e-02,  5.61254472e-02,\n",
       "         -9.59252939e-03, -3.95537791e-04, -3.99325192e-02, -2.78075896e-02,\n",
       "          6.23093359e-02, -3.60577516e-02,  1.92602053e-02,  1.98025983e-02,\n",
       "          2.82965516e-07, -1.38810435e-02, -1.45984804e-02,  2.15437915e-02,\n",
       "          8.63521919e-03,  1.13835419e-02,  3.74790211e-03, -1.53511250e-02,\n",
       "          3.43992524e-02, -4.06253617e-03, -3.23354118e-02, -4.78635579e-02,\n",
       "          4.57281508e-02,  4.43153530e-02,  1.86665319e-02, -7.17118531e-02,\n",
       "         -3.16257440e-02, -6.44388199e-02,  1.46992663e-02, -4.31431979e-02,\n",
       "         -2.55737789e-02,  3.45329382e-02,  7.04647228e-02, -2.49313680e-03,\n",
       "         -1.44820530e-02,  4.54464853e-02, -2.52406076e-02,  9.15193260e-02,\n",
       "          7.93369673e-03, -2.46539321e-02,  1.15113398e-02,  3.78440134e-02,\n",
       "          1.87183134e-02,  6.36503682e-04,  2.80281529e-03, -1.96281057e-02,\n",
       "          8.95316154e-03, -1.41913416e-02,  5.62675744e-02,  2.04605293e-02,\n",
       "         -4.06470709e-02,  5.77740371e-03,  1.00206062e-02, -1.51381940e-02,\n",
       "         -5.93643114e-02,  3.74046974e-02, -4.12827097e-02, -1.29223587e-02,\n",
       "          2.53875647e-02, -7.19592022e-03,  2.83916388e-02,  1.73610076e-02,\n",
       "         -4.01427075e-02, -8.15162528e-03,  1.09067596e-02,  8.76943674e-03,\n",
       "          4.65278737e-02,  9.92414635e-03, -5.38504496e-02, -4.19863015e-02,\n",
       "          1.48035670e-02, -5.15637919e-02, -2.52843574e-02, -4.91653904e-02,\n",
       "          1.66145724e-03, -3.69309681e-03, -6.03796691e-02, -1.41345859e-02,\n",
       "          2.89944360e-34,  7.44625973e-03,  5.93845546e-03,  7.40405731e-03,\n",
       "          2.18936019e-02,  1.16523709e-02, -4.09841351e-02,  1.20017389e-02,\n",
       "          2.87564136e-02,  1.26121221e-02, -4.87755574e-02, -5.25439866e-02]),\n",
       "  'score': tensor(0.3939)}]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = random.choice(query_list)\n",
    "print(f\"Query: {query}\")\n",
    "\n",
    "# Answer query with context and return context \n",
    "answer, context_items = ask(query=query, \n",
    "                            temperature=0.7,\n",
    "                            max_new_tokens=512,\n",
    "                            return_answer_only=False)\n",
    "\n",
    "print(f\"Answer:\\n\")\n",
    "print_wrapped(answer)\n",
    "print(f\"Context items:\")\n",
    "context_items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Extensions\n",
    "\n",
    "* May want to improve text extraction with something like Marker - https://github.com/VikParuchuri/marker\n",
    "* Guide to more advanced PDF extraction - https://towardsdatascience.com/extracting-text-from-pdf-files-with-python-a-comprehensive-guide-9fc4003d517 \n",
    "* See the following prompt engineering resources for more prompting techniques - promptinguide.ai, Brex's Prompt Engineering Guide \n",
    "* What happens when a query comes through that there isn't any context in the textbook on?\n",
    "* Try another embedding model (e.g. Mixed Bread AI large, `mixedbread-ai/mxbai-embed-large-v1`, see: https://huggingface.co/mixedbread-ai/mxbai-embed-large-v1)\n",
    "* Try another LLM... (e.g. Mistral-Instruct)\n",
    "* Try different prompts (e.g. see prompting techniques online)\n",
    "* Our example only focuses on text from a PDF, however, we could extend it to include figures and images \n",
    "* Evaluate the answers -> could use another LLM to rate our answers (e.g. use GPT-4 to make)\n",
    "* Vector database/index for larger setup (e.g. 100,000+ chunks)\n",
    "* Libraries/frameworks such as LangChain / LlamaIndex can help do many of the steps for you - so it's worth looking into those next, wanted to recreate a workflow with lower-level tools to show the principles\n",
    "* Optimizations for speed\n",
    "    * See Hugging Face docs for recommended speed ups on GPU - https://huggingface.co/docs/transformers/perf_infer_gpu_one \n",
    "    * Optimum NVIDIA - https://huggingface.co/blog/optimum-nvidia, GitHub: https://github.com/huggingface/optimum-nvidia \n",
    "    * See NVIDIA TensorRT-LLM - https://github.com/NVIDIA/TensorRT-LLM \n",
    "    * See GPT-Fast for PyTorch-based optimizations - https://github.com/pytorch-labs/gpt-fast \n",
    "    * Flash attention 2 (requires Ampere GPUs or newer) - https://github.com/Dao-AILab/flash-attention\n",
    "* Stream text output so it looks prettier (e.g. each token appears as it gets output from the model)\n",
    "* Turn the workflow into an app, see Gradio type chatbots for this - https://www.gradio.app/guides/creating-a-chatbot-fast, see local example: https://www.gradio.app/guides/creating-a-chatbot-fast#example-using-a-local-open-source-llm-with-hugging-face "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
